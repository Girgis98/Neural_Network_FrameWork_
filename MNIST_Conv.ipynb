{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Conv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXV6-X7dAyDy"
      },
      "source": [
        "Remmeber to change runtime to GPU , have fun using OmMariamFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhID-tEcZRof",
        "outputId": "638fb94f-073a-41ae-9328-144502261029"
      },
      "source": [
        "!pip install OmMariamFlow"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: OmMariamFlow in /usr/local/lib/python3.6/dist-packages (0.0.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D61-a2MAU8YP"
      },
      "source": [
        "import cupy as cp"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JMSotRkV3hf"
      },
      "source": [
        "\n",
        "from OmMariamFlow.OmMariamFlow import *\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az68SjnSdQUD"
      },
      "source": [
        "train_path = 'sample_data/mnist_train_small.csv'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U24RGS8UFRW"
      },
      "source": [
        "#load the csv\n",
        "img_data = Image(path = train_path,test_frac = 0.5,val_frac = 0.45,image_size=(28,28), colour = 'gray')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5MPWO1RV7H7"
      },
      "source": [
        "#get trainning data\n",
        "train_data = img_data.train_data\n",
        "train_labels = img_data.train_labels\n",
        "\n",
        "test_data = img_data.train_data\n",
        "test_labels = img_data.train_labels"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGq95so1WMX9"
      },
      "source": [
        "#define the model\n",
        "Layer1 = Conv(X = np.array(train_data),in_channels = 1, out_channels = 2, kernel_size=8, stride=1, padding= 2  , Activation_fn = 'relu')\n",
        "Layer2 = MaxPool(Layer1.output(),kernel_size=3, stride=1, padding=0)\n",
        "Layer3 = Flatten(Layer2.output())\n",
        "Layer4 = Linear(Input_Matrix = Layer3.output().T,Output_Dimension = 500,Activation_fn = 'relu')\n",
        "Layer5 = Linear(Input_Matrix = Layer4.output(),Output_Dimension = 10,Activation_fn = 'softmax')\n",
        "my_Model = Model([Layer1,Layer2,Layer3,Layer4,Layer5])\n",
        "my_Loss = my_Model.Loss(np.array(train_labels), Layer5.output()).CrossEntropy()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqNbzo16WOvI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01b4047c-7749-4e6f-aa0b-6415d4d04bb8"
      },
      "source": [
        "#parameters\n",
        "learning_rate = 0.065\n",
        "training_epochs = 400\n",
        "epsilon = 0.01\n",
        "#train and visualize\n",
        "opt = my_Model.Optimization(training_epochs, my_Loss, learning_rate, epsilon).GradientDescent()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Loss : 0.10886677771482842\n",
            "accuracy  :  0.14614614614614616\n",
            "\n",
            " Loss : 2.3559103378331887\n",
            "accuracy  :  0.0\n",
            "\n",
            " Loss : 2.260161094286925\n",
            "accuracy  :  0.16016016016016016\n",
            "\n",
            " Loss : 2.2172197617303167\n",
            "accuracy  :  0.2122122122122122\n",
            "\n",
            " Loss : 2.182126370726085\n",
            "accuracy  :  0.2552552552552553\n",
            "\n",
            " Loss : 2.1493853231431914\n",
            "accuracy  :  0.2752752752752753\n",
            "\n",
            " Loss : 2.118003783698437\n",
            "accuracy  :  0.3123123123123123\n",
            "\n",
            " Loss : 2.087725040109705\n",
            "accuracy  :  0.3353353353353353\n",
            "\n",
            " Loss : 2.058289237271979\n",
            "accuracy  :  0.36036036036036034\n",
            "\n",
            " Loss : 2.0295500116953034\n",
            "accuracy  :  0.3783783783783784\n",
            "\n",
            " Loss : 2.0014653970064447\n",
            "accuracy  :  0.4014014014014014\n",
            "\n",
            " Loss : 1.9740257867703546\n",
            "accuracy  :  0.42042042042042044\n",
            "\n",
            " Loss : 1.947222224390422\n",
            "accuracy  :  0.44544544544544545\n",
            "\n",
            " Loss : 1.9210435240706252\n",
            "accuracy  :  0.46346346346346345\n",
            "\n",
            " Loss : 1.8954782287155933\n",
            "accuracy  :  0.4804804804804805\n",
            "\n",
            " Loss : 1.8705149542258293\n",
            "accuracy  :  0.4954954954954955\n",
            "\n",
            " Loss : 1.8461420621497424\n",
            "accuracy  :  0.5155155155155156\n",
            "\n",
            " Loss : 1.8223475268767526\n",
            "accuracy  :  0.5295295295295295\n",
            "\n",
            " Loss : 1.7991189877240357\n",
            "accuracy  :  0.5455455455455456\n",
            "\n",
            " Loss : 1.776443833108516\n",
            "accuracy  :  0.5585585585585585\n",
            "\n",
            " Loss : 1.754309271277837\n",
            "accuracy  :  0.5745745745745746\n",
            "\n",
            " Loss : 1.7327023930405157\n",
            "accuracy  :  0.5855855855855856\n",
            "\n",
            " Loss : 1.7116102313023898\n",
            "accuracy  :  0.5965965965965966\n",
            "\n",
            " Loss : 1.6910198164236043\n",
            "accuracy  :  0.6046046046046046\n",
            "\n",
            " Loss : 1.6709182260002744\n",
            "accuracy  :  0.6166166166166166\n",
            "\n",
            " Loss : 1.6512926288247411\n",
            "accuracy  :  0.6306306306306306\n",
            "\n",
            " Loss : 1.6321303233060351\n",
            "accuracy  :  0.6416416416416416\n",
            "\n",
            " Loss : 1.613418770682444\n",
            "accuracy  :  0.6486486486486487\n",
            "\n",
            " Loss : 1.595145623338375\n",
            "accuracy  :  0.6566566566566566\n",
            "\n",
            " Loss : 1.5772987485547445\n",
            "accuracy  :  0.6676676676676677\n",
            "\n",
            " Loss : 1.5598662480519958\n",
            "accuracy  :  0.6736736736736737\n",
            "\n",
            " Loss : 1.5428364737051987\n",
            "accuracy  :  0.6846846846846847\n",
            "\n",
            " Loss : 1.5261980398172785\n",
            "accuracy  :  0.6916916916916916\n",
            "\n",
            " Loss : 1.5099398323310866\n",
            "accuracy  :  0.6976976976976977\n",
            "\n",
            " Loss : 1.4940510153464461\n",
            "accuracy  :  0.7027027027027027\n",
            "\n",
            " Loss : 1.4785210352870914\n",
            "accuracy  :  0.7097097097097097\n",
            "\n",
            " Loss : 1.46333962303707\n",
            "accuracy  :  0.7137137137137137\n",
            "\n",
            " Loss : 1.4484967943386797\n",
            "accuracy  :  0.7267267267267268\n",
            "\n",
            " Loss : 1.4339828487158879\n",
            "accuracy  :  0.7297297297297297\n",
            "\n",
            " Loss : 1.4197883671594609\n",
            "accuracy  :  0.7367367367367368\n",
            "\n",
            " Loss : 1.4059042087833877\n",
            "accuracy  :  0.7427427427427428\n",
            "\n",
            " Loss : 1.3923215066371255\n",
            "accuracy  :  0.7477477477477478\n",
            "\n",
            " Loss : 1.3790316628349253\n",
            "accuracy  :  0.7517517517517518\n",
            "\n",
            " Loss : 1.3660263431422721\n",
            "accuracy  :  0.7547547547547547\n",
            "\n",
            " Loss : 1.3532974711402024\n",
            "accuracy  :  0.7577577577577578\n",
            "\n",
            " Loss : 1.3408372220710794\n",
            "accuracy  :  0.7617617617617618\n",
            "\n",
            " Loss : 1.3286380164540614\n",
            "accuracy  :  0.7667667667667668\n",
            "\n",
            " Loss : 1.3166925135450365\n",
            "accuracy  :  0.7697697697697697\n",
            "\n",
            " Loss : 1.3049936047039516\n",
            "accuracy  :  0.7707707707707707\n",
            "\n",
            " Loss : 1.2935344067221788\n",
            "accuracy  :  0.7767767767767768\n",
            "\n",
            " Loss : 1.2823082551536296\n",
            "accuracy  :  0.7827827827827828\n",
            "\n",
            " Loss : 1.271308697685651\n",
            "accuracy  :  0.7847847847847848\n",
            "\n",
            " Loss : 1.2605294875791184\n",
            "accuracy  :  0.7837837837837838\n",
            "\n",
            " Loss : 1.2499645772015198\n",
            "accuracy  :  0.7837837837837838\n",
            "\n",
            " Loss : 1.2396081116720095\n",
            "accuracy  :  0.7847847847847848\n",
            "\n",
            " Loss : 1.2294544226333624\n",
            "accuracy  :  0.7867867867867868\n",
            "\n",
            " Loss : 1.2194980221623064\n",
            "accuracy  :  0.7877877877877878\n",
            "\n",
            " Loss : 1.2097335968268488\n",
            "accuracy  :  0.7927927927927928\n",
            "\n",
            " Loss : 1.2001560018967805\n",
            "accuracy  :  0.7997997997997998\n",
            "\n",
            " Loss : 1.1907602557115395\n",
            "accuracy  :  0.8038038038038038\n",
            "\n",
            " Loss : 1.181541534207949\n",
            "accuracy  :  0.8118118118118118\n",
            "\n",
            " Loss : 1.172495165608958\n",
            "accuracy  :  0.8128128128128128\n",
            "\n",
            " Loss : 1.163616625273399\n",
            "accuracy  :  0.8138138138138138\n",
            "\n",
            " Loss : 1.1549015307058526\n",
            "accuracy  :  0.8138138138138138\n",
            "\n",
            " Loss : 1.1463456367249545\n",
            "accuracy  :  0.8178178178178178\n",
            "\n",
            " Loss : 1.1379448307879096\n",
            "accuracy  :  0.8198198198198198\n",
            "\n",
            " Loss : 1.129695128468486\n",
            "accuracy  :  0.8228228228228228\n",
            "\n",
            " Loss : 1.1215926690854072\n",
            "accuracy  :  0.8228228228228228\n",
            "\n",
            " Loss : 1.1136337114777766\n",
            "accuracy  :  0.8248248248248248\n",
            "\n",
            " Loss : 1.1058146299239628\n",
            "accuracy  :  0.8258258258258259\n",
            "\n",
            " Loss : 1.098131910200225\n",
            "accuracy  :  0.8288288288288288\n",
            "\n",
            " Loss : 1.0905821457752514\n",
            "accuracy  :  0.8278278278278278\n",
            "\n",
            " Loss : 1.0831620341367418\n",
            "accuracy  :  0.8298298298298298\n",
            "\n",
            " Loss : 1.0758683732461183\n",
            "accuracy  :  0.8298298298298298\n",
            "\n",
            " Loss : 1.0686980581174592\n",
            "accuracy  :  0.8298298298298298\n",
            "\n",
            " Loss : 1.0616480775167854\n",
            "accuracy  :  0.8318318318318318\n",
            "\n",
            " Loss : 1.0547155107778343\n",
            "accuracy  :  0.8348348348348348\n",
            "\n",
            " Loss : 1.047897524730557\n",
            "accuracy  :  0.8358358358358359\n",
            "\n",
            " Loss : 1.0411913707385907\n",
            "accuracy  :  0.8408408408408409\n",
            "\n",
            " Loss : 1.0345943818420766\n",
            "accuracy  :  0.8418418418418419\n",
            "\n",
            " Loss : 1.0281039700022339\n",
            "accuracy  :  0.8428428428428428\n",
            "\n",
            " Loss : 1.0217176234442193\n",
            "accuracy  :  0.8458458458458459\n",
            "\n",
            " Loss : 1.0154329040948618\n",
            "accuracy  :  0.8458458458458459\n",
            "\n",
            " Loss : 1.0092474451119742\n",
            "accuracy  :  0.8458458458458459\n",
            "\n",
            " Loss : 1.0031589485020218\n",
            "accuracy  :  0.8468468468468469\n",
            "\n",
            " Loss : 0.9971651828230297\n",
            "accuracy  :  0.8468468468468469\n",
            "\n",
            " Loss : 0.9912639809696946\n",
            "accuracy  :  0.8468468468468469\n",
            "\n",
            " Loss : 0.9854532380377703\n",
            "accuracy  :  0.8468468468468469\n",
            "\n",
            " Loss : 0.9797309092648796\n",
            "accuracy  :  0.8478478478478478\n",
            "\n",
            " Loss : 0.9740950080449964\n",
            "accuracy  :  0.8468468468468469\n",
            "\n",
            " Loss : 0.9685436040139381\n",
            "accuracy  :  0.8478478478478478\n",
            "\n",
            " Loss : 0.9630748212032864\n",
            "accuracy  :  0.8498498498498499\n",
            "\n",
            " Loss : 0.957686836260249\n",
            "accuracy  :  0.8488488488488488\n",
            "\n",
            " Loss : 0.9523778767310509\n",
            "accuracy  :  0.8498498498498499\n",
            "\n",
            " Loss : 0.9471462194055366\n",
            "accuracy  :  0.8508508508508509\n",
            "\n",
            " Loss : 0.9419901887207306\n",
            "accuracy  :  0.8508508508508509\n",
            "\n",
            " Loss : 0.9369081552211955\n",
            "accuracy  :  0.8528528528528528\n",
            "\n",
            " Loss : 0.9318985340740938\n",
            "accuracy  :  0.8538538538538538\n",
            "\n",
            " Loss : 0.9269597836369369\n",
            "accuracy  :  0.8538538538538538\n",
            "\n",
            " Loss : 0.9220904040760755\n",
            "accuracy  :  0.8528528528528528\n",
            "\n",
            " Loss : 0.9172889360340564\n",
            "accuracy  :  0.8528528528528528\n",
            "\n",
            " Loss : 0.9125539593440376\n",
            "accuracy  :  0.8528528528528528\n",
            "\n",
            " Loss : 0.9078840917895167\n",
            "accuracy  :  0.8538538538538538\n",
            "\n",
            " Loss : 0.9032779879076955\n",
            "accuracy  :  0.8548548548548549\n",
            "\n",
            " Loss : 0.898734337834863\n",
            "accuracy  :  0.8548548548548549\n",
            "\n",
            " Loss : 0.8942518661922355\n",
            "accuracy  :  0.8558558558558559\n",
            "\n",
            " Loss : 0.8898293310107555\n",
            "accuracy  :  0.8548548548548549\n",
            "\n",
            " Loss : 0.8854655226934021\n",
            "accuracy  :  0.8548548548548549\n",
            "\n",
            " Loss : 0.8811592630136225\n",
            "accuracy  :  0.8548548548548549\n",
            "\n",
            " Loss : 0.876909404148542\n",
            "accuracy  :  0.8578578578578578\n",
            "\n",
            " Loss : 0.8727148277456674\n",
            "accuracy  :  0.8578578578578578\n",
            "\n",
            " Loss : 0.8685744440218353\n",
            "accuracy  :  0.8578578578578578\n",
            "\n",
            " Loss : 0.8644871908932176\n",
            "accuracy  :  0.8578578578578578\n",
            "\n",
            " Loss : 0.8604520331352298\n",
            "accuracy  :  0.8588588588588588\n",
            "\n",
            " Loss : 0.8564679615712383\n",
            "accuracy  :  0.8608608608608609\n",
            "\n",
            " Loss : 0.852533992288999\n",
            "accuracy  :  0.8618618618618619\n",
            "\n",
            " Loss : 0.8486491658838077\n",
            "accuracy  :  0.8618618618618619\n",
            "\n",
            " Loss : 0.8448125467273726\n",
            "accuracy  :  0.8618618618618619\n",
            "\n",
            " Loss : 0.8410232222614644\n",
            "accuracy  :  0.8638638638638638\n",
            "\n",
            " Loss : 0.8372803023154305\n",
            "accuracy  :  0.8638638638638638\n",
            "\n",
            " Loss : 0.8335829184466972\n",
            "accuracy  :  0.8648648648648649\n",
            "\n",
            " Loss : 0.8299302233034167\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.8263213900084462\n",
            "accuracy  :  0.8668668668668669\n",
            "\n",
            " Loss : 0.8227556115638828\n",
            "accuracy  :  0.8668668668668669\n",
            "\n",
            " Loss : 0.8192321002753978\n",
            "accuracy  :  0.8668668668668669\n",
            "\n",
            " Loss : 0.8157500871956551\n",
            "accuracy  :  0.8668668668668669\n",
            "\n",
            " Loss : 0.8123088215861151\n",
            "accuracy  :  0.8668668668668669\n",
            "\n",
            " Loss : 0.8089075703965599\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.8055456177616951\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.8022222645142132\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.7989368277137239\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.7956886401909798\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.7924770501068507\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.7893014205255138\n",
            "accuracy  :  0.8698698698698699\n",
            "\n",
            " Loss : 0.7861611290013578\n",
            "accuracy  :  0.8708708708708709\n",
            "\n",
            " Loss : 0.783055567179107\n",
            "accuracy  :  0.8708708708708709\n",
            "\n",
            " Loss : 0.7799841404066974\n",
            "accuracy  :  0.8718718718718719\n",
            "\n",
            " Loss : 0.7769462673604555\n",
            "accuracy  :  0.8718718718718719\n",
            "\n",
            " Loss : 0.7739413796821376\n",
            "accuracy  :  0.8718718718718719\n",
            "\n",
            " Loss : 0.7709689216274207\n",
            "accuracy  :  0.8718718718718719\n",
            "\n",
            " Loss : 0.7680283497254331\n",
            "accuracy  :  0.8718718718718719\n",
            "\n",
            " Loss : 0.7651191324489457\n",
            "accuracy  :  0.8728728728728729\n",
            "\n",
            " Loss : 0.7622407498948449\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7593926934745315\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7565744656139015\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7537855794625742\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7510255586120496\n",
            "accuracy  :  0.8728728728728729\n",
            "\n",
            " Loss : 0.7482939368224869\n",
            "accuracy  :  0.8728728728728729\n",
            "\n",
            " Loss : 0.7455902577578092\n",
            "accuracy  :  0.8728728728728729\n",
            "\n",
            " Loss : 0.7429140747288469\n",
            "accuracy  :  0.8728728728728729\n",
            "\n",
            " Loss : 0.7402649504442477\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7376424567688884\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7350461744895338\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7324756930874972\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7299306105180674\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7274105329964763\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7249150747901832\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.7224438580172728\n",
            "accuracy  :  0.8748748748748749\n",
            "\n",
            " Loss : 0.7199965124507558\n",
            "accuracy  :  0.8748748748748749\n",
            "\n",
            " Loss : 0.7175726753285818\n",
            "accuracy  :  0.8748748748748749\n",
            "\n",
            " Loss : 0.7151719911691741\n",
            "accuracy  :  0.8748748748748749\n",
            "\n",
            " Loss : 0.7127941115923043\n",
            "accuracy  :  0.8748748748748749\n",
            "\n",
            " Loss : 0.7104386951451316\n",
            "accuracy  :  0.8758758758758759\n",
            "\n",
            " Loss : 0.708105407133239\n",
            "accuracy  :  0.8778778778778779\n",
            "\n",
            " Loss : 0.7057939194565027\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.7035039104496382\n",
            "accuracy  :  0.8798798798798799\n",
            "\n",
            " Loss : 0.7012350647272712\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6989870730333886\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6967596320950276\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6945524444800688\n",
            "accuracy  :  0.8798798798798799\n",
            "\n",
            " Loss : 0.6923652184590006\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6901976678705294\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.688049511990915\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6859204754069124\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6838102878922051\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6817186842872248\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6796454043822476\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6775901928036666\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6755527989033415\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.673532976650933\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6715304845291253\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6695450854316524\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6675765465640408\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.665624639346985\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.6636891393222795\n",
            "accuracy  :  0.8818818818818819\n",
            "\n",
            " Loss : 0.6617698260612234\n",
            "accuracy  :  0.8818818818818819\n",
            "\n",
            " Loss : 0.6598664830754314\n",
            "accuracy  :  0.8818818818818819\n",
            "\n",
            " Loss : 0.6579788977299719\n",
            "accuracy  :  0.8828828828828829\n",
            "\n",
            " Loss : 0.6561068611587675\n",
            "accuracy  :  0.8828828828828829\n",
            "\n",
            " Loss : 0.6542501681821863\n",
            "accuracy  :  0.8828828828828829\n",
            "\n",
            " Loss : 0.6524086172267642\n",
            "accuracy  :  0.8828828828828829\n",
            "\n",
            " Loss : 0.6505820102469886\n",
            "accuracy  :  0.8838838838838838\n",
            "\n",
            " Loss : 0.6487701526490894\n",
            "accuracy  :  0.8848848848848849\n",
            "\n",
            " Loss : 0.6469728532167738\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.6451899240388488\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.643421180438679\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.6416664409054228\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.6399255270269971\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.6381982634247222\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.6364844776895953\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.6347840003201493\n",
            "accuracy  :  0.8868868868868869\n",
            "\n",
            " Loss : 0.6330966646618486\n",
            "accuracy  :  0.8868868868868869\n",
            "\n",
            " Loss : 0.6314223068479812\n",
            "accuracy  :  0.8868868868868869\n",
            "\n",
            " Loss : 0.6297607657420021\n",
            "accuracy  :  0.8878878878878879\n",
            "\n",
            " Loss : 0.6281118828812893\n",
            "accuracy  :  0.8878878878878879\n",
            "\n",
            " Loss : 0.6264755024222697\n",
            "accuracy  :  0.8878878878878879\n",
            "\n",
            " Loss : 0.624851471086881\n",
            "accuracy  :  0.8878878878878879\n",
            "\n",
            " Loss : 0.6232396381103267\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.6216398551900938\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.6200519764361935\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.6184758583225941\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6169113596398123\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6153583414486309\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6138166670349122\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6122862018654781\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6107668135450254\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6092583717740528\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6077607483077667\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6062738169159454\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.60479745334373\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6033315352733232\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6018759422865664\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.6004305558283768\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.5989952591710173\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.5975699373791814\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.5961544772758682\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.5947487674090286\n",
            "accuracy  :  0.8878878878878879\n",
            "\n",
            " Loss : 0.5933526980189634\n",
            "accuracy  :  0.8878878878878879\n",
            "\n",
            " Loss : 0.5919661610064518\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.5905890499015927\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.58922125983334\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.5878626874997148\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.5865132311386754\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.5851727904996308\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.5838412668155789\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.5825185627758551\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.5812045824994765\n",
            "accuracy  :  0.8898898898898899\n",
            "\n",
            " Loss : 0.579899231509063\n",
            "accuracy  :  0.8908908908908909\n",
            "\n",
            " Loss : 0.5786024167053265\n",
            "accuracy  :  0.8908908908908909\n",
            "\n",
            " Loss : 0.577314046342109\n",
            "accuracy  :  0.8918918918918919\n",
            "\n",
            " Loss : 0.5760340300019593\n",
            "accuracy  :  0.8918918918918919\n",
            "\n",
            " Loss : 0.5747622785722311\n",
            "accuracy  :  0.8918918918918919\n",
            "\n",
            " Loss : 0.5734987042216957\n",
            "accuracy  :  0.8918918918918919\n",
            "\n",
            " Loss : 0.5722432203776495\n",
            "accuracy  :  0.8928928928928929\n",
            "\n",
            " Loss : 0.5709957417035096\n",
            "accuracy  :  0.8928928928928929\n",
            "\n",
            " Loss : 0.5697561840768824\n",
            "accuracy  :  0.8928928928928929\n",
            "\n",
            " Loss : 0.5685244645680957\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.5673005014191805\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5660842140232949\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5648755229045768\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5636743496984149\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5624806171321315\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5612942490060611\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5601151701750223\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5589433065301683\n",
            "accuracy  :  0.8958958958958959\n",
            "\n",
            " Loss : 0.5577785849812092\n",
            "accuracy  :  0.8958958958958959\n",
            "\n",
            " Loss : 0.5566209334389973\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5554702807984665\n",
            "accuracy  :  0.8978978978978979\n",
            "\n",
            " Loss : 0.5543265569219181\n",
            "accuracy  :  0.8988988988988988\n",
            "\n",
            " Loss : 0.5531896926226434\n",
            "accuracy  :  0.8998998998998999\n",
            "\n",
            " Loss : 0.5520596196488761\n",
            "accuracy  :  0.8998998998998999\n",
            "\n",
            " Loss : 0.5509362706680687\n",
            "accuracy  :  0.8998998998998999\n",
            "\n",
            " Loss : 0.5498195792514815\n",
            "accuracy  :  0.9019019019019019\n",
            "\n",
            " Loss : 0.5487094798590799\n",
            "accuracy  :  0.9019019019019019\n",
            "\n",
            " Loss : 0.5476059078247318\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5465087993416999\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5454180914484175\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5443337220145478\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5432556297273152\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5421837540781049\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5411180353493227\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5400584146015119\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5390048336607199\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.537957235106108\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5369155622578008\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5358797591649685\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5348497705941389\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5338255420177305\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5328070196028047\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5317941502000332\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5307868813328709\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.529785161186936\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.5287889385995878\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.5277981630497013\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.5268127846476325\n",
            "accuracy  :  0.9049049049049049\n",
            "\n",
            " Loss : 0.5258327541253699\n",
            "accuracy  :  0.9049049049049049\n",
            "\n",
            " Loss : 0.5248580228268701\n",
            "accuracy  :  0.9049049049049049\n",
            "\n",
            " Loss : 0.5238885426985725\n",
            "accuracy  :  0.9049049049049049\n",
            "\n",
            " Loss : 0.5229242662800881\n",
            "accuracy  :  0.9049049049049049\n",
            "\n",
            " Loss : 0.521965146695061\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.5210111376421965\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.5200621933864554\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.5191182687504061\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.5181793191057372\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.5172453003649217\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.5163161689730342\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.5153918818997132\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.5144723966312705\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.5135576711629403\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.512647663991268\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5117423341066345\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5108416409859131\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5099455445852565\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5090540053330127\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5081669841227637\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5072844423064886\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5064063416878449\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5055326445155683\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5046633134769873\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5037983116916507\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5029376027050647\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5020811504825398\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.501228919403142\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.5003808742537497\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4995369802232112\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.49869720289660285\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4978615082495842\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4970298626428505\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.49620223281667786\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.49537858588556155\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.49455888933294423\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.49374311100603296\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.49293121911070376\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.4921231822064897\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.4913189692016548\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.49051854934834827\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.48972189223783935\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.48892896779583206\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.4881397462778555\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.48735419826473214\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.4865722946581182\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.4857940066761191\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.48501930584897496\n",
            "accuracy  :  0.9119119119119119\n",
            "\n",
            " Loss : 0.4842481640148172\n",
            "accuracy  :  0.9119119119119119\n",
            "\n",
            " Loss : 0.4834805533154942\n",
            "accuracy  :  0.9119119119119119\n",
            "\n",
            " Loss : 0.48271644619246334\n",
            "accuracy  :  0.9119119119119119\n",
            "\n",
            " Loss : 0.481955815382751\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.4811986339149767\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.4804448751054413\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.479694512554278\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.4789475201416646\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.47820387202409703\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.4774635426307209\n",
            "accuracy  :  0.913913913913914\n",
            "\n",
            " Loss : 0.47672650665972177\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.47599273907477335\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4752622151015405\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.4745349102242375\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.47381080018224153\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.47308986096675754\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.47237206881753635\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.4716574002196438\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.470945831900279\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.470237340825644\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.46953190419785945\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.4688294994519298\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.46813010425275414\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.4674336964921832\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4667402542861215\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4660497559716736\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4653621801043337\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4646775054552189\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.46399571100834236\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.46331677595793036\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.46264067970577727\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.46196740185864227\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.46129692222568414\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.46062922081593444\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.4599642778358093\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.4593020736866568\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.45864258896234245\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.4579858044468695\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.45733170111203425\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.45668026011511703\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.45603146279660595\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.45538529067795497\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.4547417254593745\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.454100749017654\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.45346234340401675\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.45282649084200594\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.4521931737254007\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.4515623746161633\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.4509340762424154\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.4503082614964429\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.4496849134327309\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.449064015266026\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.4484455503694259\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.4478295022724972\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44721585465941927\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44660459136715513\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44599569638364756\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44538915384604144\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.4447849480389304\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.4441830633926291\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44358348448146856\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44298619602211664\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44239118287192153\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.4417984300272773\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44120792262201436\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44061964592581027\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.44003358534262327\n",
            "accuracy  :  0.91991991991992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWNLVD2RTZzJ"
      },
      "source": [
        "#inference the model\n",
        "\n",
        "y_hat = my_Model.inference(Test_Inputs = cp.array(test_data))\n",
        "\n",
        "y_hat = np.argmax(y_hat, axis = 0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "EU1Us-ijUdlJ",
        "outputId": "16395378-066f-43cd-b269-1f10718742bf"
      },
      "source": [
        "#see what the model has learned\n",
        "\n",
        "test_id = 454\n",
        "\n",
        "print(y_hat[test_id])\n",
        "img =  train2img(train_data[test_id,:,:,:]).reshape((28,28))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5c59f42080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDHf9A3tUvXy"
      },
      "source": [
        "#save the model\n",
        "\n",
        "Utils = Model_Utils()\n",
        "Utils.save(my_Model,'MNIST-Conv')\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn2GprjdXfs2"
      },
      "source": [
        "#load the model\n",
        "\n",
        "loaded_Model = Utils.load('MNIST-Conv')"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}
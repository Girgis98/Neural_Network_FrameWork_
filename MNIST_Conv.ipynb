{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Conv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXV6-X7dAyDy"
      },
      "source": [
        "Remmeber to change runtime to GPU, enjoy using FinalFlow\n",
        "\n",
        "An example of MNIST trained with conv layers using CUDA\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhID-tEcZRof",
        "outputId": "41e0015f-3cb6-4d75-c983-894e2a357d30"
      },
      "source": [
        "!pip install FinalFlow"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: FinalFlow in /usr/local/lib/python3.6/dist-packages (0.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D61-a2MAU8YP"
      },
      "source": [
        "import cupy as cp"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JMSotRkV3hf"
      },
      "source": [
        "\n",
        "from FinalFlow.FinalFlowConv import *\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az68SjnSdQUD"
      },
      "source": [
        "train_path = 'sample_data/mnist_train_small.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U24RGS8UFRW"
      },
      "source": [
        "#load the csv\n",
        "img_data = Image(path = train_path,test_frac = 0.5,val_frac = 0.45,image_size=(28,28), colour = 'gray')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5MPWO1RV7H7"
      },
      "source": [
        "#get trainning data\n",
        "train_data = img_data.train_data\n",
        "train_labels = img_data.train_labels\n",
        "\n",
        "test_data = img_data.train_data\n",
        "test_labels = img_data.train_labels"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "yuAcZO22X5da",
        "outputId": "4bd9a95c-ebc8-408d-d609-2d00048ee5f7"
      },
      "source": [
        "#show some labels and images\n",
        "\n",
        "id = 454\n",
        "\n",
        "print('label :' ,test_labels[id,:])\n",
        "img =  train2img(train_data[id,:,:,:]).reshape((28,28))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label : [9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd6d6d4b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGq95so1WMX9"
      },
      "source": [
        "#define the model\n",
        "Layer1 = Conv(X = np.array(train_data),in_channels = 1, out_channels = 2, kernel_size=8, stride=1, padding= 2  , Activation_fn = 'relu')\n",
        "Layer2 = MaxPool(Layer1.output(),kernel_size=3, stride=1, padding=0)\n",
        "Layer3 = Flatten(Layer2.output())\n",
        "Layer4 = Linear(Input_Matrix = Layer3.output().T,Output_Dimension = 500,Activation_fn = 'relu')\n",
        "Layer5 = Linear(Input_Matrix = Layer4.output(),Output_Dimension = 10,Activation_fn = 'softmax')\n",
        "my_Model = Model([Layer1,Layer2,Layer3,Layer4,Layer5])\n",
        "my_Loss = my_Model.Loss(np.array(train_labels), Layer5.output()).CrossEntropy()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqNbzo16WOvI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98afb7be-6e5b-4918-f6e9-8acfe273b0f3"
      },
      "source": [
        "#parameters\n",
        "learning_rate = 0.065\n",
        "training_epochs = 400\n",
        "epsilon = 0.01\n",
        "#train and visualize\n",
        "opt = my_Model.Optimization(training_epochs, my_Loss, learning_rate, epsilon).GradientDescent()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Loss : 0.10876206220396395\n",
            "accuracy  :  0.09509509509509509\n",
            "\n",
            " Loss : 2.276736022102496\n",
            "accuracy  :  0.0\n",
            "\n",
            " Loss : 2.1848815502811436\n",
            "accuracy  :  0.15615615615615616\n",
            "\n",
            " Loss : 2.1446171645577468\n",
            "accuracy  :  0.2502502502502503\n",
            "\n",
            " Loss : 2.0831652330332835\n",
            "accuracy  :  0.3113113113113113\n",
            "\n",
            " Loss : 2.030754815199078\n",
            "accuracy  :  0.3833833833833834\n",
            "\n",
            " Loss : 1.9889141978768268\n",
            "accuracy  :  0.42242242242242245\n",
            "\n",
            " Loss : 1.9479096822560673\n",
            "accuracy  :  0.4444444444444444\n",
            "\n",
            " Loss : 1.9073656816313647\n",
            "accuracy  :  0.4824824824824825\n",
            "\n",
            " Loss : 1.8695045304217752\n",
            "accuracy  :  0.5255255255255256\n",
            "\n",
            " Loss : 1.8332103809883336\n",
            "accuracy  :  0.5495495495495496\n",
            "\n",
            " Loss : 1.7978198008805664\n",
            "accuracy  :  0.5805805805805806\n",
            "\n",
            " Loss : 1.7640377623918366\n",
            "accuracy  :  0.5985985985985987\n",
            "\n",
            " Loss : 1.731622671984986\n",
            "accuracy  :  0.6256256256256256\n",
            "\n",
            " Loss : 1.7001983536068475\n",
            "accuracy  :  0.6366366366366366\n",
            "\n",
            " Loss : 1.6699709198498829\n",
            "accuracy  :  0.6436436436436437\n",
            "\n",
            " Loss : 1.6409485647871391\n",
            "accuracy  :  0.6546546546546547\n",
            "\n",
            " Loss : 1.6129174032304532\n",
            "accuracy  :  0.6596596596596597\n",
            "\n",
            " Loss : 1.585866107230452\n",
            "accuracy  :  0.6656656656656657\n",
            "\n",
            " Loss : 1.5598357669178367\n",
            "accuracy  :  0.6826826826826827\n",
            "\n",
            " Loss : 1.5347319142523976\n",
            "accuracy  :  0.6956956956956957\n",
            "\n",
            " Loss : 1.5104899273783126\n",
            "accuracy  :  0.7027027027027027\n",
            "\n",
            " Loss : 1.4871130049098418\n",
            "accuracy  :  0.7087087087087087\n",
            "\n",
            " Loss : 1.4645622823907003\n",
            "accuracy  :  0.7177177177177178\n",
            "\n",
            " Loss : 1.4427789960410418\n",
            "accuracy  :  0.7227227227227228\n",
            "\n",
            " Loss : 1.4217405753169807\n",
            "accuracy  :  0.7277277277277278\n",
            "\n",
            " Loss : 1.4014238075873795\n",
            "accuracy  :  0.7337337337337337\n",
            "\n",
            " Loss : 1.3817872543452634\n",
            "accuracy  :  0.7397397397397397\n",
            "\n",
            " Loss : 1.3628005348173458\n",
            "accuracy  :  0.7407407407407407\n",
            "\n",
            " Loss : 1.3444418268901923\n",
            "accuracy  :  0.7457457457457457\n",
            "\n",
            " Loss : 1.3266815430359882\n",
            "accuracy  :  0.7477477477477478\n",
            "\n",
            " Loss : 1.3094910616321558\n",
            "accuracy  :  0.7527527527527528\n",
            "\n",
            " Loss : 1.2928485031718906\n",
            "accuracy  :  0.7547547547547547\n",
            "\n",
            " Loss : 1.2767308106385604\n",
            "accuracy  :  0.7597597597597597\n",
            "\n",
            " Loss : 1.2611138267199073\n",
            "accuracy  :  0.7627627627627628\n",
            "\n",
            " Loss : 1.2459768311165558\n",
            "accuracy  :  0.7707707707707707\n",
            "\n",
            " Loss : 1.2313003077694484\n",
            "accuracy  :  0.7757757757757757\n",
            "\n",
            " Loss : 1.2170642138529602\n",
            "accuracy  :  0.7787787787787788\n",
            "\n",
            " Loss : 1.2032500318199821\n",
            "accuracy  :  0.7797797797797797\n",
            "\n",
            " Loss : 1.1898407384508587\n",
            "accuracy  :  0.7787787787787788\n",
            "\n",
            " Loss : 1.1768195294485568\n",
            "accuracy  :  0.7797797797797797\n",
            "\n",
            " Loss : 1.1641703478973637\n",
            "accuracy  :  0.7837837837837838\n",
            "\n",
            " Loss : 1.1518782792950317\n",
            "accuracy  :  0.7867867867867868\n",
            "\n",
            " Loss : 1.1399289739536256\n",
            "accuracy  :  0.7887887887887888\n",
            "\n",
            " Loss : 1.1283086278637198\n",
            "accuracy  :  0.7897897897897898\n",
            "\n",
            " Loss : 1.1170042548692065\n",
            "accuracy  :  0.7947947947947948\n",
            "\n",
            " Loss : 1.1060034948328699\n",
            "accuracy  :  0.7957957957957958\n",
            "\n",
            " Loss : 1.0952944836742642\n",
            "accuracy  :  0.7977977977977978\n",
            "\n",
            " Loss : 1.0848659573679422\n",
            "accuracy  :  0.7987987987987988\n",
            "\n",
            " Loss : 1.0747072085761373\n",
            "accuracy  :  0.8028028028028028\n",
            "\n",
            " Loss : 1.0648079917463655\n",
            "accuracy  :  0.8048048048048048\n",
            "\n",
            " Loss : 1.0551585420907434\n",
            "accuracy  :  0.8058058058058059\n",
            "\n",
            " Loss : 1.045749567747205\n",
            "accuracy  :  0.8068068068068068\n",
            "\n",
            " Loss : 1.0365721928319693\n",
            "accuracy  :  0.8048048048048048\n",
            "\n",
            " Loss : 1.0276179419552327\n",
            "accuracy  :  0.8058058058058059\n",
            "\n",
            " Loss : 1.01887873316897\n",
            "accuracy  :  0.8058058058058059\n",
            "\n",
            " Loss : 1.010346846803863\n",
            "accuracy  :  0.8088088088088088\n",
            "\n",
            " Loss : 1.0020149054471563\n",
            "accuracy  :  0.8098098098098098\n",
            "\n",
            " Loss : 0.9938758640498008\n",
            "accuracy  :  0.8118118118118118\n",
            "\n",
            " Loss : 0.9859229902107802\n",
            "accuracy  :  0.8118118118118118\n",
            "\n",
            " Loss : 0.9781498452785001\n",
            "accuracy  :  0.8168168168168168\n",
            "\n",
            " Loss : 0.9705502720780186\n",
            "accuracy  :  0.8188188188188188\n",
            "\n",
            " Loss : 0.9631183806976844\n",
            "accuracy  :  0.8188188188188188\n",
            "\n",
            " Loss : 0.955848533630118\n",
            "accuracy  :  0.8188188188188188\n",
            "\n",
            " Loss : 0.9487353341330811\n",
            "accuracy  :  0.8178178178178178\n",
            "\n",
            " Loss : 0.9417736147760849\n",
            "accuracy  :  0.8188188188188188\n",
            "\n",
            " Loss : 0.9349584253381212\n",
            "accuracy  :  0.8188188188188188\n",
            "\n",
            " Loss : 0.9282850220959038\n",
            "accuracy  :  0.8228228228228228\n",
            "\n",
            " Loss : 0.9217488580008533\n",
            "accuracy  :  0.8238238238238238\n",
            "\n",
            " Loss : 0.9153455729182932\n",
            "accuracy  :  0.8248248248248248\n",
            "\n",
            " Loss : 0.9090709845540597\n",
            "accuracy  :  0.8248248248248248\n",
            "\n",
            " Loss : 0.9029210800837968\n",
            "accuracy  :  0.8258258258258259\n",
            "\n",
            " Loss : 0.8968920080119647\n",
            "accuracy  :  0.8258258258258259\n",
            "\n",
            " Loss : 0.8909800704034181\n",
            "accuracy  :  0.8268268268268268\n",
            "\n",
            " Loss : 0.8851817156472213\n",
            "accuracy  :  0.8278278278278278\n",
            "\n",
            " Loss : 0.8794935315914978\n",
            "accuracy  :  0.8318318318318318\n",
            "\n",
            " Loss : 0.8739122390135742\n",
            "accuracy  :  0.8318318318318318\n",
            "\n",
            " Loss : 0.8684346854753253\n",
            "accuracy  :  0.8318318318318318\n",
            "\n",
            " Loss : 0.8630578394975597\n",
            "accuracy  :  0.8318318318318318\n",
            "\n",
            " Loss : 0.8577787850051185\n",
            "accuracy  :  0.8318318318318318\n",
            "\n",
            " Loss : 0.8525947160639005\n",
            "accuracy  :  0.8318318318318318\n",
            "\n",
            " Loss : 0.8475029319018864\n",
            "accuracy  :  0.8328328328328328\n",
            "\n",
            " Loss : 0.8425008321845672\n",
            "accuracy  :  0.8348348348348348\n",
            "\n",
            " Loss : 0.8375859125343912\n",
            "accuracy  :  0.8358358358358359\n",
            "\n",
            " Loss : 0.8327557602818396\n",
            "accuracy  :  0.8378378378378378\n",
            "\n",
            " Loss : 0.8280080504273463\n",
            "accuracy  :  0.8388388388388388\n",
            "\n",
            " Loss : 0.8233405418026499\n",
            "accuracy  :  0.8398398398398398\n",
            "\n",
            " Loss : 0.8187510734255002\n",
            "accuracy  :  0.8398398398398398\n",
            "\n",
            " Loss : 0.8142375610374701\n",
            "accuracy  :  0.8408408408408409\n",
            "\n",
            " Loss : 0.8097979938139327\n",
            "accuracy  :  0.8418418418418419\n",
            "\n",
            " Loss : 0.8054304312368192\n",
            "accuracy  :  0.8418418418418419\n",
            "\n",
            " Loss : 0.801133000120386\n",
            "accuracy  :  0.8418418418418419\n",
            "\n",
            " Loss : 0.796903891780838\n",
            "accuracy  :  0.8418418418418419\n",
            "\n",
            " Loss : 0.7927413593425151\n",
            "accuracy  :  0.8418418418418419\n",
            "\n",
            " Loss : 0.7886437151739887\n",
            "accuracy  :  0.8418418418418419\n",
            "\n",
            " Loss : 0.7846093284472344\n",
            "accuracy  :  0.8438438438438438\n",
            "\n",
            " Loss : 0.7806366228132164\n",
            "accuracy  :  0.8458458458458459\n",
            "\n",
            " Loss : 0.7767240741875306\n",
            "accuracy  :  0.8458458458458459\n",
            "\n",
            " Loss : 0.7728702086400618\n",
            "accuracy  :  0.8478478478478478\n",
            "\n",
            " Loss : 0.7690736003831243\n",
            "accuracy  :  0.8488488488488488\n",
            "\n",
            " Loss : 0.7653328698530548\n",
            "accuracy  :  0.8488488488488488\n",
            "\n",
            " Loss : 0.7616466818805132\n",
            "accuracy  :  0.8498498498498499\n",
            "\n",
            " Loss : 0.7580137439449274\n",
            "accuracy  :  0.8498498498498499\n",
            "\n",
            " Loss : 0.75443280450871\n",
            "accuracy  :  0.8508508508508509\n",
            "\n",
            " Loss : 0.7509026514271014\n",
            "accuracy  :  0.8528528528528528\n",
            "\n",
            " Loss : 0.7474221104297369\n",
            "accuracy  :  0.8528528528528528\n",
            "\n",
            " Loss : 0.7439900436702948\n",
            "accuracy  :  0.8538538538538538\n",
            "\n",
            " Loss : 0.74060534834082\n",
            "accuracy  :  0.8548548548548549\n",
            "\n",
            " Loss : 0.7372669553474931\n",
            "accuracy  :  0.8568568568568569\n",
            "\n",
            " Loss : 0.7339738280447791\n",
            "accuracy  :  0.8578578578578578\n",
            "\n",
            " Loss : 0.7307249610250471\n",
            "accuracy  :  0.8588588588588588\n",
            "\n",
            " Loss : 0.7275193789609006\n",
            "accuracy  :  0.8588588588588588\n",
            "\n",
            " Loss : 0.72435613549762\n",
            "accuracy  :  0.8598598598598599\n",
            "\n",
            " Loss : 0.7212343121932695\n",
            "accuracy  :  0.8598598598598599\n",
            "\n",
            " Loss : 0.7181530175041472\n",
            "accuracy  :  0.8598598598598599\n",
            "\n",
            " Loss : 0.7151113858133982\n",
            "accuracy  :  0.8598598598598599\n",
            "\n",
            " Loss : 0.7121085765007021\n",
            "accuracy  :  0.8618618618618619\n",
            "\n",
            " Loss : 0.7091437730510737\n",
            "accuracy  :  0.8628628628628628\n",
            "\n",
            " Loss : 0.7062161822009042\n",
            "accuracy  :  0.8628628628628628\n",
            "\n",
            " Loss : 0.7033250331194825\n",
            "accuracy  :  0.8648648648648649\n",
            "\n",
            " Loss : 0.7004695766243205\n",
            "accuracy  :  0.8648648648648649\n",
            "\n",
            " Loss : 0.697649084428702\n",
            "accuracy  :  0.8648648648648649\n",
            "\n",
            " Loss : 0.6948628484199507\n",
            "accuracy  :  0.8648648648648649\n",
            "\n",
            " Loss : 0.6921101799669951\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.6893904092558761\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.6867028846519171\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.684046972087334\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.6814220544731389\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.678827531134232\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.6762628172666457\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.67372734341595\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.671220554975876\n",
            "accuracy  :  0.8658658658658659\n",
            "\n",
            " Loss : 0.668741911706268\n",
            "accuracy  :  0.8668668668668669\n",
            "\n",
            " Loss : 0.66629088726951\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.6638669687846229\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.6614696563982574\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.6590984628718574\n",
            "accuracy  :  0.8678678678678678\n",
            "\n",
            " Loss : 0.6567529131842952\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.6544325441493146\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.652136904047152\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.6498655522697353\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.6476180589788867\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.6453940047769846\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.6431929803895645\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.6410145863593635\n",
            "accuracy  :  0.8688688688688688\n",
            "\n",
            " Loss : 0.6388584327513337\n",
            "accuracy  :  0.8698698698698699\n",
            "\n",
            " Loss : 0.6367241388681789\n",
            "accuracy  :  0.8708708708708709\n",
            "\n",
            " Loss : 0.6346113329759769\n",
            "accuracy  :  0.8728728728728729\n",
            "\n",
            " Loss : 0.6325196520394847\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.6304487414667282\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.6283982548625087\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.6263678537904627\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.62435720754334\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.6223659929211705\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.6203938940170082\n",
            "accuracy  :  0.8738738738738738\n",
            "\n",
            " Loss : 0.6184406020099587\n",
            "accuracy  :  0.8768768768768769\n",
            "\n",
            " Loss : 0.6165058149652002\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.614589237640732\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6126905813005846\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6108095635342474\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6089459080820726\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6070993446664306\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6052696088283945\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6034564417697509\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.6016595902001302\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.5998788061890712\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.5981138470228328\n",
            "accuracy  :  0.8788788788788788\n",
            "\n",
            " Loss : 0.5963644750657783\n",
            "accuracy  :  0.8798798798798799\n",
            "\n",
            " Loss : 0.5946304576261638\n",
            "accuracy  :  0.8798798798798799\n",
            "\n",
            " Loss : 0.5929115668261693\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.5912075794760172\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.5895182769520305\n",
            "accuracy  :  0.8808808808808809\n",
            "\n",
            " Loss : 0.5878434450784891\n",
            "accuracy  :  0.8818818818818819\n",
            "\n",
            " Loss : 0.5861828740131443\n",
            "accuracy  :  0.8828828828828829\n",
            "\n",
            " Loss : 0.5845363581362655\n",
            "accuracy  :  0.8838838838838838\n",
            "\n",
            " Loss : 0.582903695943088\n",
            "accuracy  :  0.8838838838838838\n",
            "\n",
            " Loss : 0.5812846899395469\n",
            "accuracy  :  0.8838838838838838\n",
            "\n",
            " Loss : 0.5796791465411744\n",
            "accuracy  :  0.8838838838838838\n",
            "\n",
            " Loss : 0.5780868759750573\n",
            "accuracy  :  0.8838838838838838\n",
            "\n",
            " Loss : 0.5765076921847404\n",
            "accuracy  :  0.8838838838838838\n",
            "\n",
            " Loss : 0.5749414127379779\n",
            "accuracy  :  0.8848848848848849\n",
            "\n",
            " Loss : 0.5733878587372323\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.5718468547328259\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.5703182286386566\n",
            "accuracy  :  0.8858858858858859\n",
            "\n",
            " Loss : 0.5688018116503846\n",
            "accuracy  :  0.8868868868868869\n",
            "\n",
            " Loss : 0.5672974381660134\n",
            "accuracy  :  0.8868868868868869\n",
            "\n",
            " Loss : 0.5658049457087773\n",
            "accuracy  :  0.8868868868868869\n",
            "\n",
            " Loss : 0.5643241748522616\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.5628549691476811\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.5613971750532406\n",
            "accuracy  :  0.8888888888888888\n",
            "\n",
            " Loss : 0.559950641865513\n",
            "accuracy  :  0.8908908908908909\n",
            "\n",
            " Loss : 0.558515221652765\n",
            "accuracy  :  0.8908908908908909\n",
            "\n",
            " Loss : 0.5570907691901686\n",
            "accuracy  :  0.8918918918918919\n",
            "\n",
            " Loss : 0.5556771418968337\n",
            "accuracy  :  0.8918918918918919\n",
            "\n",
            " Loss : 0.5542741997746051\n",
            "accuracy  :  0.8928928928928929\n",
            "\n",
            " Loss : 0.5528818053485658\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.5514998236091893\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.5501281219560912\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.5487665701433261\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.5474150402261818\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.546073406509422\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.5447415454969343\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.543419335842734\n",
            "accuracy  :  0.8938938938938938\n",
            "\n",
            " Loss : 0.5421066583032894\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5408033956911157\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5395094328296121\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5382246565090903\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5369489554439666\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5356822202310776\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5344243433090864\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5331752189189466\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5319347430653912\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5307028134794148\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.529479329581721\n",
            "accuracy  :  0.8948948948948949\n",
            "\n",
            " Loss : 0.5282641924471047\n",
            "accuracy  :  0.8958958958958959\n",
            "\n",
            " Loss : 0.5270573047697426\n",
            "accuracy  :  0.8958958958958959\n",
            "\n",
            " Loss : 0.5258585708293634\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5246678964582726\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5234851890092074\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5223103573239947\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5211433117029939\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5199839638752946\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5188322269696544\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5176880154861493\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5165512452685216\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.5154218334772017\n",
            "accuracy  :  0.8968968968968969\n",
            "\n",
            " Loss : 0.514299698562985\n",
            "accuracy  :  0.8978978978978979\n",
            "\n",
            " Loss : 0.5131847602413473\n",
            "accuracy  :  0.8978978978978979\n",
            "\n",
            " Loss : 0.512076939467379\n",
            "accuracy  :  0.8988988988988988\n",
            "\n",
            " Loss : 0.5109761584113206\n",
            "accuracy  :  0.9019019019019019\n",
            "\n",
            " Loss : 0.5098823404346838\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5087954100669403\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5077152929827637\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5066419159798096\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.505575206957017\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.504515094893418\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5034615098274431\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5024143828367061\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5013736460182566\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.5003392324692886\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.49931107626829113\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.49828911245663005\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.4972732770205488\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.49626350687357823\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.49525973983934335\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.49426191463475627\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.4932699708535872\n",
            "accuracy  :  0.9029029029029029\n",
            "\n",
            " Loss : 0.4922838489504008\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.4913034902248511\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.4903288368063231\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.4893598316389141\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.48839641846674425\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.4874385418195903\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.48648614699883036\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.48553918006369656\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.4845975878178231\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.4836613177960858\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.48273031825172363\n",
            "accuracy  :  0.9039039039039038\n",
            "\n",
            " Loss : 0.481804538143736\n",
            "accuracy  :  0.9049049049049049\n",
            "\n",
            " Loss : 0.4808839271245488\n",
            "accuracy  :  0.9049049049049049\n",
            "\n",
            " Loss : 0.47996843552794205\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.4790580143572333\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.47815261527371045\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.47725219058530627\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.47635669323551133\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.475466076792517\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.4745802954385846\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.4736993039596338\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.47282305773504657\n",
            "accuracy  :  0.9059059059059059\n",
            "\n",
            " Loss : 0.47195151272767993\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4710846254740827\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.47022235307491334\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.46936465318555043\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4685114840068949\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.46766280427635687\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4668185732590239\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4659787507390059\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4651432970109536\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4643121728717443\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.463485339612334\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4626627590097685\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4618443933193536\n",
            "accuracy  :  0.9069069069069069\n",
            "\n",
            " Loss : 0.4610302052669773\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.4602201580415832\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.45941421528778936\n",
            "accuracy  :  0.9079079079079079\n",
            "\n",
            " Loss : 0.4586123410986512\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4578145000085637\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4570206569863011\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4562307774281895\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4554448271514106\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.45466277238743263\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.45388457977556684\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4531102163566455\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.4523396495668195\n",
            "accuracy  :  0.908908908908909\n",
            "\n",
            " Loss : 0.45157284723147206\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.45080977755924767\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.4500504091361915\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.44929471091999856\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.4485426522343694\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.4477942027634703\n",
            "accuracy  :  0.9099099099099099\n",
            "\n",
            " Loss : 0.4470493325464954\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.4463080119723292\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.44557021177430667\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.444835903025068\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.4441050571315093\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.44337764582982214\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.44265364118062506\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.44193301556418124\n",
            "accuracy  :  0.9109109109109109\n",
            "\n",
            " Loss : 0.4412157416757028\n",
            "accuracy  :  0.9119119119119119\n",
            "\n",
            " Loss : 0.440501792520739\n",
            "accuracy  :  0.9119119119119119\n",
            "\n",
            " Loss : 0.43979114141064707\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43908376195814275\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43837962807293057\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43767871395741115\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43698099410246355\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.4362864432833028\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43559503655540893\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.4349067492505273\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43422155697273906\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43353943559459895\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43286036125334054\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43218431034714616\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43151125953148184\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.4308411857154941\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.43017406605846886\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.42950987796635026\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.42884859908831907\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.428190207313428\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.4275346807672952\n",
            "accuracy  :  0.9129129129129129\n",
            "\n",
            " Loss : 0.42688199780885183\n",
            "accuracy  :  0.913913913913914\n",
            "\n",
            " Loss : 0.4262321370271452\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.42558507723819483\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4249407974819014\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.42429927701900605\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4236604953281014\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.42302443210269075\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4223910672482963\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.42176038087961454\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4211323533177187\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4205069650873061\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4198841969139905\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4192640297216394\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4186464446297524\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.41803142295088375\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4174189461881051\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4168089960325099\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4162015543607565\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.41559660323265146\n",
            "accuracy  :  0.914914914914915\n",
            "\n",
            " Loss : 0.4149941248887707\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.4143941017481189\n",
            "accuracy  :  0.9159159159159159\n",
            "\n",
            " Loss : 0.413796516405825\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.41320135163087474\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.41260859036387876\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.41201821571487507\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.4114302109611667\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.41084455954519244\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.41026124507243084\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.40968025130933633\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.4091015621813081\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.40852516177068954\n",
            "accuracy  :  0.9169169169169169\n",
            "\n",
            " Loss : 0.40795103431479823\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.40737916420398684\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.406809535979733\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.40624213433275863\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4056769441011778\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4051139502686723\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4045531379626954\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4039944924527018\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.40343799914840506\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.402883643598061\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.40233141148677554\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4017812886348398\n",
            "accuracy  :  0.9179179179179179\n",
            "\n",
            " Loss : 0.4012332609960881\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.4006873146562813\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.400143435831514\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.39960161086664436\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.39906182623374853\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.39852406853059585\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.3979883244791481\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.39745458092407976\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.3969228248313194\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.39639304328661323\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.3958652234941089\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.39533935277495974\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.3948154185659487\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.394293408418133\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.3937733099955076\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.3932551110736874\n",
            "accuracy  :  0.918918918918919\n",
            "\n",
            " Loss : 0.39273879953860896\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.3922243633852502\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.3917117907163683\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.39120106974125557\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.39069218877451267\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.3901851362348391\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.38967990064384106\n",
            "accuracy  :  0.91991991991992\n",
            "\n",
            " Loss : 0.38917647062485544\n",
            "accuracy  :  0.9209209209209209\n",
            "\n",
            " Loss : 0.3886748349017901\n",
            "accuracy  :  0.9209209209209209\n",
            "\n",
            " Loss : 0.3881749822979813\n",
            "accuracy  :  0.9209209209209209\n",
            "\n",
            " Loss : 0.3876769017350656\n",
            "accuracy  :  0.9209209209209209\n",
            "\n",
            " Loss : 0.38718058223186874\n",
            "accuracy  :  0.9209209209209209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWNLVD2RTZzJ"
      },
      "source": [
        "#inference the model\n",
        "\n",
        "y_hat = my_Model.inference(Test_Inputs = cp.array(test_data))\n",
        "\n",
        "y_hat = np.argmax(y_hat, axis = 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "EU1Us-ijUdlJ",
        "outputId": "99738fca-3ec3-45e2-ac37-cfc3058f0667"
      },
      "source": [
        "#see what the model has learned\n",
        "\n",
        "test_id = 30\n",
        "\n",
        "print('label :' ,y_hat[test_id])\n",
        "img =  train2img(train_data[test_id,:,:,:]).reshape((28,28))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label : 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd6091aa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDHf9A3tUvXy"
      },
      "source": [
        "#save the model\n",
        "\n",
        "Utils = Model_Utils()\n",
        "Utils.save(my_Model,'MNIST-Conv')\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn2GprjdXfs2"
      },
      "source": [
        "#load the model\n",
        "\n",
        "loaded_Model = Utils.load('MNIST-Conv')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwO5hX9gZOl3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
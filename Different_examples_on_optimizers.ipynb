{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Different_examples_on_optimizers",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wYhB-DlJ2eNA",
        "outputId": "c6360642-ba24-45e6-9f77-47f4d6f790d1"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1]]\r\n",
        "Y = [1, 1, 1, -1]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "Y = np.reshape(Y, (1, 4))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1, False]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.00002\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes, 2))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "}\r\n",
        "\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros((n_classes, 1))\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).LogisticRegressionSigmoid()\r\n",
        "opt = my_Model.Optimization(20, my_Loss, learning_rate, epsilon,'Batch').GradientDescent()\r\n",
        "# my_Model.split_Batches()\r\n",
        "my_Model.Evaluate(X, Y, True)\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[-1  1 -1  1]\n",
            " [-1 -1  1  1]]\n",
            "Y : [[ 1  1  1 -1]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.250001 -0.250001]] \n",
            " bias : \n",
            " [[0.249001]]\n",
            "\n",
            " Loss : [[0.69114918]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "//////////// end of iteration\n",
            "epoch : 1 \n",
            " weights : \n",
            "[[-0.250001 -0.250001]] \n",
            " bias : \n",
            " [[0.249001]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.48206816 -0.48206816]] \n",
            " bias : \n",
            " [[0.48014483]]\n",
            "\n",
            " Loss : [[0.52716048]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "//////////// end of iteration\n",
            "epoch : 2 \n",
            " weights : \n",
            "[[-0.48206816 -0.48206816]] \n",
            " bias : \n",
            " [[0.48014483]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.64390456 -0.64390456]] \n",
            " bias : \n",
            " [[0.64160919]]\n",
            "\n",
            " Loss : [[0.41227929]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 3 \n",
            " weights : \n",
            "[[-0.64390456 -0.64390456]] \n",
            " bias : \n",
            " [[0.64160919]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.7693909 -0.7693909]] \n",
            " bias : \n",
            " [[0.7670339]]\n",
            "\n",
            " Loss : [[0.34928316]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 4 \n",
            " weights : \n",
            "[[-0.7693909 -0.7693909]] \n",
            " bias : \n",
            " [[0.7670339]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.87545582 -0.87545582]] \n",
            " bias : \n",
            " [[0.87314162]]\n",
            "\n",
            " Loss : [[0.30808768]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 5 \n",
            " weights : \n",
            "[[-0.87545582 -0.87545582]] \n",
            " bias : \n",
            " [[0.87314162]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.96869856 -0.96869856]] \n",
            " bias : \n",
            " [[0.96645601]]\n",
            "\n",
            " Loss : [[0.27757352]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 6 \n",
            " weights : \n",
            "[[-0.96869856 -0.96869856]] \n",
            " bias : \n",
            " [[0.96645601]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.05250848 -1.05250848]] \n",
            " bias : \n",
            " [[1.05034293]]\n",
            "\n",
            " Loss : [[0.25352997]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 7 \n",
            " weights : \n",
            "[[-1.05250848 -1.05250848]] \n",
            " bias : \n",
            " [[1.05034293]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.12896764 -1.12896764]] \n",
            " bias : \n",
            " [[1.12687679]]\n",
            "\n",
            " Loss : [[0.23386014]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 8 \n",
            " weights : \n",
            "[[-1.12896764 -1.12896764]] \n",
            " bias : \n",
            " [[1.12687679]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.19947818 -1.19947818]] \n",
            " bias : \n",
            " [[1.19745716]]\n",
            "\n",
            " Loss : [[0.21734269]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 9 \n",
            " weights : \n",
            "[[-1.19947818 -1.19947818]] \n",
            " bias : \n",
            " [[1.19745716]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.26504106 -1.26504106]] \n",
            " bias : \n",
            " [[1.26308422]]\n",
            "\n",
            " Loss : [[0.20320064]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 10 \n",
            " weights : \n",
            "[[-1.26504106 -1.26504106]] \n",
            " bias : \n",
            " [[1.26308422]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.32640165 -1.32640165]] \n",
            " bias : \n",
            " [[1.32450335]]\n",
            "\n",
            " Loss : [[0.19090901]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 11 \n",
            " weights : \n",
            "[[-1.32640165 -1.32640165]] \n",
            " bias : \n",
            " [[1.32450335]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.38413345 -1.38413345]] \n",
            " bias : \n",
            " [[1.38228838]]\n",
            "\n",
            " Loss : [[0.18009666]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 12 \n",
            " weights : \n",
            "[[-1.38413345 -1.38413345]] \n",
            " bias : \n",
            " [[1.38228838]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.43868947 -1.43868947]] \n",
            " bias : \n",
            " [[1.43689275]]\n",
            "\n",
            " Loss : [[0.17049166]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 13 \n",
            " weights : \n",
            "[[-1.43868947 -1.43868947]] \n",
            " bias : \n",
            " [[1.43689275]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.4904353 -1.4904353]] \n",
            " bias : \n",
            " [[1.48868254]]\n",
            "\n",
            " Loss : [[0.16188893]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 14 \n",
            " weights : \n",
            "[[-1.4904353 -1.4904353]] \n",
            " bias : \n",
            " [[1.48868254]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.53967141 -1.53967141]] \n",
            " bias : \n",
            " [[1.53795866]]\n",
            "\n",
            " Loss : [[0.15413007]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 15 \n",
            " weights : \n",
            "[[-1.53967141 -1.53967141]] \n",
            " bias : \n",
            " [[1.53795866]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.58664851 -1.58664851]] \n",
            " bias : \n",
            " [[1.58497225]]\n",
            "\n",
            " Loss : [[0.14709022]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 16 \n",
            " weights : \n",
            "[[-1.58664851 -1.58664851]] \n",
            " bias : \n",
            " [[1.58497225]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.63157854 -1.63157854]] \n",
            " bias : \n",
            " [[1.62993564]]\n",
            "\n",
            " Loss : [[0.1406693]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 17 \n",
            " weights : \n",
            "[[-1.63157854 -1.63157854]] \n",
            " bias : \n",
            " [[1.62993564]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.67464273 -1.67464273]] \n",
            " bias : \n",
            " [[1.6730304]]\n",
            "\n",
            " Loss : [[0.13478588]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 18 \n",
            " weights : \n",
            "[[-1.67464273 -1.67464273]] \n",
            " bias : \n",
            " [[1.6730304]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.71599758 -1.71599758]] \n",
            " bias : \n",
            " [[1.71441332]]\n",
            "\n",
            " Loss : [[0.12937286]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 19 \n",
            " weights : \n",
            "[[-1.71599758 -1.71599758]] \n",
            " bias : \n",
            " [[1.71441332]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.7557794 -1.7557794]] \n",
            " bias : \n",
            " [[1.75422098]]\n",
            "\n",
            " Loss : [[0.12437432]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 20 \n",
            " weights : \n",
            "[[-1.7557794 -1.7557794]] \n",
            " bias : \n",
            " [[1.75422098]]\n",
            "Y_Hat : [[0.99486118 0.8524844  0.8524844  0.14712407]]\n",
            " Loss : [[0.1197432]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r6rQo8Nw2yE-",
        "outputId": "92910d87-8574-4d02-f9e7-e37ce4e014d1"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1]]\r\n",
        "Y = [1, 1, 1, -1]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "Y = np.reshape(Y, (1, 4))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1, False]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.00002\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes, 2))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "}\r\n",
        "\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros((n_classes, 1))\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).LogisticRegressionSigmoid()\r\n",
        "opt = my_Model.Optimization(20, my_Loss, learning_rate, epsilon,'minibatch').GradientDescent()\r\n",
        "# my_Model.split_Batches()\r\n",
        "my_Model.Evaluate(X, Y, True)\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[-1  1 -1  1]\n",
            " [-1 -1  1  1]]\n",
            "Y : [[ 1  1  1 -1]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.499002 -0.499002]] \n",
            " bias : \n",
            " [[0.499002]]\n",
            "\n",
            " Loss : [[0.69114918]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANT0lEQVR4nO3cYYjkd33H8ffHO1NpjKb0VpC706T00njYQtIlTRFqirZc8uDugUXuIFgleGAbKVWEFEuU+MiGWhCu1ZOKVdAYfSALntwDjQTEC7chNXgXItvTeheFrDHNk6Ax7bcPZtKdrneZf3Zndy/7fb/gYP7/+e3Mlx97752d2ZlUFZKk7e8VWz2AJGlzGHxJasLgS1ITBl+SmjD4ktSEwZekJqYGP8lnkzyZ5PuXuD5JPplkKcmjSW6c/ZiSpPUa8gj/c8CBF7n+VmDf+N9R4F/WP5YkadamBr+qHgR+/iJLDgGfr5FTwNVJXj+rASVJs7FzBrexGzg/cXxhfO6nqxcmOcrotwCuvPLKP7z++utncPeS1MfDDz/8s6qaW8vXziL4g1XVceA4wPz8fC0uLm7m3UvSy16S/1zr187ir3SeAPZOHO8Zn5MkXUZmEfwF4F3jv9a5GXimqn7t6RxJ0taa+pROki8BtwC7klwAPgK8EqCqPgWcAG4DloBngfds1LCSpLWbGvyqOjLl+gL+emYTSZI2hO+0laQmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqYlBwU9yIMnjSZaS3HWR69+Q5IEkjyR5NMltsx9VkrQeU4OfZAdwDLgV2A8cSbJ/1bK/B+6vqhuAw8A/z3pQSdL6DHmEfxOwVFXnquo54D7g0Ko1BbxmfPm1wE9mN6IkaRaGBH83cH7i+ML43KSPArcnuQCcAN5/sRtKcjTJYpLF5eXlNYwrSVqrWb1oewT4XFXtAW4DvpDk1267qo5X1XxVzc/Nzc3oriVJQwwJ/hPA3onjPeNzk+4A7geoqu8CrwJ2zWJASdJsDAn+aWBfkmuTXMHoRdmFVWt+DLwNIMmbGAXf52wk6TIyNfhV9TxwJ3ASeIzRX+OcSXJPkoPjZR8E3pvke8CXgHdXVW3U0JKkl27nkEVVdYLRi7GT5+6euHwWeMtsR5MkzZLvtJWkJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNTEo+EkOJHk8yVKSuy6x5p1JziY5k+SLsx1TkrReO6ctSLIDOAb8GXABOJ1koarOTqzZB/wd8JaqejrJ6zZqYEnS2gx5hH8TsFRV56rqOeA+4NCqNe8FjlXV0wBV9eRsx5QkrdeQ4O8Gzk8cXxifm3QdcF2S7yQ5leTAxW4oydEki0kWl5eX1zaxJGlNZvWi7U5gH3ALcAT4TJKrVy+qquNVNV9V83NzczO6a0nSEEOC/wSwd+J4z/jcpAvAQlX9qqp+CPyA0Q8ASdJlYkjwTwP7klyb5ArgMLCwas3XGD26J8kuRk/xnJvhnJKkdZoa/Kp6HrgTOAk8BtxfVWeS3JPk4HjZSeCpJGeBB4APVdVTGzW0JOmlS1VtyR3Pz8/X4uLilty3JL1cJXm4qubX8rW+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yYEkjydZSnLXi6x7R5JKMj+7ESVJszA1+El2AMeAW4H9wJEk+y+y7irgb4CHZj2kJGn9hjzCvwlYqqpzVfUccB9w6CLrPgZ8HPjFDOeTJM3IkODvBs5PHF8Yn/s/SW4E9lbV11/shpIcTbKYZHF5efklDytJWrt1v2ib5BXAJ4APTltbVcerar6q5ufm5tZ715Kkl2BI8J8A9k4c7xmfe8FVwJuBbyf5EXAzsOALt5J0eRkS/NPAviTXJrkCOAwsvHBlVT1TVbuq6pqqugY4BRysqsUNmViStCZTg19VzwN3AieBx4D7q+pMknuSHNzoASVJs7FzyKKqOgGcWHXu7kusvWX9Y0mSZs132kpSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmhgU/CQHkjyeZCnJXRe5/gNJziZ5NMk3k7xx9qNKktZjavCT7ACOAbcC+4EjSfavWvYIMF9VfwB8FfiHWQ8qSVqfIY/wbwKWqupcVT0H3AccmlxQVQ9U1bPjw1PAntmOKUlaryHB3w2cnzi+MD53KXcA37jYFUmOJllMsri8vDx8SknSus30RdsktwPzwL0Xu76qjlfVfFXNz83NzfKuJUlT7Byw5glg78TxnvG5/yfJ24EPA2+tql/OZjxJ0qwMeYR/GtiX5NokVwCHgYXJBUluAD4NHKyqJ2c/piRpvaYGv6qeB+4ETgKPAfdX1Zkk9yQ5OF52L/Bq4CtJ/j3JwiVuTpK0RYY8pUNVnQBOrDp398Tlt894LknSjPlOW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpoYFPwkB5I8nmQpyV0Xuf43knx5fP1DSa6Z9aCSpPWZGvwkO4BjwK3AfuBIkv2rlt0BPF1Vvwv8E/DxWQ8qSVqfIY/wbwKWqupcVT0H3AccWrXmEPBv48tfBd6WJLMbU5K0XjsHrNkNnJ84vgD80aXWVNXzSZ4Bfhv42eSiJEeBo+PDXyb5/lqG3oZ2sWqvGnMvVrgXK9yLFb+31i8cEvyZqarjwHGAJItVNb+Z93+5ci9WuBcr3IsV7sWKJItr/dohT+k8AeydON4zPnfRNUl2Aq8FnlrrUJKk2RsS/NPAviTXJrkCOAwsrFqzAPzl+PJfAN+qqprdmJKk9Zr6lM74Ofk7gZPADuCzVXUmyT3AYlUtAP8KfCHJEvBzRj8Upjm+jrm3G/dihXuxwr1Y4V6sWPNexAfiktSD77SVpCYMviQ1seHB92MZVgzYiw8kOZvk0STfTPLGrZhzM0zbi4l170hSSbbtn+QN2Ysk7xx/b5xJ8sXNnnGzDPg/8oYkDyR5ZPz/5LatmHOjJflskicv9V6ljHxyvE+PJrlx0A1X1Yb9Y/Qi738AvwNcAXwP2L9qzV8BnxpfPgx8eSNn2qp/A/fiT4HfHF9+X+e9GK+7CngQOAXMb/XcW/h9sQ94BPit8fHrtnruLdyL48D7xpf3Az/a6rk3aC/+BLgR+P4lrr8N+AYQ4GbgoSG3u9GP8P1YhhVT96KqHqiqZ8eHpxi952E7GvJ9AfAxRp/L9IvNHG6TDdmL9wLHquppgKp6cpNn3CxD9qKA14wvvxb4ySbOt2mq6kFGf/F4KYeAz9fIKeDqJK+fdrsbHfyLfSzD7kutqarngRc+lmG7GbIXk+5g9BN8O5q6F+NfUfdW1dc3c7AtMOT74jrguiTfSXIqyYFNm25zDdmLjwK3J7kAnADevzmjXXZeak+ATf5oBQ2T5HZgHnjrVs+yFZK8AvgE8O4tHuVysZPR0zq3MPqt78Ekv19V/7WlU22NI8Dnquofk/wxo/f/vLmq/merB3s52OhH+H4sw4ohe0GStwMfBg5W1S83abbNNm0vrgLeDHw7yY8YPUe5sE1fuB3yfXEBWKiqX1XVD4EfMPoBsN0M2Ys7gPsBquq7wKsYfbBaN4N6stpGB9+PZVgxdS+S3AB8mlHst+vztDBlL6rqmaraVVXXVNU1jF7POFhVa/7QqMvYkP8jX2P06J4kuxg9xXNuM4fcJEP24sfA2wCSvIlR8Jc3dcrLwwLwrvFf69wMPFNVP532RRv6lE5t3McyvOwM3It7gVcDXxm/bv3jqjq4ZUNvkIF70cLAvTgJ/HmSs8B/Ax+qqm33W/DAvfgg8Jkkf8voBdx3b8cHiEm+xOiH/K7x6xUfAV4JUFWfYvT6xW3AEvAs8J5Bt7sN90qSdBG+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElq4n8BzPZcum6w2goAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-0.68165097 -0.68165097]] \n",
            " bias : \n",
            " [[0.68165097]]\n",
            "\n",
            " Loss : [[0.20073708]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 1 \n",
            " weights : \n",
            "[[-0.68165097 -0.68165097]] \n",
            " bias : \n",
            " [[0.68165097]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.79608508 -0.79608508]] \n",
            " bias : \n",
            " [[0.79608508]]\n",
            "\n",
            " Loss : [[0.12054563]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-0.88006608 -0.88006608]] \n",
            " bias : \n",
            " [[0.88006608]]\n",
            "\n",
            " Loss : [[0.08672708]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 2 \n",
            " weights : \n",
            "[[-0.88006608 -0.88006608]] \n",
            " bias : \n",
            " [[0.88006608]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.94659052 -0.94659052]] \n",
            " bias : \n",
            " [[0.94659052]]\n",
            "\n",
            " Loss : [[0.06784608]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.0017446 -1.0017446]] \n",
            " bias : \n",
            " [[1.0017446]]\n",
            "\n",
            " Loss : [[0.05573732]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 3 \n",
            " weights : \n",
            "[[-1.0017446 -1.0017446]] \n",
            " bias : \n",
            " [[1.0017446]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.04888511 -1.04888511]] \n",
            " bias : \n",
            " [[1.04888511]]\n",
            "\n",
            " Loss : [[0.04729078]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.09006543 -1.09006543]] \n",
            " bias : \n",
            " [[1.09006543]]\n",
            "\n",
            " Loss : [[0.04105459]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 4 \n",
            " weights : \n",
            "[[-1.09006543 -1.09006543]] \n",
            " bias : \n",
            " [[1.09006543]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.12663537 -1.12663537]] \n",
            " bias : \n",
            " [[1.12663537]]\n",
            "\n",
            " Loss : [[0.03625733]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.15953074 -1.15953074]] \n",
            " bias : \n",
            " [[1.15953074]]\n",
            "\n",
            " Loss : [[0.03245024]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 5 \n",
            " weights : \n",
            "[[-1.15953074 -1.15953074]] \n",
            " bias : \n",
            " [[1.15953074]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.18942745 -1.18942745]] \n",
            " bias : \n",
            " [[1.18942745]]\n",
            "\n",
            " Loss : [[0.02935417]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.21682987 -1.21682987]] \n",
            " bias : \n",
            " [[1.21682987]]\n",
            "\n",
            " Loss : [[0.02678617]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 6 \n",
            " weights : \n",
            "[[-1.21682987 -1.21682987]] \n",
            " bias : \n",
            " [[1.21682987]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.24212453 -1.24212453]] \n",
            " bias : \n",
            " [[1.24212453]]\n",
            "\n",
            " Loss : [[0.02462125]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.26561427 -1.26561427]] \n",
            " bias : \n",
            " [[1.26561427]]\n",
            "\n",
            " Loss : [[0.02277109]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 7 \n",
            " weights : \n",
            "[[-1.26561427 -1.26561427]] \n",
            " bias : \n",
            " [[1.26561427]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.28754079 -1.28754079]] \n",
            " bias : \n",
            " [[1.28754079]]\n",
            "\n",
            " Loss : [[0.02117149]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.30810018 -1.30810018]] \n",
            " bias : \n",
            " [[1.30810018]]\n",
            "\n",
            " Loss : [[0.01977461]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 8 \n",
            " weights : \n",
            "[[-1.30810018 -1.30810018]] \n",
            " bias : \n",
            " [[1.30810018]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.32745365 -1.32745365]] \n",
            " bias : \n",
            " [[1.32745365]]\n",
            "\n",
            " Loss : [[0.0185441]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.34573546 -1.34573546]] \n",
            " bias : \n",
            " [[1.34573546]]\n",
            "\n",
            " Loss : [[0.01745183]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 9 \n",
            " weights : \n",
            "[[-1.34573546 -1.34573546]] \n",
            " bias : \n",
            " [[1.34573546]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.36305852 -1.36305852]] \n",
            " bias : \n",
            " [[1.36305852]]\n",
            "\n",
            " Loss : [[0.01647568]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.37951879 -1.37951879]] \n",
            " bias : \n",
            " [[1.37951879]]\n",
            "\n",
            " Loss : [[0.01559802]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 10 \n",
            " weights : \n",
            "[[-1.37951879 -1.37951879]] \n",
            " bias : \n",
            " [[1.37951879]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.39519843 -1.39519843]] \n",
            " bias : \n",
            " [[1.39519843]]\n",
            "\n",
            " Loss : [[0.01480463]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.41016841 -1.41016841]] \n",
            " bias : \n",
            " [[1.41016841]]\n",
            "\n",
            " Loss : [[0.01408389]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 11 \n",
            " weights : \n",
            "[[-1.41016841 -1.41016841]] \n",
            " bias : \n",
            " [[1.41016841]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.4244904 -1.4244904]] \n",
            " bias : \n",
            " [[1.4244904]]\n",
            "\n",
            " Loss : [[0.01342624]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.43821834 -1.43821834]] \n",
            " bias : \n",
            " [[1.43821834]]\n",
            "\n",
            " Loss : [[0.01282374]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 12 \n",
            " weights : \n",
            "[[-1.43821834 -1.43821834]] \n",
            " bias : \n",
            " [[1.43821834]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.45139972 -1.45139972]] \n",
            " bias : \n",
            " [[1.45139972]]\n",
            "\n",
            " Loss : [[0.0122697]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.46407651 -1.46407651]] \n",
            " bias : \n",
            " [[1.46407651]]\n",
            "\n",
            " Loss : [[0.01175849]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 13 \n",
            " weights : \n",
            "[[-1.46407651 -1.46407651]] \n",
            " bias : \n",
            " [[1.46407651]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.47628604 -1.47628604]] \n",
            " bias : \n",
            " [[1.47628604]]\n",
            "\n",
            " Loss : [[0.01128533]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.48806162 -1.48806162]] \n",
            " bias : \n",
            " [[1.48806162]]\n",
            "\n",
            " Loss : [[0.01084611]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 14 \n",
            " weights : \n",
            "[[-1.48806162 -1.48806162]] \n",
            " bias : \n",
            " [[1.48806162]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.49943313 -1.49943313]] \n",
            " bias : \n",
            " [[1.49943313]]\n",
            "\n",
            " Loss : [[0.01043729]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.51042745 -1.51042745]] \n",
            " bias : \n",
            " [[1.51042745]]\n",
            "\n",
            " Loss : [[0.01005583]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 15 \n",
            " weights : \n",
            "[[-1.51042745 -1.51042745]] \n",
            " bias : \n",
            " [[1.51042745]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.52106887 -1.52106887]] \n",
            " bias : \n",
            " [[1.52106887]]\n",
            "\n",
            " Loss : [[0.00969905]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.53137938 -1.53137938]] \n",
            " bias : \n",
            " [[1.53137938]]\n",
            "\n",
            " Loss : [[0.00936464]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 16 \n",
            " weights : \n",
            "[[-1.53137938 -1.53137938]] \n",
            " bias : \n",
            " [[1.53137938]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.541379 -1.541379]] \n",
            " bias : \n",
            " [[1.541379]]\n",
            "\n",
            " Loss : [[0.00905056]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.55108598 -1.55108598]] \n",
            " bias : \n",
            " [[1.55108598]]\n",
            "\n",
            " Loss : [[0.00875499]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 17 \n",
            " weights : \n",
            "[[-1.55108598 -1.55108598]] \n",
            " bias : \n",
            " [[1.55108598]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.56051699 -1.56051699]] \n",
            " bias : \n",
            " [[1.56051699]]\n",
            "\n",
            " Loss : [[0.00847635]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.56968732 -1.56968732]] \n",
            " bias : \n",
            " [[1.56968732]]\n",
            "\n",
            " Loss : [[0.00821322]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 18 \n",
            " weights : \n",
            "[[-1.56968732 -1.56968732]] \n",
            " bias : \n",
            " [[1.56968732]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.57861103 -1.57861103]] \n",
            " bias : \n",
            " [[1.57861103]]\n",
            "\n",
            " Loss : [[0.00796435]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.58730107 -1.58730107]] \n",
            " bias : \n",
            " [[1.58730107]]\n",
            "\n",
            " Loss : [[0.00772859]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 19 \n",
            " weights : \n",
            "[[-1.58730107 -1.58730107]] \n",
            " bias : \n",
            " [[1.58730107]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-1.59576938 -1.59576938]] \n",
            " bias : \n",
            " [[1.59576938]]\n",
            "\n",
            " Loss : [[0.00750494]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "alpha :  1\n",
            "iterations : 2 \n",
            " weights : \n",
            "[[-1.60402702 -1.60402702]] \n",
            " bias : \n",
            " [[1.60402702]]\n",
            "\n",
            " Loss : [[0.00729249]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "//////////// end of iteration\n",
            "epoch : 20 \n",
            " weights : \n",
            "[[-1.60402702 -1.60402702]] \n",
            " bias : \n",
            " [[1.60402702]]\n",
            "Y_Hat : [[0.99193466 0.83258046 0.83258046 0.16741954]]\n",
            " Loss : [[0.13829139]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u42JH48P22im",
        "outputId": "db68319e-cf72-4170-caf7-f7651cc9cdc9"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1]]\r\n",
        "Y = [1, 1, 1, -1]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "Y = np.reshape(Y, (1, 4))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1, False]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.00002\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes, 2))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "}\r\n",
        "\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros((n_classes, 1))\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).LogisticRegressionSigmoid()\r\n",
        "opt = my_Model.Optimization(20, my_Loss, learning_rate, epsilon,'Batch').Momentum()\r\n",
        "\r\n",
        "my_Model.Evaluate(X, Y, True)\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[-1  1 -1  1]\n",
            " [-1 -1  1  1]]\n",
            "Y : [[ 1  1  1 -1]]\n",
            "iterations : \n",
            " 1 \n",
            " weights : \n",
            "[[-0.250001 -0.250001]] \n",
            " bias : \n",
            " [[0.249001]]\n",
            "\n",
            " Loss : [[0.69114918]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "iterations : \n",
            " 2 \n",
            " weights : \n",
            "[[-0.60706866 -0.60706866]] \n",
            " bias : \n",
            " [[0.60464533]]\n",
            "\n",
            " Loss : [[0.52716048]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 3 \n",
            " weights : \n",
            "[[-0.93135202 -0.93135202]] \n",
            " bias : \n",
            " [[0.92796231]]\n",
            "\n",
            " Loss : [[0.36259102]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 4 \n",
            " weights : \n",
            "[[-1.18755816 -1.18755816]] \n",
            " bias : \n",
            " [[1.18393064]]\n",
            "\n",
            " Loss : [[0.26296671]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 5 \n",
            " weights : \n",
            "[[-1.38511227 -1.38511227]] \n",
            " bias : \n",
            " [[1.38173934]]\n",
            "\n",
            " Loss : [[0.20562673]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 6 \n",
            " weights : \n",
            "[[-1.53996016 -1.53996016]] \n",
            " bias : \n",
            " [[1.53704158]]\n",
            "\n",
            " Loss : [[0.17041615]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 7 \n",
            " weights : \n",
            "[[-1.66522288 -1.66522288]] \n",
            " bias : \n",
            " [[1.66277012]]\n",
            "\n",
            " Loss : [[0.1471063]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 8 \n",
            " weights : \n",
            "[[-1.77011234 -1.77011234]] \n",
            " bias : \n",
            " [[1.7680506]]\n",
            "\n",
            " Loss : [[0.13057317]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 9 \n",
            " weights : \n",
            "[[-1.86073272 -1.86073272]] \n",
            " bias : \n",
            " [[1.85896448]]\n",
            "\n",
            " Loss : [[0.11813532]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 10 \n",
            " weights : \n",
            "[[-1.94105205 -1.94105205]] \n",
            " bias : \n",
            " [[1.93948807]]\n",
            "\n",
            " Loss : [[0.10832146]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 11 \n",
            " weights : \n",
            "[[-2.01365462 -2.01365462]] \n",
            " bias : \n",
            " [[2.01222497]]\n",
            "\n",
            " Loss : [[0.10028592]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 12 \n",
            " weights : \n",
            "[[-2.0802509 -2.0802509]] \n",
            " bias : \n",
            " [[2.07890573]]\n",
            "\n",
            " Loss : [[0.09351954]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 13 \n",
            " weights : \n",
            "[[-2.14200335 -2.14200335]] \n",
            " bias : \n",
            " [[2.14070951]]\n",
            "\n",
            " Loss : [[0.08770093]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 14 \n",
            " weights : \n",
            "[[-2.19972872 -2.19972872]] \n",
            " bias : \n",
            " [[2.19846546]]\n",
            "\n",
            " Loss : [[0.08261748]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 15 \n",
            " weights : \n",
            "[[-2.25402236 -2.25402236]] \n",
            " bias : \n",
            " [[2.25277737]]\n",
            "\n",
            " Loss : [[0.07812201]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 16 \n",
            " weights : \n",
            "[[-2.3053343 -2.3053343]] \n",
            " bias : \n",
            " [[2.30410069]]\n",
            "\n",
            " Loss : [[0.07410834]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 17 \n",
            " weights : \n",
            "[[-2.35401632 -2.35401632]] \n",
            " bias : \n",
            " [[2.35279052]]\n",
            "\n",
            " Loss : [[0.07049707]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 18 \n",
            " weights : \n",
            "[[-2.40035155 -2.40035155]] \n",
            " bias : \n",
            " [[2.39913186]]\n",
            "\n",
            " Loss : [[0.06722694]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 19 \n",
            " weights : \n",
            "[[-2.4445734 -2.4445734]] \n",
            " bias : \n",
            " [[2.44335912]]\n",
            "\n",
            " Loss : [[0.06424953]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 20 \n",
            " weights : \n",
            "[[-2.48687806 -2.48687806]] \n",
            " bias : \n",
            " [[2.48566898]]\n",
            "\n",
            " Loss : [[0.06152577]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "Y_Hat : [[0.99942434 0.92313104 0.92313104 0.07669755]]\n",
            " Loss : [[0.05902362]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j02ei27627lj",
        "outputId": "a7b97650-6e4c-4897-9846-2968c1e5e8a7"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1]]\r\n",
        "Y = [1, 1, 1, -1]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "Y = np.reshape(Y, (1, 4))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1, False]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.00002\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes, 2))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "}\r\n",
        "\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros((n_classes, 1))\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).LogisticRegressionSigmoid()\r\n",
        "opt = my_Model.Optimization(20, my_Loss, learning_rate, epsilon,'Batch').Adam(0.4,0.7)\r\n",
        "# my_Model.split_Batches()\r\n",
        "my_Model.Evaluate(X, Y, True)\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[-1  1 -1  1]\n",
            " [-1 -1  1  1]]\n",
            "Y : [[ 1  1  1 -1]]\n",
            "iterations : \n",
            " 1 \n",
            " weights : \n",
            "[[-0.2302285  0.       ]] \n",
            " bias : \n",
            " [[-0.11465355]]\n",
            "\n",
            " Loss : [[0.69114918]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "iterations : \n",
            " 2 \n",
            " weights : \n",
            "[[-0.5534222  0.       ]] \n",
            " bias : \n",
            " [[-0.31026969]]\n",
            "\n",
            " Loss : [[0.67051177]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 3 \n",
            " weights : \n",
            "[[-0.90612021  0.        ]] \n",
            " bias : \n",
            " [[-0.60067069]]\n",
            "\n",
            " Loss : [[0.67919902]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 4 \n",
            " weights : \n",
            "[[-1.25425545  0.        ]] \n",
            " bias : \n",
            " [[-1.00520907]]\n",
            "\n",
            " Loss : [[0.75025942]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 5 \n",
            " weights : \n",
            "[[-1.59954282  0.        ]] \n",
            " bias : \n",
            " [[-1.54716869]]\n",
            "\n",
            " Loss : [[0.89890311]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 6 \n",
            " weights : \n",
            "[[-1.98388401  0.        ]] \n",
            " bias : \n",
            " [[-2.25333053]]\n",
            "\n",
            " Loss : [[1.13415011]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 7 \n",
            " weights : \n",
            "[[-2.48958879  0.        ]] \n",
            " bias : \n",
            " [[-3.15343256]]\n",
            "\n",
            " Loss : [[1.46656337]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 8 \n",
            " weights : \n",
            "[[-3.22093588  0.        ]] \n",
            " bias : \n",
            " [[-4.27927129]]\n",
            "\n",
            " Loss : [[1.88802824]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 9 \n",
            " weights : \n",
            "[[-4.29429523  0.        ]] \n",
            " bias : \n",
            " [[-5.66454247]]\n",
            "\n",
            " Loss : [[2.29301681]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 10 \n",
            " weights : \n",
            "[[-5.85439508  0.        ]] \n",
            " bias : \n",
            " [[-7.34911335]]\n",
            "\n",
            " Loss : [[2.51099396]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 11 \n",
            " weights : \n",
            "[[-8.09837723  0.        ]] \n",
            " bias : \n",
            " [[-9.40869973]]\n",
            "\n",
            " Loss : [[2.57205576]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 12 \n",
            " weights : \n",
            "[[-11.37953231   0.        ]] \n",
            " bias : \n",
            " [[-12.04024527]]\n",
            "\n",
            " Loss : [[2.49889915]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 13 \n",
            " weights : \n",
            "[[-15.97533149   0.        ]] \n",
            " bias : \n",
            " [[-15.54563311]]\n",
            "\n",
            " Loss : [[2.26377638]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 14 \n",
            " weights : \n",
            "[[-20.59387588   0.        ]] \n",
            " bias : \n",
            " [[-20.01769658]]\n",
            "\n",
            " Loss : [[1.97646561]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 15 \n",
            " weights : \n",
            "[[-24.59103138   0.        ]] \n",
            " bias : \n",
            " [[-25.62355149]]\n",
            "\n",
            " Loss : [[1.94890539]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 16 \n",
            " weights : \n",
            "[[-28.13183376   0.        ]] \n",
            " bias : \n",
            " [[-32.3835699]]\n",
            "\n",
            " Loss : [[2.39335811]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 17 \n",
            " weights : \n",
            "[[-30.82210866   0.        ]] \n",
            " bias : \n",
            " [[-41.21411213]]\n",
            "\n",
            " Loss : [[3.82522408]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 18 \n",
            " weights : \n",
            "[[-32.84408539   0.        ]] \n",
            " bias : \n",
            " [[-52.82792194]]\n",
            "\n",
            " Loss : [[5.1654592]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 19 \n",
            " weights : \n",
            "[[-34.3620212   0.       ]] \n",
            " bias : \n",
            " [[-68.08571363]]\n",
            "\n",
            " Loss : [[5.18056554]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 20 \n",
            " weights : \n",
            "[[-35.49841386   0.        ]] \n",
            " bias : \n",
            " [[-88.07553304]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "Y_Hat : [[1.46570735e-23 2.15038764e-54 1.46570735e-23 2.15038764e-54]]\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W5rgBwiU2-e0",
        "outputId": "d064bec9-2ada-4276-9e77-b5da96544987"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1]]\r\n",
        "Y = [1, 1, 1, -1]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "Y = np.reshape(Y, (1, 4))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1, False]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.00002\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes, 2))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "}\r\n",
        "\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros((n_classes, 1))\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).LogisticRegressionSigmoid()\r\n",
        "opt = my_Model.Optimization(20, my_Loss, learning_rate, epsilon,'Batch').RMSprop(0.2)\r\n",
        "# my_Model.split_Batches()\r\n",
        "my_Model.Evaluate(X, Y, True)\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[-1  1 -1  1]\n",
            " [-1 -1  1  1]]\n",
            "Y : [[ 1  1  1 -1]]\n",
            "iterations : \n",
            " 1 \n",
            " weights : \n",
            "[[-1.11803399 -1.11803399]] \n",
            " bias : \n",
            " [[1.]]\n",
            "\n",
            " Loss : [[0.69114918]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "iterations : \n",
            " 2 \n",
            " weights : \n",
            "[[-1.88557386 -1.88557386]] \n",
            " bias : \n",
            " [[1.45431715]]\n",
            "\n",
            " Loss : [[0.22876863]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 3 \n",
            " weights : \n",
            "[[-2.30422398 -2.30422398]] \n",
            " bias : \n",
            " [[1.7289295]]\n",
            "\n",
            " Loss : [[0.12865669]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 4 \n",
            " weights : \n",
            "[[-2.74651949 -2.74651949]] \n",
            " bias : \n",
            " [[1.94859953]]\n",
            "\n",
            " Loss : [[0.09468544]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 5 \n",
            " weights : \n",
            "[[-3.21010667 -3.21010667]] \n",
            " bias : \n",
            " [[2.13687769]]\n",
            "\n",
            " Loss : [[0.0727852]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 6 \n",
            " weights : \n",
            "[[-3.66170564 -3.66170564]] \n",
            " bias : \n",
            " [[2.30096333]]\n",
            "\n",
            " Loss : [[0.05819253]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 7 \n",
            " weights : \n",
            "[[-4.10287229 -4.10287229]] \n",
            " bias : \n",
            " [[2.4443979]]\n",
            "\n",
            " Loss : [[0.04833589]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 8 \n",
            " weights : \n",
            "[[-4.53605109 -4.53605109]] \n",
            " bias : \n",
            " [[2.57076829]]\n",
            "\n",
            " Loss : [[0.04135662]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 9 \n",
            " weights : \n",
            "[[-4.96248793 -4.96248793]] \n",
            " bias : \n",
            " [[2.68320371]]\n",
            "\n",
            " Loss : [[0.03618592]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 10 \n",
            " weights : \n",
            "[[-5.38327632 -5.38327632]] \n",
            " bias : \n",
            " [[2.78423152]]\n",
            "\n",
            " Loss : [[0.03220079]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 11 \n",
            " weights : \n",
            "[[-5.79935559 -5.79935559]] \n",
            " bias : \n",
            " [[2.87584247]]\n",
            "\n",
            " Loss : [[0.02902698]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 12 \n",
            " weights : \n",
            "[[-6.21149735 -6.21149735]] \n",
            " bias : \n",
            " [[2.95959542]]\n",
            "\n",
            " Loss : [[0.02643174]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 13 \n",
            " weights : \n",
            "[[-6.62032397 -6.62032397]] \n",
            " bias : \n",
            " [[3.03671527]]\n",
            "\n",
            " Loss : [[0.0242645]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 14 \n",
            " weights : \n",
            "[[-7.02633487 -7.02633487]] \n",
            " bias : \n",
            " [[3.10817258]]\n",
            "\n",
            " Loss : [[0.0224239]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 15 \n",
            " weights : \n",
            "[[-7.42993174 -7.42993174]] \n",
            " bias : \n",
            " [[3.17474461]]\n",
            "\n",
            " Loss : [[0.02083912]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 16 \n",
            " weights : \n",
            "[[-7.83143967 -7.83143967]] \n",
            " bias : \n",
            " [[3.23706105]]\n",
            "\n",
            " Loss : [[0.01945901]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 17 \n",
            " weights : \n",
            "[[-8.23112405 -8.23112405]] \n",
            " bias : \n",
            " [[3.29563797]]\n",
            "\n",
            " Loss : [[0.01824557]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 18 \n",
            " weights : \n",
            "[[-8.62920357 -8.62920357]] \n",
            " bias : \n",
            " [[3.35090305]]\n",
            "\n",
            " Loss : [[0.01716985]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 19 \n",
            " weights : \n",
            "[[-9.02586017 -9.02586017]] \n",
            " bias : \n",
            " [[3.40321442]]\n",
            "\n",
            " Loss : [[0.01620938]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 20 \n",
            " weights : \n",
            "[[-9.4212467 -9.4212467]] \n",
            " bias : \n",
            " [[3.45287488]]\n",
            "\n",
            " Loss : [[0.0153464]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "Y_Hat : [[1.00000000e+00 9.69316760e-01 9.69316760e-01 2.07192251e-07]]\n",
            " Loss : [[0.01456665]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5x3CkGrK33BC",
        "outputId": "6532f19e-10b9-4929-a98c-57ee6bc064c1"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1]]\r\n",
        "Y = [1, 1, 1, -1]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "Y = np.reshape(Y, (1, 4))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1, False]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.00002\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes, 2))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "}\r\n",
        "\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros((n_classes, 1))\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).LogisticRegressionSigmoid()\r\n",
        "opt = my_Model.Optimization(20, my_Loss, learning_rate, epsilon,'Batch').AdaGrad()\r\n",
        "# my_Model.split_Batches()\r\n",
        "my_Model.Evaluate(X, Y, True)\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[-1  1 -1  1]\n",
            " [-1 -1  1  1]]\n",
            "Y : [[ 1  1  1 -1]]\n",
            "iterations : \n",
            " 1 \n",
            " weights : \n",
            "[[-1. -1.]] \n",
            " bias : \n",
            " [[1.]]\n",
            "\n",
            " Loss : [[0.69114918]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "iterations : \n",
            " 2 \n",
            " weights : \n",
            "[[-1.43578843 -1.43578843]] \n",
            " bias : \n",
            " [[1.4349027]]\n",
            "\n",
            " Loss : [[0.24580559]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 3 \n",
            " weights : \n",
            "[[-1.63538196 -1.63538196]] \n",
            " bias : \n",
            " [[1.634763]]\n",
            "\n",
            " Loss : [[0.16228823]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 4 \n",
            " weights : \n",
            "[[-1.78916449 -1.78916449]] \n",
            " bias : \n",
            " [[1.78883606]]\n",
            "\n",
            " Loss : [[0.13425546]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 5 \n",
            " weights : \n",
            "[[-1.91993596 -1.91993596]] \n",
            " bias : \n",
            " [[1.91974222]]\n",
            "\n",
            " Loss : [[0.11594137]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 6 \n",
            " weights : \n",
            "[[-2.03445092 -2.03445092]] \n",
            " bias : \n",
            " [[2.03431929]]\n",
            "\n",
            " Loss : [[0.10229437]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 7 \n",
            " weights : \n",
            "[[-2.13656904 -2.13656904]] \n",
            " bias : \n",
            " [[2.13647247]]\n",
            "\n",
            " Loss : [[0.09162642]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 8 \n",
            " weights : \n",
            "[[-2.22884846 -2.22884846]] \n",
            " bias : \n",
            " [[2.22877524]]\n",
            "\n",
            " Loss : [[0.08302101]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 9 \n",
            " weights : \n",
            "[[-2.31309606 -2.31309606]] \n",
            " bias : \n",
            " [[2.31303993]]\n",
            "\n",
            " Loss : [[0.0759151]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 10 \n",
            " weights : \n",
            "[[-2.39064488 -2.39064488]] \n",
            " bias : \n",
            " [[2.39060202]]\n",
            "\n",
            " Loss : [[0.06993891]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 11 \n",
            " weights : \n",
            "[[-2.46251127 -2.46251127]] \n",
            " bias : \n",
            " [[2.46247913]]\n",
            "\n",
            " Loss : [[0.06483768]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 12 \n",
            " weights : \n",
            "[[-2.52949048 -2.52949048]] \n",
            " bias : \n",
            " [[2.52946722]]\n",
            "\n",
            " Loss : [[0.06042933]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 13 \n",
            " weights : \n",
            "[[-2.59221789 -2.59221789]] \n",
            " bias : \n",
            " [[2.59220217]]\n",
            "\n",
            " Loss : [[0.05657978]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 14 \n",
            " weights : \n",
            "[[-2.65121009 -2.65121009]] \n",
            " bias : \n",
            " [[2.65120085]]\n",
            "\n",
            " Loss : [[0.05318793]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 15 \n",
            " weights : \n",
            "[[-2.70689327 -2.70689327]] \n",
            " bias : \n",
            " [[2.70688968]]\n",
            "\n",
            " Loss : [[0.05017598]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 16 \n",
            " weights : \n",
            "[[-2.7596235 -2.7596235]] \n",
            " bias : \n",
            " [[2.7596249]]\n",
            "\n",
            " Loss : [[0.04748295]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 17 \n",
            " weights : \n",
            "[[-2.80970156 -2.80970156]] \n",
            " bias : \n",
            " [[2.80970739]]\n",
            "\n",
            " Loss : [[0.04506039]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 18 \n",
            " weights : \n",
            "[[-2.85738394 -2.85738394]] \n",
            " bias : \n",
            " [[2.85739374]]\n",
            "\n",
            " Loss : [[0.04286926]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 19 \n",
            " weights : \n",
            "[[-2.90289124 -2.90289124]] \n",
            " bias : \n",
            " [[2.90290463]]\n",
            "\n",
            " Loss : [[0.04087774]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 20 \n",
            " weights : \n",
            "[[-2.94641467 -2.94641467]] \n",
            " bias : \n",
            " [[2.94643131]]\n",
            "\n",
            " Loss : [[0.03905961]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "Y_Hat : [[0.99985509 0.95009455 0.95009455 0.04990703]]\n",
            " Loss : [[0.03739308]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wdWPJPe6351S",
        "outputId": "b65e2ee3-68dc-4f65-8a3d-af633517be52"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1]]\r\n",
        "Y = [1, 1, 1, -1]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "Y = np.reshape(Y, (1, 4))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1, False]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.00002\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes, 2))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "}\r\n",
        "\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros((n_classes, 1))\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).LogisticRegressionSigmoid()\r\n",
        "opt = my_Model.Optimization(20, my_Loss, learning_rate, epsilon,'minibatch').AdaDelta(0.4)\r\n",
        "\r\n",
        "my_Model.Evaluate(X, Y, True)\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[-1  1 -1  1]\n",
            " [-1 -1  1  1]]\n",
            "Y : [[ 1  1  1 -1]]\n",
            "iterations : \n",
            " 1 \n",
            " weights : \n",
            "[[-0.71807759 -0.27092847]] \n",
            " bias : \n",
            " [[0.83005917]]\n",
            "\n",
            " Loss : [[0.69114918]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "iterations : \n",
            " 2 \n",
            " weights : \n",
            "[[-0.94063197 -0.35489755]] \n",
            " bias : \n",
            " [[1.0873201]]\n",
            "\n",
            " Loss : [[0.14913371]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 3 \n",
            " weights : \n",
            "[[-0.99367746 -0.37491145]] \n",
            " bias : \n",
            " [[1.14863784]]\n",
            "\n",
            " Loss : [[0.08718217]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 4 \n",
            " weights : \n",
            "[[-1.02195929 -0.3855821 ]] \n",
            " bias : \n",
            " [[1.18133012]]\n",
            "\n",
            " Loss : [[0.0765132]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 5 \n",
            " weights : \n",
            "[[-1.03866431 -0.39188485]] \n",
            " bias : \n",
            " [[1.20064023]]\n",
            "\n",
            " Loss : [[0.07134357]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 6 \n",
            " weights : \n",
            "[[-1.04883139 -0.39572086]] \n",
            " bias : \n",
            " [[1.21239282]]\n",
            "\n",
            " Loss : [[0.06844791]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 7 \n",
            " weights : \n",
            "[[-1.05512078 -0.39809383]] \n",
            " bias : \n",
            " [[1.21966302]]\n",
            "\n",
            " Loss : [[0.06674067]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 8 \n",
            " weights : \n",
            "[[-1.05904871 -0.39957582]] \n",
            " bias : \n",
            " [[1.2242035]]\n",
            "\n",
            " Loss : [[0.06570494]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 9 \n",
            " weights : \n",
            "[[-1.06151604 -0.40050674]] \n",
            " bias : \n",
            " [[1.2270556]]\n",
            "\n",
            " Loss : [[0.06506588]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 10 \n",
            " weights : \n",
            "[[-1.0630714  -0.40109357]] \n",
            " bias : \n",
            " [[1.22885351]]\n",
            "\n",
            " Loss : [[0.06466749]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 11 \n",
            " weights : \n",
            "[[-1.06405403 -0.40146432]] \n",
            " bias : \n",
            " [[1.22998938]]\n",
            "\n",
            " Loss : [[0.06441755]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 12 \n",
            " weights : \n",
            "[[-1.06467569 -0.40169886]] \n",
            " bias : \n",
            " [[1.23070798]]\n",
            "\n",
            " Loss : [[0.06426011]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 13 \n",
            " weights : \n",
            "[[-1.0650693  -0.40184737]] \n",
            " bias : \n",
            " [[1.23116298]]\n",
            "\n",
            " Loss : [[0.0641607]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 14 \n",
            " weights : \n",
            "[[-1.06531867 -0.40194146]] \n",
            " bias : \n",
            " [[1.23145123]]\n",
            "\n",
            " Loss : [[0.06409784]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 15 \n",
            " weights : \n",
            "[[-1.06547669 -0.40200108]] \n",
            " bias : \n",
            " [[1.2316339]]\n",
            "\n",
            " Loss : [[0.06405804]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 16 \n",
            " weights : \n",
            "[[-1.06557686 -0.40203887]] \n",
            " bias : \n",
            " [[1.23174968]]\n",
            "\n",
            " Loss : [[0.06403283]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 17 \n",
            " weights : \n",
            "[[-1.06564035 -0.40206283]] \n",
            " bias : \n",
            " [[1.23182308]]\n",
            "\n",
            " Loss : [[0.06401686]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 18 \n",
            " weights : \n",
            "[[-1.06568061 -0.40207802]] \n",
            " bias : \n",
            " [[1.23186961]]\n",
            "\n",
            " Loss : [[0.06400673]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 19 \n",
            " weights : \n",
            "[[-1.06570613 -0.40208765]] \n",
            " bias : \n",
            " [[1.23189911]]\n",
            "\n",
            " Loss : [[0.06400032]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "iterations : \n",
            " 20 \n",
            " weights : \n",
            "[[-1.06572231 -0.40209375]] \n",
            " bias : \n",
            " [[1.23191781]]\n",
            "\n",
            " Loss : [[0.06399625]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "Y_Hat : [[0.93701094 0.63836834 0.86938663 0.44129741]]\n",
            " Loss : [[0.30760893]]\n",
            "accuracy  :  1.0\n",
            "recall  :  1.0\n",
            "precision  :  1.0\n",
            "specificity  :  1.0\n",
            "F1 score  :  1.0\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8u6TJbc4hh0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
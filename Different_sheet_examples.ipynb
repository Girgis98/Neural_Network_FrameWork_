{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Different_sheet_examples.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WctQMpRAzf-7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Naix3glNzv6M"
      },
      "source": [
        "#### Sheet 4 Q8 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_H8tUcWKzEv6",
        "outputId": "173218d7-796a-407e-eeb4-b9c98579b55f"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1]]\r\n",
        "Y = [1, 1, 1, -1]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X=X.T\r\n",
        "Y = np.reshape(Y, (1,4))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1,False]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.2\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes,2))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "    }\r\n",
        "\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros((n_classes,1))\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "#Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).LogisticRegressionSigmoid()\r\n",
        "opt = my_Model.Optimization(200, my_Loss,learning_rate,epsilon).Adam(0.2,0.9)\r\n",
        "my_Model.Evaluate(X, Y,True)\r\n",
        "\r\n",
        "print(\"opa\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[-1  1 -1  1]\n",
            " [-1 -1  1  1]]\n",
            "Y : [[ 1  1  1 -1]]\n",
            "iterations : \n",
            " 1 \n",
            " weights : \n",
            "[[-0.16818049  0.        ]] \n",
            " bias : \n",
            " [[-0.02087139]]\n",
            "\n",
            " Loss : [[0.69114918]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "iterations : \n",
            " 2 \n",
            " weights : \n",
            "[[-0.49835173  0.        ]] \n",
            " bias : \n",
            " [[-0.08597322]]\n",
            "\n",
            " Loss : [[0.65796681]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 3 \n",
            " weights : \n",
            "[[-0.92521518  0.        ]] \n",
            " bias : \n",
            " [[-0.24010502]]\n",
            "\n",
            " Loss : [[0.61973258]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 4 \n",
            " weights : \n",
            "[[-1.30279577  0.        ]] \n",
            " bias : \n",
            " [[-0.56502129]]\n",
            "\n",
            " Loss : [[0.62898579]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 5 \n",
            " weights : \n",
            "[[-1.58778305  0.        ]] \n",
            " bias : \n",
            " [[-1.21601474]]\n",
            "\n",
            " Loss : [[0.731287]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 6 \n",
            " weights : \n",
            "[[-2.03325199  0.        ]] \n",
            " bias : \n",
            " [[-2.49089278]]\n",
            "\n",
            " Loss : [[0.98712967]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 7 \n",
            " weights : \n",
            "[[-3.77965362  0.        ]] \n",
            " bias : \n",
            " [[-4.88494998]]\n",
            "\n",
            " Loss : [[1.58656754]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 8 \n",
            " weights : \n",
            "[[-10.08694524   0.        ]] \n",
            " bias : \n",
            " [[-9.26302881]]\n",
            "\n",
            " Loss : [[2.38058486]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 9 \n",
            " weights : \n",
            "[[-37.92925882   0.        ]] \n",
            " bias : \n",
            " [[-18.17217961]]\n",
            "\n",
            " Loss : [[1.9078426]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 10 \n",
            " weights : \n",
            "[[-49.52611437   0.        ]] \n",
            " bias : \n",
            " [[-34.90557122]]\n",
            "\n",
            " Loss : [[1.7261892]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 11 \n",
            " weights : \n",
            "[[-53.65317478   0.        ]] \n",
            " bias : \n",
            " [[-61.72237347]]\n",
            "\n",
            " Loss : [[1.72618942]]\n",
            "accuracy  :  0.75\n",
            "recall  :  0.75\n",
            "precision  :  0.75\n",
            "specificity  :  0.75\n",
            "F1 score  :  0.75\n",
            "iterations : \n",
            " 12 \n",
            " weights : \n",
            "[[-55.05825083   0.        ]] \n",
            " bias : \n",
            " [[-102.81300277]]\n",
            "\n",
            " Loss : [[5.04443364]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 13 \n",
            " weights : \n",
            "[[-55.53202096   0.        ]] \n",
            " bias : \n",
            " [[-165.16319533]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 14 \n",
            " weights : \n",
            "[[-55.69145603   0.        ]] \n",
            " bias : \n",
            " [[-259.5843814]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 15 \n",
            " weights : \n",
            "[[-55.74508866   0.        ]] \n",
            " bias : \n",
            " [[-402.51583578]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 16 \n",
            " weights : \n",
            "[[-55.76312881   0.        ]] \n",
            " bias : \n",
            " [[-618.86314151]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 17 \n",
            " weights : \n",
            "[[-55.76919679   0.        ]] \n",
            " bias : \n",
            " [[-946.33066224]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 18 \n",
            " weights : \n",
            "[[-55.77123781   0.        ]] \n",
            " bias : \n",
            " [[-1441.99033388]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 19 \n",
            " weights : \n",
            "[[-55.77192433   0.        ]] \n",
            " bias : \n",
            " [[-2192.22764764]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 20 \n",
            " weights : \n",
            "[[-55.77215524   0.        ]] \n",
            " bias : \n",
            " [[-3327.79704585]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/Activations.py:48: RuntimeWarning: overflow encountered in exp\n",
            "  o = 1 / (1 + np.exp(-Z))  # o is an intermediate variable\n",
            "/content/Activations.py:54: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1 / (1 + np.exp(-Z))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iterations : \n",
            " 21 \n",
            " weights : \n",
            "[[-55.77223291   0.        ]] \n",
            " bias : \n",
            " [[-5046.61028203]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 22 \n",
            " weights : \n",
            "[[-55.77225904   0.        ]] \n",
            " bias : \n",
            " [[-7648.22928519]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 23 \n",
            " weights : \n",
            "[[-55.77226783   0.        ]] \n",
            " bias : \n",
            " [[-11586.0750547]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 24 \n",
            " weights : \n",
            "[[-55.77227078   0.        ]] \n",
            " bias : \n",
            " [[-17546.45175953]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 25 \n",
            " weights : \n",
            "[[-55.77227178   0.        ]] \n",
            " bias : \n",
            " [[-26568.15868799]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 26 \n",
            " weights : \n",
            "[[-55.77227211   0.        ]] \n",
            " bias : \n",
            " [[-40223.53651613]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 27 \n",
            " weights : \n",
            "[[-55.77227222   0.        ]] \n",
            " bias : \n",
            " [[-60892.50139245]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 28 \n",
            " weights : \n",
            "[[-55.77227226   0.        ]] \n",
            " bias : \n",
            " [[-92177.32664116]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 29 \n",
            " weights : \n",
            "[[-55.77227227   0.        ]] \n",
            " bias : \n",
            " [[-139530.46196741]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 30 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-211204.80911179]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 31 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-319692.07195462]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 32 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-483899.86272003]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 33 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-732446.99942049]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 34 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1108651.31271187]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 35 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1678079.25792134]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 36 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2539973.11009082]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 37 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3844547.32120417]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 38 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5819168.52080797]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 39 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8807981.91962345]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 40 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-13331890.37089061]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 41 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-20179339.4901824]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 42 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-30543731.24266279]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 43 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-46231415.01036547]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 44 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-69976505.6893766]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 45 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.05917397e+08]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 46 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.60318016e+08]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 47 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.42659531e+08]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 48 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.67292763e+08]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 49 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.55939311e+08]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 50 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.41477282e+08]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 51 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.27367142e+09]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 52 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.92784633e+09]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 53 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.91801433e+09]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 54 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.41674604e+09]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 55 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.68524665e+09]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 56 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.01188799e+10]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 57 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.53160737e+10]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 58 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.31826167e+10]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 59 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.50895227e+10]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 60 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.31119769e+10]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 61 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.03910078e+10]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 62 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.21680919e+11]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 63 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.84177887e+11]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 64 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.78774145e+11]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 65 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.21956322e+11]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 66 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.38678805e+11]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 67 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-9.66712892e+11]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 68 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.46322973e+12]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 69 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.21476434e+12]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 70 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.35229731e+12]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 71 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.07408263e+12]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 72 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.68020021e+12]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 73 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.16248551e+13]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 74 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.75955381e+13]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 75 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.66328449e+13]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 76 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.03118348e+13]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 77 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.10165394e+13]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 78 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-9.23554606e+13]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 79 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.39790476e+14]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 80 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.11588759e+14]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 81 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.20263612e+14]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 82 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.84755341e+14]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 83 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.33732252e+14]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 84 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.11058708e+15]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 85 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.68099965e+15]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 86 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.54438384e+15]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 87 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.85121384e+15]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 88 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.82924945e+15]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 89 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.82323094e+15]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 90 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.33549619e+16]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 91 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.02142512e+16]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 92 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.05965645e+16]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 93 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.63113745e+16]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 94 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.00975239e+16]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 95 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.06100562e+17]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 96 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.60595248e+17]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 97 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.43079143e+17]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 98 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.67927884e+17]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 99 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.56900629e+17]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 100 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.42932337e+17]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 101 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.2758738e+18]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 102 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.93117988e+18]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 103 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.92306002e+18]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 104 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.42438325e+18]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 105 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.69680642e+18]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 106 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.01363769e+19]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 107 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.53425574e+19]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 108 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.32227028e+19]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 109 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.51501976e+19]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 110 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.32038152e+19]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 111 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.05300155e+19]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 112 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.21891322e+20]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 113 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.84496357e+20]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 114 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.79256185e+20]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 115 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.22685945e+20]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 116 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.39783173e+20]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 117 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-9.68384478e+20]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 118 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.46575987e+21]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 119 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.21859399e+21]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 120 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.35809392e+21]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 121 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.08285645e+21]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 122 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.69348038e+21]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 123 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.16449561e+22]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 124 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.76259634e+22]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 125 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.66788969e+22]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 126 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.03815398e+22]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 127 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.11220458e+22]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 128 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-9.25151565e+22]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 129 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.40032194e+23]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 130 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.11954626e+23]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 131 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.20817394e+23]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 132 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.85593553e+23]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 133 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.35000981e+23]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 134 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.11250744e+24]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 135 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.68390634e+24]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 136 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.54878344e+24]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 137 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.85787315e+24]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 138 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.83932906e+24]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 139 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.83848758e+24]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 140 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.33780545e+25]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 141 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.02492046e+25]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 142 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.06494704e+25]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 143 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.63914536e+25]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 144 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.02187327e+25]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 145 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.06284025e+26]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 146 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.6087294e+26]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 147 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.43499462e+26]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 148 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.68564084e+26]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 149 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.57863591e+26]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 150 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.44389888e+26]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 151 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.27807997e+27]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 152 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.93451916e+27]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 153 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.92811441e+27]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 154 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.43203365e+27]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 155 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.70838617e+27]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 156 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.01539042e+28]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 157 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.53690869e+28]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 158 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.32628582e+28]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 159 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.52109773e+28]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 160 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.32958123e+28]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 161 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.06692635e+28]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 162 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.2210209e+29]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 163 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.84815378e+29]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 164 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.7973906e+29]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 165 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.2341683e+29]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 166 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.40889451e+29]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 167 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-9.70058955e+29]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 168 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.46829438e+30]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 169 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.22243026e+30]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 170 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.36390055e+30]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 171 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.09164544e+30]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 172 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.70678352e+30]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 173 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.16650919e+31]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 174 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.76564412e+31]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 175 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.67250286e+31]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 176 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.04513653e+31]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 177 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-6.12277346e+31]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 178 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-9.26751286e+31]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 179 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.4027433e+32]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 180 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.12321126e+32]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 181 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.21372133e+32]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 182 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.86433215e+32]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 183 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.36271904e+32]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 184 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.11443113e+33]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 185 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.68681805e+33]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 186 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.55319066e+33]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 187 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.86454397e+33]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 188 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.84942611e+33]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 189 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.8537706e+33]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 190 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.34011871e+34]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 191 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.02842184e+34]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 192 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.07024677e+34]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 193 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-4.64716711e+34]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 194 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-7.0340151e+34]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 195 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.06467805e+35]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 196 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-1.61151113e+35]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 197 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-2.43920507e+35]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 198 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-3.69201385e+35]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 199 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-5.58828217e+35]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "iterations : \n",
            " 200 \n",
            " weights : \n",
            "[[-55.77227228   0.        ]] \n",
            " bias : \n",
            " [[-8.4584996e+35]]\n",
            "\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "Y_Hat : [[0. 0. 0. 0.]]\n",
            " Loss : [[5.18056658]]\n",
            "accuracy  :  0.25\n",
            "recall  :  0.25\n",
            "precision  :  0.25\n",
            "specificity  :  0.25\n",
            "F1 score  :  0.25\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK59qJefz5Qc"
      },
      "source": [
        "#### Sheet 4 Q3 :\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KZbAL68V0EH_",
        "outputId": "aadc42ab-0fb9-4850-d345-67e85c377a25"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [0, 1, 2, 3, 4, 5, 6, 7, 8]\r\n",
        "Y = [0, 0.81, 0.95, 0.31, -0.59, -1, -0.59, 0.31, 0.95]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "Y = np.reshape(Y, (1,9))\r\n",
        "    #.T\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = 0.01\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.2\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 9  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {\r\n",
        "    'h1': np.zeros((n_classes, 1))\r\n",
        "    # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "}\r\n",
        "biases = {\r\n",
        "    'b1': np.zeros(n_classes)\r\n",
        "    # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "    # 'out': (np.random.rand(n_classes))\r\n",
        "}\r\n",
        "\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'identity')\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).MSE()\r\n",
        "opt = my_Model.Optimization(10, my_Loss,learning_rate,epsilon).GradientDescent()\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X : [[0 1 2 3 4 5 6 7 8]]\n",
            "Y : [[ 0.    0.81  0.95  0.31 -0.59 -1.   -0.59  0.31  0.95]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.00278889]] \n",
            " bias : \n",
            " [[0.00127778]]\n",
            "\n",
            " Loss : [[0.24163889]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "//////////// end of iteration\n",
            "epoch : 1 \n",
            " weights : \n",
            "[[0.00278889]] \n",
            " bias : \n",
            " [[0.00127778]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.00557778]] \n",
            " bias : \n",
            " [[0.00255556]]\n",
            "\n",
            " Loss : [[0.24080105]]\n",
            "//////////// end of iteration\n",
            "epoch : 2 \n",
            " weights : \n",
            "[[0.00557778]] \n",
            " bias : \n",
            " [[0.00255556]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.00768341]] \n",
            " bias : \n",
            " [[0.003709]]\n",
            "\n",
            " Loss : [[0.24016965]]\n",
            "//////////// end of iteration\n",
            "epoch : 3 \n",
            " weights : \n",
            "[[0.00768341]] \n",
            " bias : \n",
            " [[0.003709]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.00910578]] \n",
            " bias : \n",
            " [[0.00473811]]\n",
            "\n",
            " Loss : [[0.23981207]]\n",
            "//////////// end of iteration\n",
            "epoch : 4 \n",
            " weights : \n",
            "[[0.00910578]] \n",
            " bias : \n",
            " [[0.00473811]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.01000473]] \n",
            " bias : \n",
            " [[0.00567146]]\n",
            "\n",
            " Loss : [[0.23961747]]\n",
            "//////////// end of iteration\n",
            "epoch : 5 \n",
            " weights : \n",
            "[[0.01000473]] \n",
            " bias : \n",
            " [[0.00567146]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.01054012]] \n",
            " bias : \n",
            " [[0.00653763]]\n",
            "\n",
            " Loss : [[0.23950145]]\n",
            "//////////// end of iteration\n",
            "epoch : 6 \n",
            " weights : \n",
            "[[0.01054012]] \n",
            " bias : \n",
            " [[0.00653763]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.01083441]] \n",
            " bias : \n",
            " [[0.0073585]]\n",
            "\n",
            " Loss : [[0.23942007]]\n",
            "//////////// end of iteration\n",
            "epoch : 7 \n",
            " weights : \n",
            "[[0.01083441]] \n",
            " bias : \n",
            " [[0.0073585]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.0109727]] \n",
            " bias : \n",
            " [[0.0081493]]\n",
            "\n",
            " Loss : [[0.23935337]]\n",
            "//////////// end of iteration\n",
            "epoch : 8 \n",
            " weights : \n",
            "[[0.0109727]] \n",
            " bias : \n",
            " [[0.0081493]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.01101145]] \n",
            " bias : \n",
            " [[0.00892011]]\n",
            "\n",
            " Loss : [[0.23929285]]\n",
            "//////////// end of iteration\n",
            "epoch : 9 \n",
            " weights : \n",
            "[[0.01101145]] \n",
            " bias : \n",
            " [[0.00892011]]\n",
            "alpha :  0.01\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.01098722]] \n",
            " bias : \n",
            " [[0.00967749]]\n",
            "\n",
            " Loss : [[0.23923499]]\n",
            "//////////// end of iteration\n",
            "epoch : 10 \n",
            " weights : \n",
            "[[0.01098722]] \n",
            " bias : \n",
            " [[0.00967749]]\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzUJRFDo1ER2"
      },
      "source": [
        "#### Sheet 5 Q8 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TQ7h1BxB0FAF",
        "outputId": "10156ab0-a6ff-49e0-b758-951ba6fc86b9"
      },
      "source": [
        "from Model import *\r\n",
        "X = [[0,0],[0,1],[1,0],[2,0],[2,1],[3,0],[0,3],[0,4],[1,3]]\r\n",
        "Y = np.array([1, 1, 1, 2, 2, 2, 3, 3, 3]) - 1\r\n",
        "\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X=X.T\r\n",
        "#Y = np.reshape(Y, (9, 1))\r\n",
        "print(np.shape(Y))\r\n",
        "Y = np.reshape(Y,(1,9))\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [1,True]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.01\r\n",
        "\r\n",
        "n_input = 1\r\n",
        "n_classes = 2\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {'h1': np.array([[1, 0], [0, 1],[0,0]]),\r\n",
        "             'h2': np.array([[1, 0], [0, 1]])}\r\n",
        "biases = {'b1': np.array([0,0,1], ndmin=2).T,\r\n",
        "           'b2': np.array([1, 1], ndmin=2).T}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'softmax')\r\n",
        "\r\n",
        "#Layer2 = Linear(Layer1.output(), weights['h2'], biases['b2'], 'softmax')\r\n",
        "\r\n",
        "my_Model = Model([Layer1])\r\n",
        "\r\n",
        "my_Loss = my_Model.Loss(Y, Layer1.output()).CrossEntropy()\r\n",
        "opt = my_Model.Optimization(3, my_Loss, learning_rate, epsilon,'Batch').GradientDescent()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(\"opa\")\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9,)\n",
            "alpha :  0.8999999999999999\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.54570743 -0.02456217]\n",
            " [ 0.53276771  0.17284391]\n",
            " [-0.07847514  0.85171826]] \n",
            " bias : \n",
            " [[-0.00404402]\n",
            " [-0.07006253]\n",
            " [ 1.07410655]]\n",
            "\n",
            " Loss : 6.907755278982137\n",
            "accuracy  :  0.1111111111111111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "//////////// end of iteration\n",
            "epoch : 1 \n",
            " weights : \n",
            "[[ 0.54570743 -0.02456217]\n",
            " [ 0.53276771  0.17284391]\n",
            " [-0.07847514  0.85171826]] \n",
            " bias : \n",
            " [[-0.00404402]\n",
            " [-0.07006253]\n",
            " [ 1.07410655]]\n",
            "alpha :  0.75\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.25046363  0.03830268]\n",
            " [ 1.56007413 -0.4331195 ]\n",
            " [-0.06053776  2.39481681]] \n",
            " bias : \n",
            " [[0.24258596]\n",
            " [0.12155203]\n",
            " [1.38586201]]\n",
            "\n",
            " Loss : 0.11546958312331819\n",
            "accuracy  :  0.0\n",
            "//////////// end of iteration\n",
            "epoch : 2 \n",
            " weights : \n",
            "[[ 0.25046363  0.03830268]\n",
            " [ 1.56007413 -0.4331195 ]\n",
            " [-0.06053776  2.39481681]] \n",
            " bias : \n",
            " [[0.24258596]\n",
            " [0.12155203]\n",
            " [1.38586201]]\n",
            "alpha :  0.6\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.12971857  0.06619431]\n",
            " [ 1.84807433 -0.41951177]\n",
            " [-0.2277929   2.35331747]] \n",
            " bias : \n",
            " [[0.32904548]\n",
            " [0.20887564]\n",
            " [1.21207887]]\n",
            "\n",
            " Loss : 0.0006651527047407833\n",
            "accuracy  :  0.3333333333333333\n",
            "//////////// end of iteration\n",
            "epoch : 3 \n",
            " weights : \n",
            "[[ 0.12971857  0.06619431]\n",
            " [ 1.84807433 -0.41951177]\n",
            " [-0.2277929   2.35331747]] \n",
            " bias : \n",
            " [[0.32904548]\n",
            " [0.20887564]\n",
            " [1.21207887]]\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdwFYobT1B0F"
      },
      "source": [
        "#### Sheet 6 Q3 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZC9OkQTt1dmr",
        "outputId": "0e898a5d-fc0e-4e62-c4a4-3ada6240366e"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[1, 0.1]]\r\n",
        "Y = [0.6,0.01]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X=X.T\r\n",
        "print(np.shape(X))\r\n",
        "Y = np.reshape(Y, (2, 1))\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = 1\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.002\r\n",
        "\r\n",
        "n_input = 1\r\n",
        "n_classes = 2\r\n",
        "\r\n",
        "#\r\n",
        "# # Store layers weight & bias\r\n",
        "# weights = {'h1': np.array([[1, 0], [0, 1]]),\r\n",
        "#              'h2': np.array([[1, 0], [0, 1]])}\r\n",
        "# biases = {'b1': np.array([1, 1], ndmin=2).T,\r\n",
        "#            'b2': np.array([1, 1], ndmin=2).T}\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {'h1': np.array([[1, 0], [0, 1]]),\r\n",
        "             'h2': np.array([[1, 0], [0, 1]])}\r\n",
        "biases = {'b1': np.array([1, 1], ndmin=2).T,\r\n",
        "           'b2': np.array([1, 1], ndmin=2).T}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "\r\n",
        "Layer2 = Linear(Layer1.output(), weights['h2'], biases['b2'], 'sigmoid')\r\n",
        "\r\n",
        "my_Model = Model([Layer1,Layer2])\r\n",
        "\r\n",
        "my_Loss = my_Model.Loss(Y, Layer2.output()).MSE()\r\n",
        "opt = my_Model.Optimization(10, my_Loss,learning_rate,epsilon).GradientDescent()\r\n",
        "\r\n",
        "print(\"opa\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 1)\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.97293235 -0.02305614]\n",
            " [-0.09352264  0.92033772]] \n",
            " bias : \n",
            " [[0.96926914]\n",
            " [0.89382045]]\n",
            "\n",
            " Loss : [[0.03583236]\n",
            " [0.35446988]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANT0lEQVR4nO3cYYjkd33H8ffHO1NpjKb0VpC706T00njYQtIlTRFqirZc8uDugUXuIFgleGAbKVWEFEuU+MiGWhCu1ZOKVdAYfSALntwDjQTEC7chNXgXItvTeheFrDHNk6Ax7bcPZtKdrneZf3Zndy/7fb/gYP7/+e3Mlx97752d2ZlUFZKk7e8VWz2AJGlzGHxJasLgS1ITBl+SmjD4ktSEwZekJqYGP8lnkzyZ5PuXuD5JPplkKcmjSW6c/ZiSpPUa8gj/c8CBF7n+VmDf+N9R4F/WP5YkadamBr+qHgR+/iJLDgGfr5FTwNVJXj+rASVJs7FzBrexGzg/cXxhfO6nqxcmOcrotwCuvPLKP7z++utncPeS1MfDDz/8s6qaW8vXziL4g1XVceA4wPz8fC0uLm7m3UvSy16S/1zr187ir3SeAPZOHO8Zn5MkXUZmEfwF4F3jv9a5GXimqn7t6RxJ0taa+pROki8BtwC7klwAPgK8EqCqPgWcAG4DloBngfds1LCSpLWbGvyqOjLl+gL+emYTSZI2hO+0laQmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqYlBwU9yIMnjSZaS3HWR69+Q5IEkjyR5NMltsx9VkrQeU4OfZAdwDLgV2A8cSbJ/1bK/B+6vqhuAw8A/z3pQSdL6DHmEfxOwVFXnquo54D7g0Ko1BbxmfPm1wE9mN6IkaRaGBH83cH7i+ML43KSPArcnuQCcAN5/sRtKcjTJYpLF5eXlNYwrSVqrWb1oewT4XFXtAW4DvpDk1267qo5X1XxVzc/Nzc3oriVJQwwJ/hPA3onjPeNzk+4A7geoqu8CrwJ2zWJASdJsDAn+aWBfkmuTXMHoRdmFVWt+DLwNIMmbGAXf52wk6TIyNfhV9TxwJ3ASeIzRX+OcSXJPkoPjZR8E3pvke8CXgHdXVW3U0JKkl27nkEVVdYLRi7GT5+6euHwWeMtsR5MkzZLvtJWkJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNTEo+EkOJHk8yVKSuy6x5p1JziY5k+SLsx1TkrReO6ctSLIDOAb8GXABOJ1koarOTqzZB/wd8JaqejrJ6zZqYEnS2gx5hH8TsFRV56rqOeA+4NCqNe8FjlXV0wBV9eRsx5QkrdeQ4O8Gzk8cXxifm3QdcF2S7yQ5leTAxW4oydEki0kWl5eX1zaxJGlNZvWi7U5gH3ALcAT4TJKrVy+qquNVNV9V83NzczO6a0nSEEOC/wSwd+J4z/jcpAvAQlX9qqp+CPyA0Q8ASdJlYkjwTwP7klyb5ArgMLCwas3XGD26J8kuRk/xnJvhnJKkdZoa/Kp6HrgTOAk8BtxfVWeS3JPk4HjZSeCpJGeBB4APVdVTGzW0JOmlS1VtyR3Pz8/X4uLilty3JL1cJXm4qubX8rW+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yYEkjydZSnLXi6x7R5JKMj+7ESVJszA1+El2AMeAW4H9wJEk+y+y7irgb4CHZj2kJGn9hjzCvwlYqqpzVfUccB9w6CLrPgZ8HPjFDOeTJM3IkODvBs5PHF8Yn/s/SW4E9lbV11/shpIcTbKYZHF5efklDytJWrt1v2ib5BXAJ4APTltbVcerar6q5ufm5tZ715Kkl2BI8J8A9k4c7xmfe8FVwJuBbyf5EXAzsOALt5J0eRkS/NPAviTXJrkCOAwsvHBlVT1TVbuq6pqqugY4BRysqsUNmViStCZTg19VzwN3AieBx4D7q+pMknuSHNzoASVJs7FzyKKqOgGcWHXu7kusvWX9Y0mSZs132kpSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmhgU/CQHkjyeZCnJXRe5/gNJziZ5NMk3k7xx9qNKktZjavCT7ACOAbcC+4EjSfavWvYIMF9VfwB8FfiHWQ8qSVqfIY/wbwKWqupcVT0H3AccmlxQVQ9U1bPjw1PAntmOKUlaryHB3w2cnzi+MD53KXcA37jYFUmOJllMsri8vDx8SknSus30RdsktwPzwL0Xu76qjlfVfFXNz83NzfKuJUlT7Byw5glg78TxnvG5/yfJ24EPA2+tql/OZjxJ0qwMeYR/GtiX5NokVwCHgYXJBUluAD4NHKyqJ2c/piRpvaYGv6qeB+4ETgKPAfdX1Zkk9yQ5OF52L/Bq4CtJ/j3JwiVuTpK0RYY8pUNVnQBOrDp398Tlt894LknSjPlOW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpoYFPwkB5I8nmQpyV0Xuf43knx5fP1DSa6Z9aCSpPWZGvwkO4BjwK3AfuBIkv2rlt0BPF1Vvwv8E/DxWQ8qSVqfIY/wbwKWqupcVT0H3AccWrXmEPBv48tfBd6WJLMbU5K0XjsHrNkNnJ84vgD80aXWVNXzSZ4Bfhv42eSiJEeBo+PDXyb5/lqG3oZ2sWqvGnMvVrgXK9yLFb+31i8cEvyZqarjwHGAJItVNb+Z93+5ci9WuBcr3IsV7sWKJItr/dohT+k8AeydON4zPnfRNUl2Aq8FnlrrUJKk2RsS/NPAviTXJrkCOAwsrFqzAPzl+PJfAN+qqprdmJKk9Zr6lM74Ofk7gZPADuCzVXUmyT3AYlUtAP8KfCHJEvBzRj8Upjm+jrm3G/dihXuxwr1Y4V6sWPNexAfiktSD77SVpCYMviQ1seHB92MZVgzYiw8kOZvk0STfTPLGrZhzM0zbi4l170hSSbbtn+QN2Ysk7xx/b5xJ8sXNnnGzDPg/8oYkDyR5ZPz/5LatmHOjJflskicv9V6ljHxyvE+PJrlx0A1X1Yb9Y/Qi738AvwNcAXwP2L9qzV8BnxpfPgx8eSNn2qp/A/fiT4HfHF9+X+e9GK+7CngQOAXMb/XcW/h9sQ94BPit8fHrtnruLdyL48D7xpf3Az/a6rk3aC/+BLgR+P4lrr8N+AYQ4GbgoSG3u9GP8P1YhhVT96KqHqiqZ8eHpxi952E7GvJ9AfAxRp/L9IvNHG6TDdmL9wLHquppgKp6cpNn3CxD9qKA14wvvxb4ySbOt2mq6kFGf/F4KYeAz9fIKeDqJK+fdrsbHfyLfSzD7kutqarngRc+lmG7GbIXk+5g9BN8O5q6F+NfUfdW1dc3c7AtMOT74jrguiTfSXIqyYFNm25zDdmLjwK3J7kAnADevzmjXXZeak+ATf5oBQ2T5HZgHnjrVs+yFZK8AvgE8O4tHuVysZPR0zq3MPqt78Ekv19V/7WlU22NI8Dnquofk/wxo/f/vLmq/merB3s52OhH+H4sw4ohe0GStwMfBg5W1S83abbNNm0vrgLeDHw7yY8YPUe5sE1fuB3yfXEBWKiqX1XVD4EfMPoBsN0M2Ys7gPsBquq7wKsYfbBaN4N6stpGB9+PZVgxdS+S3AB8mlHst+vztDBlL6rqmaraVVXXVNU1jF7POFhVa/7QqMvYkP8jX2P06J4kuxg9xXNuM4fcJEP24sfA2wCSvIlR8Jc3dcrLwwLwrvFf69wMPFNVP532RRv6lE5t3McyvOwM3It7gVcDXxm/bv3jqjq4ZUNvkIF70cLAvTgJ/HmSs8B/Ax+qqm33W/DAvfgg8Jkkf8voBdx3b8cHiEm+xOiH/K7x6xUfAV4JUFWfYvT6xW3AEvAs8J5Bt7sN90qSdBG+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElq4n8BzPZcum6w2goAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 9.96773457e-01 -3.22654333e-04]\n",
            " [-1.98948493e-02  9.98010515e-01]] \n",
            " bias : \n",
            " [[0.99677346]\n",
            " [0.98010515]]\n",
            "//////////// end of iteration\n",
            "epoch : 1 \n",
            " weights : \n",
            "[[ 9.96773457e-01 -3.22654333e-04]\n",
            " [-1.98948493e-02  9.98010515e-01]] \n",
            " bias : \n",
            " [[0.99677346]\n",
            " [0.98010515]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.9444128  -0.04734899]\n",
            " [-0.20399622  0.82623668]] \n",
            " bias : \n",
            " [[0.9368899 ]\n",
            " [0.76839589]]\n",
            "\n",
            " Loss : [[0.03360065]\n",
            " [0.32632167]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 9.94687172e-01 -5.31282811e-04]\n",
            " [-4.18114512e-02  9.95818855e-01]] \n",
            " bias : \n",
            " [[0.99468717]\n",
            " [0.95818855]]\n",
            "//////////// end of iteration\n",
            "epoch : 2 \n",
            " weights : \n",
            "[[ 9.94687172e-01 -5.31282811e-04]\n",
            " [-4.18114512e-02  9.95818855e-01]] \n",
            " bias : \n",
            " [[0.99468717]\n",
            " [0.95818855]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.91527209 -0.07217096]\n",
            " [-0.3299939   0.71891226]] \n",
            " bias : \n",
            " [[0.90380542]\n",
            " [0.62534629]]\n",
            "\n",
            " Loss : [[0.0312054 ]\n",
            " [0.28884008]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 9.94468717e-01 -5.53128341e-04]\n",
            " [-6.45719535e-02  9.93542805e-01]] \n",
            " bias : \n",
            " [[0.99446872]\n",
            " [0.93542805]]\n",
            "//////////// end of iteration\n",
            "epoch : 3 \n",
            " weights : \n",
            "[[ 9.94468717e-01 -5.53128341e-04]\n",
            " [-6.45719535e-02  9.93542805e-01]] \n",
            " bias : \n",
            " [[0.99446872]\n",
            " [0.93542805]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.88565015 -0.09740284]\n",
            " [-0.46906112  0.60045525]] \n",
            " bias : \n",
            " [[0.87017458]\n",
            " [0.46745836]]\n",
            "\n",
            " Loss : [[0.02872255]\n",
            " [0.24192256]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 9.96726257e-01 -3.27374330e-04]\n",
            " [-8.67105350e-02  9.91328947e-01]] \n",
            " bias : \n",
            " [[0.99672626]\n",
            " [0.91328947]]\n",
            "//////////// end of iteration\n",
            "epoch : 4 \n",
            " weights : \n",
            "[[ 9.96726257e-01 -3.27374330e-04]\n",
            " [-8.67105350e-02  9.91328947e-01]] \n",
            " bias : \n",
            " [[0.99672626]\n",
            " [0.91328947]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.85569664 -0.12291714]\n",
            " [-0.61287141  0.47795811]] \n",
            " bias : \n",
            " [[0.8361673 ]\n",
            " [0.30418547]]\n",
            "\n",
            " Loss : [[0.02617565]\n",
            " [0.18824551]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 1.00162942e+00  1.62942119e-04]\n",
            " [-1.05964058e-01  9.89403594e-01]] \n",
            " bias : \n",
            " [[1.00162942]\n",
            " [0.89403594]]\n",
            "//////////// end of iteration\n",
            "epoch : 5 \n",
            " weights : \n",
            "[[ 1.00162942e+00  1.62942119e-04]\n",
            " [-1.05964058e-01  9.89403594e-01]] \n",
            " bias : \n",
            " [[1.00162942]\n",
            " [0.89403594]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.82559415 -0.14855834]\n",
            " [-0.74747374  0.36330428]] \n",
            " bias : \n",
            " [[0.80199088]\n",
            " [0.15136669]]\n",
            "\n",
            " Loss : [[0.02359283]\n",
            " [0.13556533]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 1.00837558e+00  8.37558136e-04]\n",
            " [-1.20187957e-01  9.87981204e-01]] \n",
            " bias : \n",
            " [[1.00837558]\n",
            " [0.87981204]]\n",
            "//////////// end of iteration\n",
            "epoch : 6 \n",
            " weights : \n",
            "[[ 1.00837558e+00  8.37558136e-04]\n",
            " [-1.20187957e-01  9.87981204e-01]] \n",
            " bias : \n",
            " [[1.00837558]\n",
            " [0.87981204]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.79555792 -0.1741431 ]\n",
            " [-0.86057091  0.26696848]] \n",
            " bias : \n",
            " [[0.76788969]\n",
            " [0.02296349]]\n",
            "\n",
            " Loss : [[0.02100837]\n",
            " [0.09316459]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 1.01540577  0.00154058]\n",
            " [-0.12888148  0.98711185]] \n",
            " bias : \n",
            " [[1.01540577]\n",
            " [0.87111852]]\n",
            "//////////// end of iteration\n",
            "epoch : 7 \n",
            " weights : \n",
            "[[ 1.01540577  0.00154058]\n",
            " [-0.12888148  0.98711185]] \n",
            " bias : \n",
            " [[1.01540577]\n",
            " [0.87111852]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.76583186 -0.19946367]\n",
            " [-0.94913838  0.191527  ]] \n",
            " bias : \n",
            " [[ 0.73414064]\n",
            " [-0.07759029]]\n",
            "\n",
            " Loss : [[0.0184617 ]\n",
            " [0.06458942]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 1.02152557  0.00215256]\n",
            " [-0.13329582  0.98667042]] \n",
            " bias : \n",
            " [[1.02152557]\n",
            " [0.86670418]]\n",
            "//////////// end of iteration\n",
            "epoch : 8 \n",
            " weights : \n",
            "[[ 1.02152557  0.00215256]\n",
            " [-0.13329582  0.98667042]] \n",
            " bias : \n",
            " [[1.02152557]\n",
            " [0.86670418]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.73668083 -0.22429442]\n",
            " [-1.01762179  0.13319305]] \n",
            " bias : \n",
            " [[ 0.70104446]\n",
            " [-0.15534192]]\n",
            "\n",
            " Loss : [[0.01599539]\n",
            " [0.04697178]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 1.02644676  0.00264468]\n",
            " [-0.13504728  0.98649527]] \n",
            " bias : \n",
            " [[1.02644676]\n",
            " [0.86495272]]\n",
            "//////////// end of iteration\n",
            "epoch : 9 \n",
            " weights : \n",
            "[[ 1.02644676  0.00264468]\n",
            " [-0.13504728  0.98649527]] \n",
            " bias : \n",
            " [[1.02644676]\n",
            " [0.86495272]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.70837938 -0.24840151]\n",
            " [-1.0718726   0.08698238]] \n",
            " bias : \n",
            " [[ 0.66891282]\n",
            " [-0.21693478]]\n",
            "\n",
            " Loss : [[0.0136523 ]\n",
            " [0.03605603]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 1.03037865  0.00303786]\n",
            " [-0.13525816  0.98647418]] \n",
            " bias : \n",
            " [[1.03037865]\n",
            " [0.86474184]]\n",
            "//////////// end of iteration\n",
            "epoch : 10 \n",
            " weights : \n",
            "[[ 1.03037865  0.00303786]\n",
            " [-0.13525816  0.98647418]] \n",
            " bias : \n",
            " [[1.03037865]\n",
            " [0.86474184]]\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQubaoFw1mqb"
      },
      "source": [
        "General multilayer example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lz6ya3lL1gzN",
        "outputId": "4f9dd2a8-ad8e-43e8-ef0e-533b854841e6"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[1, 0.1]]\r\n",
        "Y = [0.6,0.01]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X=X.T\r\n",
        "print(np.shape(X))\r\n",
        "Y = np.reshape(Y, (2, 1))\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = 1\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.002\r\n",
        "\r\n",
        "n_input = 1\r\n",
        "n_classes = 2\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "weights = {'h1': np.random.random((5,2)),\r\n",
        "             'h2': np.random.random((2,5))}\r\n",
        "biases = {'b1': np.random.random((5,1)),\r\n",
        "           'b2': np.random.random((2,1))}\r\n",
        "\r\n",
        "Layer1 = Linear(X, weights['h1'], biases['b1'], 'sigmoid')\r\n",
        "\r\n",
        "Layer2 = Linear(Layer1.output(), weights['h2'], biases['b2'], 'sigmoid')\r\n",
        "\r\n",
        "my_Model = Model([Layer1,Layer2])\r\n",
        "\r\n",
        "my_Loss = my_Model.Loss(Y, Layer2.output()).MSE()\r\n",
        "opt = my_Model.Optimization(10, my_Loss,learning_rate,epsilon).GradientDescent()\r\n",
        "\r\n",
        "print(\"opa\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 1)\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.60569522  0.75842765  0.96111547  0.26258305  0.43562751]\n",
            " [ 0.8532573   0.18888881  0.03572386 -0.00132453  0.80534751]] \n",
            " bias : \n",
            " [[ 0.84054922]\n",
            " [-0.10392533]]\n",
            "\n",
            " Loss : [[0.06417303]\n",
            " [0.35686483]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.56801941 0.21317804]\n",
            " [0.64466149 0.22152296]\n",
            " [0.18488753 0.90241226]\n",
            " [0.95511604 0.71712209]\n",
            " [0.87595755 0.12591479]] \n",
            " bias : \n",
            " [[0.68106517]\n",
            " [0.49917227]\n",
            " [0.28217334]\n",
            " [0.87316066]\n",
            " [0.30688493]]\n",
            "//////////// end of iteration\n",
            "epoch : 1 \n",
            " weights : \n",
            "[[0.56801941 0.21317804]\n",
            " [0.64466149 0.22152296]\n",
            " [0.18488753 0.90241226]\n",
            " [0.95511604 0.71712209]\n",
            " [0.87595755 0.12591479]] \n",
            " bias : \n",
            " [[0.68106517]\n",
            " [0.49917227]\n",
            " [0.28217334]\n",
            " [0.87316066]\n",
            " [0.30688493]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.59381584  0.74687948  0.95147701  0.24944593  0.42394488]\n",
            " [ 0.74501141  0.08366099 -0.05210255 -0.12103099  0.69889451]] \n",
            " bias : \n",
            " [[ 0.82545314]\n",
            " [-0.24148207]]\n",
            "\n",
            " Loss : [[0.06333915]\n",
            " [0.30831505]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.54636703 0.2110128 ]\n",
            " [0.63788115 0.22084492]\n",
            " [0.18039008 0.90196251]\n",
            " [0.95468801 0.71707929]\n",
            " [0.85502916 0.12382196]] \n",
            " bias : \n",
            " [[0.6594128 ]\n",
            " [0.49239193]\n",
            " [0.2776759 ]\n",
            " [0.87273263]\n",
            " [0.28595655]]\n",
            "//////////// end of iteration\n",
            "epoch : 2 \n",
            " weights : \n",
            "[[0.54636703 0.2110128 ]\n",
            " [0.63788115 0.22084492]\n",
            " [0.18039008 0.90196251]\n",
            " [0.95468801 0.71707929]\n",
            " [0.85502916 0.12382196]] \n",
            " bias : \n",
            " [[0.6594128 ]\n",
            " [0.49239193]\n",
            " [0.2776759 ]\n",
            " [0.87273263]\n",
            " [0.28595655]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.5813532   0.73476433  0.94136533  0.23566381  0.41168867]\n",
            " [ 0.61338671 -0.0442938  -0.1588976  -0.2665915   0.56944994]] \n",
            " bias : \n",
            " [[ 0.80961587]\n",
            " [-0.40874814]]\n",
            "\n",
            " Loss : [[0.06241913]\n",
            " [0.23278957]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.52287042 0.20866314]\n",
            " [0.6331704  0.22037385]\n",
            " [0.17891527 0.90181503]\n",
            " [0.95653334 0.71726382]\n",
            " [0.83248978 0.12156802]] \n",
            " bias : \n",
            " [[0.63591618]\n",
            " [0.48768118]\n",
            " [0.27620108]\n",
            " [0.87457796]\n",
            " [0.26341716]]\n",
            "//////////// end of iteration\n",
            "epoch : 3 \n",
            " weights : \n",
            "[[0.52287042 0.20866314]\n",
            " [0.6331704  0.22037385]\n",
            " [0.17891527 0.90181503]\n",
            " [0.95653334 0.71726382]\n",
            " [0.83248978 0.12156802]] \n",
            " bias : \n",
            " [[0.63591618]\n",
            " [0.48768118]\n",
            " [0.27620108]\n",
            " [0.87457796]\n",
            " [0.26341716]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.56825834  0.72203458  0.93074068  0.22118253  0.39881071]\n",
            " [ 0.47987698 -0.17408107 -0.26722208 -0.41423661  0.43815156]] \n",
            " bias : \n",
            " [[ 0.79297519]\n",
            " [-0.57840966]]\n",
            "\n",
            " Loss : [[0.06140657]\n",
            " [0.13873634]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.5024155  0.20661765]\n",
            " [0.63230655 0.22028746]\n",
            " [0.18153882 0.90207739]\n",
            " [0.96119886 0.71773037]\n",
            " [0.81318196 0.11963723]] \n",
            " bias : \n",
            " [[0.61546126]\n",
            " [0.48681734]\n",
            " [0.27882463]\n",
            " [0.87924348]\n",
            " [0.24410934]]\n",
            "//////////// end of iteration\n",
            "epoch : 4 \n",
            " weights : \n",
            "[[0.5024155  0.20661765]\n",
            " [0.63230655 0.22028746]\n",
            " [0.18153882 0.90207739]\n",
            " [0.96119886 0.71773037]\n",
            " [0.81318196 0.11963723]] \n",
            " bias : \n",
            " [[0.61546126]\n",
            " [0.48681734]\n",
            " [0.27882463]\n",
            " [0.87924348]\n",
            " [0.24410934]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.5544769   0.70863738  0.91955896  0.20594197  0.38525752]\n",
            " [ 0.38309754 -0.26816215 -0.34574507 -0.5212626   0.34297509]] \n",
            " bias : \n",
            " [[ 0.775462  ]\n",
            " [-0.70139506]]\n",
            "\n",
            " Loss : [[0.06028879]\n",
            " [0.06532551]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.48974301 0.2053504 ]\n",
            " [0.63391473 0.22044828]\n",
            " [0.18538124 0.90246163]\n",
            " [0.96647841 0.71825833]\n",
            " [0.80160182 0.11847922]] \n",
            " bias : \n",
            " [[0.60278877]\n",
            " [0.48842552]\n",
            " [0.28266706]\n",
            " [0.88452303]\n",
            " [0.2325292 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 5 \n",
            " weights : \n",
            "[[0.48974301 0.2053504 ]\n",
            " [0.63391473 0.22044828]\n",
            " [0.18538124 0.90246163]\n",
            " [0.96647841 0.71825833]\n",
            " [0.80160182 0.11847922]] \n",
            " bias : \n",
            " [[0.60278877]\n",
            " [0.48842552]\n",
            " [0.28266706]\n",
            " [0.88452303]\n",
            " [0.2325292 ]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.53994922  0.69451475  0.90777178  0.18987617  0.37097047]\n",
            " [ 0.32753697 -0.32217361 -0.39082471 -0.58270568  0.28833478]] \n",
            " bias : \n",
            " [[ 0.75700051]\n",
            " [-0.77200035]]\n",
            "\n",
            " Loss : [[0.05905105]\n",
            " [0.032818  ]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.48280265 0.20465636]\n",
            " [0.63498658 0.22055547]\n",
            " [0.18710236 0.90263374]\n",
            " [0.97015081 0.71862557]\n",
            " [0.79557429 0.11787647]] \n",
            " bias : \n",
            " [[0.59584842]\n",
            " [0.48949737]\n",
            " [0.28438818]\n",
            " [0.88819543]\n",
            " [0.22650167]]\n",
            "//////////// end of iteration\n",
            "epoch : 6 \n",
            " weights : \n",
            "[[0.48280265 0.20465636]\n",
            " [0.63498658 0.22055547]\n",
            " [0.18710236 0.90263374]\n",
            " [0.97015081 0.71862557]\n",
            " [0.79557429 0.11787647]] \n",
            " bias : \n",
            " [[0.59584842]\n",
            " [0.48949737]\n",
            " [0.28438818]\n",
            " [0.88819543]\n",
            " [0.22650167]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.52461023  0.67960344  0.89532634  0.17291316  0.35588555]\n",
            " [ 0.29349463 -0.35526678 -0.41844531 -0.62035225  0.25485629]] \n",
            " bias : \n",
            " [[ 0.73750803]\n",
            " [-0.81526067]]\n",
            "\n",
            " Loss : [[0.05767628]\n",
            " [0.02104196]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.47817364 0.20419346]\n",
            " [0.63505969 0.22056278]\n",
            " [0.18692023 0.90261553]\n",
            " [0.97253092 0.71886358]\n",
            " [0.79176114 0.11749515]] \n",
            " bias : \n",
            " [[0.5912194 ]\n",
            " [0.48957047]\n",
            " [0.28420605]\n",
            " [0.89057554]\n",
            " [0.22268852]]\n",
            "//////////// end of iteration\n",
            "epoch : 7 \n",
            " weights : \n",
            "[[0.47817364 0.20419346]\n",
            " [0.63505969 0.22056278]\n",
            " [0.18692023 0.90261553]\n",
            " [0.97253092 0.71886358]\n",
            " [0.79176114 0.11749515]] \n",
            " bias : \n",
            " [[0.5912194 ]\n",
            " [0.48957047]\n",
            " [0.28420605]\n",
            " [0.89057554]\n",
            " [0.22268852]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.50838958  0.66383505  0.88216555  0.15497514  0.33993356]\n",
            " [ 0.26889432 -0.3791812  -0.43840502 -0.64755713  0.23066344]] \n",
            " bias : \n",
            " [[ 0.71689514]\n",
            " [-0.84652226]]\n",
            "\n",
            " Loss : [[0.0561448 ]\n",
            " [0.01576592]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.47440926 0.20381702]\n",
            " [0.63452864 0.22050967]\n",
            " [0.18567726 0.90249123]\n",
            " [0.97427643 0.71903813]\n",
            " [0.78878899 0.11719794]] \n",
            " bias : \n",
            " [[0.58745502]\n",
            " [0.48903943]\n",
            " [0.28296308]\n",
            " [0.89232105]\n",
            " [0.21971637]]\n",
            "//////////// end of iteration\n",
            "epoch : 8 \n",
            " weights : \n",
            "[[0.47440926 0.20381702]\n",
            " [0.63452864 0.22050967]\n",
            " [0.18567726 0.90249123]\n",
            " [0.97427643 0.71903813]\n",
            " [0.78878899 0.11719794]] \n",
            " bias : \n",
            " [[0.58745502]\n",
            " [0.48903943]\n",
            " [0.28296308]\n",
            " [0.89232105]\n",
            " [0.21971637]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.4912122   0.6471366   0.8682285   0.1359791   0.32304069]\n",
            " [ 0.24923357 -0.39829378 -0.45435697 -0.66929947  0.21132834]] \n",
            " bias : \n",
            " [[ 0.69506647]\n",
            " [-0.87150675]]\n",
            "\n",
            " Loss : [[0.05443408]\n",
            " [0.01270343]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.47104155 0.20348025]\n",
            " [0.63361019 0.22041783]\n",
            " [0.18375549 0.90229905]\n",
            " [0.97568378 0.71917886]\n",
            " [0.78622131 0.11694117]] \n",
            " bias : \n",
            " [[0.58408731]\n",
            " [0.48812097]\n",
            " [0.2810413 ]\n",
            " [0.8937284 ]\n",
            " [0.21714869]]\n",
            "//////////// end of iteration\n",
            "epoch : 9 \n",
            " weights : \n",
            "[[0.47104155 0.20348025]\n",
            " [0.63361019 0.22041783]\n",
            " [0.18375549 0.90229905]\n",
            " [0.97568378 0.71917886]\n",
            " [0.78622131 0.11694117]] \n",
            " bias : \n",
            " [[0.58408731]\n",
            " [0.48812097]\n",
            " [0.2810413 ]\n",
            " [0.8937284 ]\n",
            " [0.21714869]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.47299971  0.62943191  0.85345162  0.11583836  0.30512986]\n",
            " [ 0.23272754 -0.41433959 -0.46774931 -0.68755308  0.1950957 ]] \n",
            " bias : \n",
            " [[ 0.6719224 ]\n",
            " [-0.89248229]]\n",
            "\n",
            " Loss : [[0.05251865]\n",
            " [0.01064325]]\n",
            "alpha :  1\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.46789382 0.20316548]\n",
            " [0.63239657 0.22029647]\n",
            " [0.18130789 0.90205429]\n",
            " [0.97687916 0.7192984 ]\n",
            " [0.78389617 0.11670866]] \n",
            " bias : \n",
            " [[0.58093959]\n",
            " [0.48690736]\n",
            " [0.2785937 ]\n",
            " [0.89492378]\n",
            " [0.21482355]]\n",
            "//////////// end of iteration\n",
            "epoch : 10 \n",
            " weights : \n",
            "[[0.46789382 0.20316548]\n",
            " [0.63239657 0.22029647]\n",
            " [0.18130789 0.90205429]\n",
            " [0.97687916 0.7192984 ]\n",
            " [0.78389617 0.11670866]] \n",
            " bias : \n",
            " [[0.58093959]\n",
            " [0.48690736]\n",
            " [0.2785937 ]\n",
            " [0.89492378]\n",
            " [0.21482355]]\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsE-Y6W14Yh"
      },
      "source": [
        "General multiclass example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q_FuPw_x187c",
        "outputId": "f4a846bd-2f08-492c-e160-122b7a488da6"
      },
      "source": [
        "from Model import *\r\n",
        "\r\n",
        "X = [[-1, -1], [1, -1], [-1, 1], [1, 1],[1, 1],[1, 1]]\r\n",
        "Y = [[1, 1, 1, -1 , 1 , -1]]\r\n",
        "X = np.array(X).reshape(len(X), -1)\r\n",
        "X = X.T\r\n",
        "print(np.shape(X))\r\n",
        "Y = np.reshape(Y, (1, 6))\r\n",
        "\r\n",
        "print(f'X : {X}')\r\n",
        "print(f'Y : {Y}')\r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = [0.1, True]\r\n",
        "training_epochs = 20\r\n",
        "epsilon = 0.0000002\r\n",
        "\r\n",
        "# Network Parameters\r\n",
        "# n_hidden_1 = 1  # 1st layer number of neurons\r\n",
        "# n_hidden_2 = 256  # 2nd layer number of neurons\r\n",
        "n_input = 4  # MNIST data input (img shape: 28*28)\r\n",
        "n_classes = 1  # MNIST total classes (0-9 digits)\r\n",
        "\r\n",
        "# Store layers weight & bias\r\n",
        "# weights = {\r\n",
        "#     'h1': np.zeros((n_classes,2))\r\n",
        "#     # 'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\r\n",
        "#     # 'out': (np.random.rand(n_hidden_1, n_classes))\r\n",
        "#     }\r\n",
        "#\r\n",
        "# biases = {\r\n",
        "#     'b1': np.zeros((n_classes,1))\r\n",
        "#     # 'b2': tf.Variable(tf.random_normal([n_hidden_2])),\r\n",
        "#     # 'out': (np.random.rand(n_classes))\r\n",
        "# }\r\n",
        "# print(f'bias : {biases}')\r\n",
        "# print(f'weights : {weights}')\r\n",
        "\r\n",
        "# w1 = np.random.random((3,4))\r\n",
        "w2 = np.random.random((2, 2))\r\n",
        "w3 = np.random.random((2, 2))\r\n",
        "w30 = np.random.random((2, 2))\r\n",
        "w31 = np.random.random((2, 2))\r\n",
        "w32 = np.random.random((2, 2))\r\n",
        "w4 = np.random.random((1, 2))\r\n",
        "\r\n",
        "# b1 = np.random.random((4,1))\r\n",
        "b2 = np.random.random((2, 1))\r\n",
        "b3 = np.random.random((2, 1))\r\n",
        "b30 = np.random.random((2, 1))\r\n",
        "b31 = np.random.random((2, 1))\r\n",
        "b32 = np.random.random((2, 1))\r\n",
        "b4 = np.random.random((1, 1))\r\n",
        "\r\n",
        "# Layer1 = Linear(X, w1, b1, 'sigmoid')\r\n",
        "Layer2 = Linear(X, w2, b2, 'relu')\r\n",
        "Layer3 = Linear(Layer2.output(), w3, b3, 'relu')\r\n",
        "Layer30 = Linear(Layer3.output(), w30, b30, 'relu')\r\n",
        "Layer31 = Linear(Layer30.output(), w31, b31, 'relu')\r\n",
        "Layer32 = Linear(Layer31.output(), w32, b32, 'relu')\r\n",
        "Layer4 = Linear(Layer32.output(), w4, b4, 'relu')\r\n",
        "my_Model = Model([Layer2, Layer3, Layer4])\r\n",
        "\r\n",
        "# Layer1()\r\n",
        "my_Loss = my_Model.Loss(Y, Layer4.output()).LogisticRegressionIdentity()\r\n",
        "opt = my_Model.Optimization(100, my_Loss, learning_rate, epsilon).GradientDescent()\r\n",
        "my_Model.Evaluate(X, Y, True)\r\n",
        "\r\n",
        "print(\"opa\")\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 6)\n",
            "X : [[-1  1 -1  1  1  1]\n",
            " [-1 -1  1  1  1  1]]\n",
            "Y : [[ 1  1  1 -1  1 -1]]\n",
            "alpha :  0.09836065573770493\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.21165935 0.40332195]] \n",
            " bias : \n",
            " [[0.81669011]]\n",
            "\n",
            " Loss : [[1.78077824]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "alpha :  0.09677419354838711\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.76088564 0.83598952]\n",
            " [0.02688208 0.76593381]] \n",
            " bias : \n",
            " [[0.93712285]\n",
            " [0.80542924]]\n",
            "alpha :  0.09523809523809525\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82642935 0.90297497]\n",
            " [0.86933288 0.38880921]] \n",
            " bias : \n",
            " [[0.95934316]\n",
            " [0.53906375]]\n",
            "//////////// end of iteration\n",
            "epoch : 1 \n",
            " weights : \n",
            "[[0.82642935 0.90297497]\n",
            " [0.86933288 0.38880921]] \n",
            " bias : \n",
            " [[0.95934316]\n",
            " [0.53906375]]\n",
            "alpha :  0.09230769230769231\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.08132967 0.25008997]] \n",
            " bias : \n",
            " [[0.78737366]]\n",
            "\n",
            " Loss : [[1.31587325]]\n",
            "alpha :  0.08955223880597016\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74396494  0.82433284]\n",
            " [-0.00536071  0.74372172]] \n",
            " bias : \n",
            " [[0.93110298]\n",
            " [0.79395823]]\n",
            "alpha :  0.08695652173913043\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82145768 0.89805662]\n",
            " [0.85528003 0.37490709]] \n",
            " bias : \n",
            " [[0.95450067]\n",
            " [0.52537607]]\n",
            "//////////// end of iteration\n",
            "epoch : 2 \n",
            " weights : \n",
            "[[0.82145768 0.89805662]\n",
            " [0.85528003 0.37490709]] \n",
            " bias : \n",
            " [[0.95450067]\n",
            " [0.52537607]]\n",
            "alpha :  0.08333333333333333\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.02890506  0.12013296]] \n",
            " bias : \n",
            " [[0.76314602]]\n",
            "\n",
            " Loss : [[0.92739613]]\n",
            "alpha :  0.07999999999999999\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.73837486  0.82046916]\n",
            " [-0.0225503   0.73184086]] \n",
            " bias : \n",
            " [[0.92921137]\n",
            " [0.7881415 ]]\n",
            "alpha :  0.07692307692307691\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8199754  0.89660278]\n",
            " [0.84894064 0.36868933]] \n",
            " bias : \n",
            " [[0.95311518]\n",
            " [0.51945058]]\n",
            "//////////// end of iteration\n",
            "epoch : 3 \n",
            " weights : \n",
            "[[0.8199754  0.89660278]\n",
            " [0.84894064 0.36868933]] \n",
            " bias : \n",
            " [[0.95311518]\n",
            " [0.51945058]]\n",
            "alpha :  0.07317073170731705\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10808618  0.02610346]] \n",
            " bias : \n",
            " [[0.74684711]]\n",
            "\n",
            " Loss : [[0.69196508]]\n",
            "alpha :  0.0697674418604651\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.73989517  0.82152683]\n",
            " [-0.02886889  0.72744509]] \n",
            " bias : \n",
            " [[0.92966058]\n",
            " [0.78627454]]\n",
            "alpha :  0.06666666666666665\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82045106 0.8970662 ]\n",
            " [0.84767095 0.36745232]] \n",
            " bias : \n",
            " [[0.95351529]\n",
            " [0.51838255]]\n",
            "//////////// end of iteration\n",
            "epoch : 4 \n",
            " weights : \n",
            "[[0.82045106 0.8970662 ]\n",
            " [0.84767095 0.36745232]] \n",
            " bias : \n",
            " [[0.95351529]\n",
            " [0.51838255]]\n",
            "alpha :  0.0631578947368421\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.14615671 -0.02028441]] \n",
            " bias : \n",
            " [[0.7409167]]\n",
            "\n",
            " Loss : [[0.6247726]]\n",
            "alpha :  0.05999999999999999\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74328664  0.82392019]\n",
            " [-0.02968795  0.72686708]] \n",
            " bias : \n",
            " [[0.93026952]\n",
            " [0.78612747]]\n",
            "alpha :  0.057142857142857134\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82148583 0.89808253]\n",
            " [0.84856576 0.36833118]] \n",
            " bias : \n",
            " [[0.9541537 ]\n",
            " [0.51893461]]\n",
            "//////////// end of iteration\n",
            "epoch : 5 \n",
            " weights : \n",
            "[[0.82148583 0.89808253]\n",
            " [0.84856576 0.36833118]] \n",
            " bias : \n",
            " [[0.9541537 ]\n",
            " [0.51893461]]\n",
            "alpha :  0.05405405405405404\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.11683135  0.01203027]] \n",
            " bias : \n",
            " [[0.75101392]]\n",
            "\n",
            " Loss : [[0.63422252]]\n",
            "alpha :  0.05128205128205128\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74237424  0.82338515]\n",
            " [-0.02981458  0.72679282]] \n",
            " bias : \n",
            " [[0.92886943]\n",
            " [0.78593316]]\n",
            "alpha :  0.048780487804878044\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82147821 0.89809016]\n",
            " [0.84855622 0.36834072]] \n",
            " bias : \n",
            " [[0.95349121]\n",
            " [0.51810575]]\n",
            "//////////// end of iteration\n",
            "epoch : 6 \n",
            " weights : \n",
            "[[0.82147821 0.89809016]\n",
            " [0.84855622 0.36834072]] \n",
            " bias : \n",
            " [[0.95349121]\n",
            " [0.51810575]]\n",
            "alpha :  0.04615384615384615\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10430171  0.02464372]] \n",
            " bias : \n",
            " [[0.75725839]]\n",
            "\n",
            " Loss : [[0.62387763]]\n",
            "alpha :  0.0437956204379562\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74279769  0.82374519]\n",
            " [-0.02985818  0.72675575]] \n",
            " bias : \n",
            " [[0.92817715]\n",
            " [0.78600445]]\n",
            "alpha :  0.04166666666666666\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82176774 0.89840542]\n",
            " [0.84884696 0.3686573 ]] \n",
            " bias : \n",
            " [[0.95325417]\n",
            " [0.51786772]]\n",
            "//////////// end of iteration\n",
            "epoch : 7 \n",
            " weights : \n",
            "[[0.82176774 0.89840542]\n",
            " [0.84884696 0.3686573 ]] \n",
            " bias : \n",
            " [[0.95325417]\n",
            " [0.51786772]]\n",
            "alpha :  0.03947368421052631\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10284058  0.02476168]] \n",
            " bias : \n",
            " [[0.76017526]]\n",
            "\n",
            " Loss : [[0.62428911]]\n",
            "alpha :  0.03749999999999999\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.7435839   0.82433439]\n",
            " [-0.03004394  0.72661653]] \n",
            " bias : \n",
            " [[0.92788813]\n",
            " [0.78607273]]\n",
            "alpha :  0.035714285714285705\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8220993  0.89874821]\n",
            " [0.84913526 0.36895537]] \n",
            " bias : \n",
            " [[0.95322438]\n",
            " [0.51784182]]\n",
            "//////////// end of iteration\n",
            "epoch : 8 \n",
            " weights : \n",
            "[[0.8220993  0.89874821]\n",
            " [0.84913526 0.36895537]] \n",
            " bias : \n",
            " [[0.95322438]\n",
            " [0.51784182]]\n",
            "alpha :  0.033898305084745756\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10481988  0.02113445]] \n",
            " bias : \n",
            " [[0.76183326]]\n",
            "\n",
            " Loss : [[0.62425357]]\n",
            "alpha :  0.032258064516129024\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74441041  0.82494249]\n",
            " [-0.03024295  0.72647012]] \n",
            " bias : \n",
            " [[0.92772587]\n",
            " [0.7861118 ]]\n",
            "alpha :  0.030769230769230764\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82241892 0.8990745 ]\n",
            " [0.8494117  0.36923758]] \n",
            " bias : \n",
            " [[0.95325185]\n",
            " [0.51786557]]\n",
            "//////////// end of iteration\n",
            "epoch : 9 \n",
            " weights : \n",
            "[[0.82241892 0.8990745 ]\n",
            " [0.8494117  0.36923758]] \n",
            " bias : \n",
            " [[0.95325185]\n",
            " [0.51786557]]\n",
            "alpha :  0.029268292682926824\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10675569  0.01774167]] \n",
            " bias : \n",
            " [[0.7632045]]\n",
            "\n",
            " Loss : [[0.62367844]]\n",
            "alpha :  0.02790697674418604\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74515035  0.82548622]\n",
            " [-0.03039214  0.72636049]] \n",
            " bias : \n",
            " [[0.92758883]\n",
            " [0.78613943]]\n",
            "alpha :  0.026666666666666658\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8227037  0.89936503]\n",
            " [0.84966914 0.36950022]] \n",
            " bias : \n",
            " [[0.95327987]\n",
            " [0.5178909 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 10 \n",
            " weights : \n",
            "[[0.8227037  0.89936503]\n",
            " [0.84966914 0.36950022]] \n",
            " bias : \n",
            " [[0.95327987]\n",
            " [0.5178909 ]]\n",
            "alpha :  0.02542372881355931\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10795872  0.01534679]] \n",
            " bias : \n",
            " [[0.76451999]]\n",
            "\n",
            " Loss : [[0.62324604]]\n",
            "alpha :  0.024291497975708492\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74578139  0.82595129]\n",
            " [-0.03049701  0.7262832 ]] \n",
            " bias : \n",
            " [[0.92745464]\n",
            " [0.78616173]]\n",
            "alpha :  0.02325581395348836\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82295057 0.89961751]\n",
            " [0.84990107 0.36973741]] \n",
            " bias : \n",
            " [[0.95329656]\n",
            " [0.51790658]]\n",
            "//////////// end of iteration\n",
            "epoch : 11 \n",
            " weights : \n",
            "[[0.82295057 0.89961751]\n",
            " [0.84990107 0.36973741]] \n",
            " bias : \n",
            " [[0.95329656]\n",
            " [0.51790658]]\n",
            "alpha :  0.02222222222222221\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1086075   0.01371827]] \n",
            " bias : \n",
            " [[0.76577456]]\n",
            "\n",
            " Loss : [[0.62298289]]\n",
            "alpha :  0.021276595744680837\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74631909  0.82634877]\n",
            " [-0.03057345  0.72622669]] \n",
            " bias : \n",
            " [[0.92732496]\n",
            " [0.78618017]]\n",
            "alpha :  0.020408163265306107\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82316454 0.89983689]\n",
            " [0.85010722 0.36994878]] \n",
            " bias : \n",
            " [[0.95330437]\n",
            " [0.51791411]]\n",
            "//////////// end of iteration\n",
            "epoch : 12 \n",
            " weights : \n",
            "[[0.82316454 0.89983689]\n",
            " [0.85010722 0.36994878]] \n",
            " bias : \n",
            " [[0.95330437]\n",
            " [0.51791411]]\n",
            "alpha :  0.019543973941368066\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10894362  0.01255665]] \n",
            " bias : \n",
            " [[0.7669388]]\n",
            "\n",
            " Loss : [[0.62280825]]\n",
            "alpha :  0.01874999999999999\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74678328  0.82669265]\n",
            " [-0.03063208  0.72618326]] \n",
            " bias : \n",
            " [[0.92720366]\n",
            " [0.78619549]]\n",
            "alpha :  0.018018018018018007\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82335159 0.90002901]\n",
            " [0.85029039 0.37013691]] \n",
            " bias : \n",
            " [[0.9533072 ]\n",
            " [0.51791688]]\n",
            "//////////// end of iteration\n",
            "epoch : 13 \n",
            " weights : \n",
            "[[0.82335159 0.90002901]\n",
            " [0.85029039 0.37013691]] \n",
            " bias : \n",
            " [[0.9533072 ]\n",
            " [0.51791688]]\n",
            "alpha :  0.01729106628242074\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10911476  0.01167473]] \n",
            " bias : \n",
            " [[0.7680015]]\n",
            "\n",
            " Loss : [[0.62267726]]\n",
            "alpha :  0.01662049861495844\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74718922  0.82699378]\n",
            " [-0.03067887  0.72614855]] \n",
            " bias : \n",
            " [[0.92709237]\n",
            " [0.78620832]]\n",
            "alpha :  0.01599999999999999\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82351659 0.90019867]\n",
            " [0.85045377 0.37030492]] \n",
            " bias : \n",
            " [[0.95330749]\n",
            " [0.51791717]]\n",
            "//////////// end of iteration\n",
            "epoch : 14 \n",
            " weights : \n",
            "[[0.82351659 0.90019867]\n",
            " [0.85045377 0.37030492]] \n",
            " bias : \n",
            " [[0.95330749]\n",
            " [0.51791717]]\n",
            "alpha :  0.015384615384615375\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1091969   0.01097107]] \n",
            " bias : \n",
            " [[0.76896511]]\n",
            "\n",
            " Loss : [[0.62257084]]\n",
            "alpha :  0.014814814814814807\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74754781  0.82726001]\n",
            " [-0.03071723  0.72612006]] \n",
            " bias : \n",
            " [[0.92699112]\n",
            " [0.78621915]]\n",
            "alpha :  0.014285714285714278\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82366323 0.90034958]\n",
            " [0.85060019 0.37045559]] \n",
            " bias : \n",
            " [[0.9533065 ]\n",
            " [0.51791618]]\n",
            "//////////// end of iteration\n",
            "epoch : 15 \n",
            " weights : \n",
            "[[0.82366323 0.90034958]\n",
            " [0.85060019 0.37045559]] \n",
            " bias : \n",
            " [[0.9533065 ]\n",
            " [0.51791618]]\n",
            "alpha :  0.013761467889908249\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1092287   0.01038984]] \n",
            " bias : \n",
            " [[0.76983773]]\n",
            "\n",
            " Loss : [[0.62248052]]\n",
            "alpha :  0.013274336283185834\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74786706  0.82749718]\n",
            " [-0.03074931  0.72609624]] \n",
            " bias : \n",
            " [[0.92689921]\n",
            " [0.78622839]]\n",
            "alpha :  0.012820512820512813\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8237944  0.90048463]\n",
            " [0.850732   0.3705913 ]] \n",
            " bias : \n",
            " [[0.95330486]\n",
            " [0.51791453]]\n",
            "//////////// end of iteration\n",
            "epoch : 16 \n",
            " weights : \n",
            "[[0.8237944  0.90048463]\n",
            " [0.850732   0.3705913 ]] \n",
            " bias : \n",
            " [[0.95330486]\n",
            " [0.51791453]]\n",
            "alpha :  0.012371134020618551\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10923087  0.00989789]] \n",
            " bias : \n",
            " [[0.77062894]]\n",
            "\n",
            " Loss : [[0.62240197]]\n",
            "alpha :  0.011952191235059757\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74815314  0.82770978]\n",
            " [-0.03077652  0.72607601]] \n",
            " bias : \n",
            " [[0.92681571]\n",
            " [0.78623633]]\n",
            "alpha :  0.011560693641618493\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82391237 0.90060615]\n",
            " [0.85085117 0.37071405]] \n",
            " bias : \n",
            " [[0.95330291]\n",
            " [0.51791256]]\n",
            "//////////// end of iteration\n",
            "epoch : 17 \n",
            " weights : \n",
            "[[0.82391237 0.90060615]\n",
            " [0.85085117 0.37071405]] \n",
            " bias : \n",
            " [[0.95330291]\n",
            " [0.51791256]]\n",
            "alpha :  0.011173184357541895\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1092152   0.00947399]] \n",
            " bias : \n",
            " [[0.771348]]\n",
            "\n",
            " Loss : [[0.62233262]]\n",
            "alpha :  0.010810810810810804\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74841091  0.8279014 ]\n",
            " [-0.03079988  0.72605865]] \n",
            " bias : \n",
            " [[0.92673972]\n",
            " [0.78624321]]\n",
            "alpha :  0.01047120418848167\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.824019   0.90071601]\n",
            " [0.85095936 0.37082553]] \n",
            " bias : \n",
            " [[0.95330082]\n",
            " [0.51791044]]\n",
            "//////////// end of iteration\n",
            "epoch : 18 \n",
            " weights : \n",
            "[[0.824019   0.90071601]\n",
            " [0.85095936 0.37082553]] \n",
            " bias : \n",
            " [[0.95330082]\n",
            " [0.51791044]]\n",
            "alpha :  0.010135135135135132\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10918876  0.00910365]] \n",
            " bias : \n",
            " [[0.77200335]]\n",
            "\n",
            " Loss : [[0.62227073]]\n",
            "alpha :  0.009819967266775776\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74864432  0.82807496]\n",
            " [-0.03082013  0.72604359]] \n",
            " bias : \n",
            " [[0.92667037]\n",
            " [0.78624923]]\n",
            "alpha :  0.009523809523809523\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82411581 0.90081579]\n",
            " [0.85105795 0.37092714]] \n",
            " bias : \n",
            " [[0.95329869]\n",
            " [0.51790828]]\n",
            "//////////// end of iteration\n",
            "epoch : 19 \n",
            " weights : \n",
            "[[0.82411581 0.90081579]\n",
            " [0.85105795 0.37092714]] \n",
            " bias : \n",
            " [[0.95329869]\n",
            " [0.51790828]]\n",
            "alpha :  0.009230769230769232\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10915591  0.00877651]] \n",
            " bias : \n",
            " [[0.77260242]]\n",
            "\n",
            " Loss : [[0.62221507]]\n",
            "alpha :  0.008955223880597015\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74885664  0.82823286]\n",
            " [-0.03083783  0.72603043]] \n",
            " bias : \n",
            " [[0.92660691]\n",
            " [0.78625452]]\n",
            "alpha :  0.008695652173913044\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82420407 0.90090677]\n",
            " [0.85114813 0.3710201 ]] \n",
            " bias : \n",
            " [[0.9532966 ]\n",
            " [0.51790613]]\n",
            "//////////// end of iteration\n",
            "epoch : 20 \n",
            " weights : \n",
            "[[0.82420407 0.90090677]\n",
            " [0.85114813 0.3710201 ]] \n",
            " bias : \n",
            " [[0.9532966 ]\n",
            " [0.51790613]]\n",
            "alpha :  0.008438818565400843\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10911945  0.00848491]] \n",
            " bias : \n",
            " [[0.7731517]]\n",
            "\n",
            " Loss : [[0.62216469]]\n",
            "alpha :  0.008196721311475409\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74905053  0.82837708]\n",
            " [-0.03085342  0.72601883]] \n",
            " bias : \n",
            " [[0.92654867]\n",
            " [0.7862592 ]]\n",
            "alpha :  0.007968127490039839\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82428484 0.90099004]\n",
            " [0.85123089 0.37110543]] \n",
            " bias : \n",
            " [[0.95329456]\n",
            " [0.51790404]]\n",
            "//////////// end of iteration\n",
            "epoch : 21 \n",
            " weights : \n",
            "[[0.82428484 0.90099004]\n",
            " [0.85123089 0.37110543]] \n",
            " bias : \n",
            " [[0.95329456]\n",
            " [0.51790404]]\n",
            "alpha :  0.007741935483870966\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10908115  0.00822301]] \n",
            " bias : \n",
            " [[0.77365683]]\n",
            "\n",
            " Loss : [[0.62211885]]\n",
            "alpha :  0.007528230865746549\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74922828  0.8285093 ]\n",
            " [-0.03086724  0.72600855]] \n",
            " bias : \n",
            " [[0.92649507]\n",
            " [0.78626337]]\n",
            "alpha :  0.007326007326007326\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82435901 0.90106653]\n",
            " [0.85130708 0.371184  ]] \n",
            " bias : \n",
            " [[0.95329259]\n",
            " [0.51790203]]\n",
            "//////////// end of iteration\n",
            "epoch : 22 \n",
            " weights : \n",
            "[[0.82435901 0.90106653]\n",
            " [0.85130708 0.371184  ]] \n",
            " bias : \n",
            " [[0.95329259]\n",
            " [0.51790203]]\n",
            "alpha :  0.007125890736342043\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1090422   0.00798625]] \n",
            " bias : \n",
            " [[0.77412267]]\n",
            "\n",
            " Loss : [[0.62207695]]\n",
            "alpha :  0.006936416184971099\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74939178  0.82863094]\n",
            " [-0.03087957  0.72599938]] \n",
            " bias : \n",
            " [[0.92644561]\n",
            " [0.7862671 ]]\n",
            "alpha :  0.006756756756756758\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82442735 0.90113701]\n",
            " [0.85137744 0.37125656]] \n",
            " bias : \n",
            " [[0.95329071]\n",
            " [0.51790009]]\n",
            "//////////// end of iteration\n",
            "epoch : 23 \n",
            " weights : \n",
            "[[0.82442735 0.90113701]\n",
            " [0.85137744 0.37125656]] \n",
            " bias : \n",
            " [[0.95329071]\n",
            " [0.51790009]]\n",
            "alpha :  0.006578947368421054\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10900335  0.00777102]] \n",
            " bias : \n",
            " [[0.77455347]]\n",
            "\n",
            " Loss : [[0.6220385]]\n",
            "alpha :  0.006410256410256411\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74954265  0.82874319]\n",
            " [-0.03089062  0.72599116]] \n",
            " bias : \n",
            " [[0.92639984]\n",
            " [0.78627045]]\n",
            "alpha :  0.006250000000000001\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8244905  0.90120215]\n",
            " [0.85144259 0.37132376]] \n",
            " bias : \n",
            " [[0.95328892]\n",
            " [0.51789824]]\n",
            "//////////// end of iteration\n",
            "epoch : 24 \n",
            " weights : \n",
            "[[0.8244905  0.90120215]\n",
            " [0.85144259 0.37132376]] \n",
            " bias : \n",
            " [[0.95328892]\n",
            " [0.51789824]]\n",
            "alpha :  0.006091370558375635\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10896511  0.00757438]] \n",
            " bias : \n",
            " [[0.77495291]]\n",
            "\n",
            " Loss : [[0.62200307]]\n",
            "alpha :  0.0059405940594059415\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74968228  0.82884709]\n",
            " [-0.03090057  0.72598376]] \n",
            " bias : \n",
            " [[0.92635738]\n",
            " [0.78627348]]\n",
            "alpha :  0.005797101449275363\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82454902 0.90126252]\n",
            " [0.85150308 0.37138616]] \n",
            " bias : \n",
            " [[0.95328722]\n",
            " [0.51789648]]\n",
            "//////////// end of iteration\n",
            "epoch : 25 \n",
            " weights : \n",
            "[[0.82454902 0.90126252]\n",
            " [0.85150308 0.37138616]] \n",
            " bias : \n",
            " [[0.95328722]\n",
            " [0.51789648]]\n",
            "alpha :  0.005655042412818097\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10892779  0.00739395]] \n",
            " bias : \n",
            " [[0.77532417]]\n",
            "\n",
            " Loss : [[0.62197033]]\n",
            "alpha :  0.005519779208831648\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74981187  0.82894351]\n",
            " [-0.03090958  0.72597705]] \n",
            " bias : \n",
            " [[0.92631789]\n",
            " [0.78627622]]\n",
            "alpha :  0.005390835579514826\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82460341 0.90131862]\n",
            " [0.85155938 0.37144424]] \n",
            " bias : \n",
            " [[0.9532856 ]\n",
            " [0.51789481]]\n",
            "//////////// end of iteration\n",
            "epoch : 26 \n",
            " weights : \n",
            "[[0.82460341 0.90131862]\n",
            " [0.85155938 0.37144424]] \n",
            " bias : \n",
            " [[0.9532856 ]\n",
            " [0.51789481]]\n",
            "alpha :  0.005263157894736843\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10889158  0.00722774]] \n",
            " bias : \n",
            " [[0.77567006]]\n",
            "\n",
            " Loss : [[0.62193999]]\n",
            "alpha :  0.0051413881748071984\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.74993244  0.82903324]\n",
            " [-0.03091776  0.72597096]] \n",
            " bias : \n",
            " [[0.92628108]\n",
            " [0.78627872]]\n",
            "alpha :  0.0050251256281407045\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82465406 0.90137089]\n",
            " [0.85161191 0.37149844]] \n",
            " bias : \n",
            " [[0.95328407]\n",
            " [0.51789322]]\n",
            "//////////// end of iteration\n",
            "epoch : 27 \n",
            " weights : \n",
            "[[0.82465406 0.90137089]\n",
            " [0.85161191 0.37149844]] \n",
            " bias : \n",
            " [[0.95328407]\n",
            " [0.51789322]]\n",
            "alpha :  0.00490998363338789\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1088566   0.00707408]] \n",
            " bias : \n",
            " [[0.77599303]]\n",
            "\n",
            " Loss : [[0.62191179]]\n",
            "alpha :  0.0048000000000000004\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75004489  0.82911693]\n",
            " [-0.03092523  0.72596541]] \n",
            " bias : \n",
            " [[0.9262467]\n",
            " [0.786281 ]]\n",
            "alpha :  0.004694835680751175\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82470136 0.90141969]\n",
            " [0.85166102 0.37154911]] \n",
            " bias : \n",
            " [[0.95328261]\n",
            " [0.5178917 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 28 \n",
            " weights : \n",
            "[[0.82470136 0.90141969]\n",
            " [0.85166102 0.37154911]] \n",
            " bias : \n",
            " [[0.95328261]\n",
            " [0.5178917 ]]\n",
            "alpha :  0.004590665646518746\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1088229   0.00693158]] \n",
            " bias : \n",
            " [[0.77629524]]\n",
            "\n",
            " Loss : [[0.62188551]]\n",
            "alpha :  0.004491017964071857\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75015002  0.82919516]\n",
            " [-0.03093206  0.72596032]] \n",
            " bias : \n",
            " [[0.92621452]\n",
            " [0.7862831 ]]\n",
            "alpha :  0.0043956043956043965\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82474562 0.90146536]\n",
            " [0.85170704 0.3715966 ]] \n",
            " bias : \n",
            " [[0.95328123]\n",
            " [0.51789027]]\n",
            "//////////// end of iteration\n",
            "epoch : 29 \n",
            " weights : \n",
            "[[0.82474562 0.90146536]\n",
            " [0.85170704 0.3715966 ]] \n",
            " bias : \n",
            " [[0.95328123]\n",
            " [0.51789027]]\n",
            "alpha :  0.004301075268817205\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1087905   0.00679903]] \n",
            " bias : \n",
            " [[0.77657858]]\n",
            "\n",
            " Loss : [[0.62186096]]\n",
            "alpha :  0.0042105263157894745\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75024849  0.82926845]\n",
            " [-0.03093833  0.72595565]] \n",
            " bias : \n",
            " [[0.92618433]\n",
            " [0.78628502]]\n",
            "alpha :  0.004123711340206186\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82478711 0.90150818]\n",
            " [0.85175023 0.37164117]] \n",
            " bias : \n",
            " [[0.95327992]\n",
            " [0.5178889 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 30 \n",
            " weights : \n",
            "[[0.82478711 0.90150818]\n",
            " [0.85175023 0.37164117]] \n",
            " bias : \n",
            " [[0.95327992]\n",
            " [0.5178889 ]]\n",
            "alpha :  0.004037685060565276\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10875939  0.0066754 ]] \n",
            " bias : \n",
            " [[0.77684473]]\n",
            "\n",
            " Loss : [[0.62183798]]\n",
            "alpha :  0.003955174686882004\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75034093  0.82933724]\n",
            " [-0.03094411  0.72595136]] \n",
            " bias : \n",
            " [[0.92615597]\n",
            " [0.78628679]]\n",
            "alpha :  0.003875968992248062\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82482609 0.90154841]\n",
            " [0.85179086 0.3716831 ]] \n",
            " bias : \n",
            " [[0.95327867]\n",
            " [0.5178876 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 31 \n",
            " weights : \n",
            "[[0.82482609 0.90154841]\n",
            " [0.85179086 0.3716831 ]] \n",
            " bias : \n",
            " [[0.95327867]\n",
            " [0.5178876 ]]\n",
            "alpha :  0.00379746835443038\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10872954  0.00655981]] \n",
            " bias : \n",
            " [[0.77709519]]\n",
            "\n",
            " Loss : [[0.62181642]]\n",
            "alpha :  0.0037220843672456576\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75042785  0.82940194]\n",
            " [-0.03094944  0.72594738]] \n",
            " bias : \n",
            " [[0.92612927]\n",
            " [0.78628843]]\n",
            "alpha :  0.0036496350364963507\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82486278 0.90158627]\n",
            " [0.85182913 0.3717226 ]] \n",
            " bias : \n",
            " [[0.95327749]\n",
            " [0.51788637]]\n",
            "//////////// end of iteration\n",
            "epoch : 32 \n",
            " weights : \n",
            "[[0.82486278 0.90158627]\n",
            " [0.85182913 0.3717226 ]] \n",
            " bias : \n",
            " [[0.95327749]\n",
            " [0.51788637]]\n",
            "alpha :  0.003577817531305904\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10870093  0.0064515 ]] \n",
            " bias : \n",
            " [[0.77733128]]\n",
            "\n",
            " Loss : [[0.62179616]]\n",
            "alpha :  0.003508771929824562\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75050974  0.82946289]\n",
            " [-0.03095438  0.72594371]] \n",
            " bias : \n",
            " [[0.9261041 ]\n",
            " [0.78628995]]\n",
            "alpha :  0.0034423407917383822\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82489737 0.90162197]\n",
            " [0.85186525 0.37175988]] \n",
            " bias : \n",
            " [[0.95327636]\n",
            " [0.51788519]]\n",
            "//////////// end of iteration\n",
            "epoch : 33 \n",
            " weights : \n",
            "[[0.82489737 0.90162197]\n",
            " [0.85186525 0.37175988]] \n",
            " bias : \n",
            " [[0.95327636]\n",
            " [0.51788519]]\n",
            "alpha :  0.003376477208778841\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10867349  0.00634977]] \n",
            " bias : \n",
            " [[0.77755419]]\n",
            "\n",
            " Loss : [[0.62177708]]\n",
            "alpha :  0.003313086692435119\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75058701  0.82952041]\n",
            " [-0.03095897  0.72594029]] \n",
            " bias : \n",
            " [[0.92608032]\n",
            " [0.78629136]]\n",
            "alpha :  0.0032520325203252037\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82493003 0.90165568]\n",
            " [0.85189939 0.37179512]] \n",
            " bias : \n",
            " [[0.95327529]\n",
            " [0.51788407]]\n",
            "//////////// end of iteration\n",
            "epoch : 34 \n",
            " weights : \n",
            "[[0.82493003 0.90165568]\n",
            " [0.85189939 0.37179512]] \n",
            " bias : \n",
            " [[0.95327529]\n",
            " [0.51788407]]\n",
            "alpha :  0.003191489361702128\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1086472   0.00625405]] \n",
            " bias : \n",
            " [[0.77776496]]\n",
            "\n",
            " Loss : [[0.62175908]]\n",
            "alpha :  0.0031331592689295045\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75066005  0.82957477]\n",
            " [-0.03096324  0.72593712]] \n",
            " bias : \n",
            " [[0.92605784]\n",
            " [0.78629267]]\n",
            "alpha :  0.0030769230769230774\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82496092 0.90168757]\n",
            " [0.85193171 0.37182847]] \n",
            " bias : \n",
            " [[0.95327427]\n",
            " [0.51788301]]\n",
            "//////////// end of iteration\n",
            "epoch : 35 \n",
            " weights : \n",
            "[[0.82496092 0.90168757]\n",
            " [0.85193171 0.37182847]] \n",
            " bias : \n",
            " [[0.95327427]\n",
            " [0.51788301]]\n",
            "alpha :  0.003021148036253777\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10862199  0.0061638 ]] \n",
            " bias : \n",
            " [[0.77796457]]\n",
            "\n",
            " Loss : [[0.62174208]]\n",
            "alpha :  0.002967359050445104\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75072918  0.82962623]\n",
            " [-0.03096722  0.72593415]] \n",
            " bias : \n",
            " [[0.92603654]\n",
            " [0.7862939 ]]\n",
            "alpha :  0.002915451895043732\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82499018 0.90171777]\n",
            " [0.85196234 0.3718601 ]] \n",
            " bias : \n",
            " [[0.9532733 ]\n",
            " [0.51788199]]\n",
            "//////////// end of iteration\n",
            "epoch : 36 \n",
            " weights : \n",
            "[[0.82499018 0.90171777]\n",
            " [0.85196234 0.3718601 ]] \n",
            " bias : \n",
            " [[0.9532733 ]\n",
            " [0.51788199]]\n",
            "alpha :  0.0028639618138424825\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10859782  0.00607858]] \n",
            " bias : \n",
            " [[0.77815385]]\n",
            "\n",
            " Loss : [[0.62172599]]\n",
            "alpha :  0.002814258911819888\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75079472  0.82967501]\n",
            " [-0.03097093  0.72593139]] \n",
            " bias : \n",
            " [[0.92601633]\n",
            " [0.78629505]]\n",
            "alpha :  0.0027662517289073307\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82501793 0.90174642]\n",
            " [0.85199142 0.37189011]] \n",
            " bias : \n",
            " [[0.95327237]\n",
            " [0.51788102]]\n",
            "//////////// end of iteration\n",
            "epoch : 37 \n",
            " weights : \n",
            "[[0.82501793 0.90174642]\n",
            " [0.85199142 0.37189011]] \n",
            " bias : \n",
            " [[0.95327237]\n",
            " [0.51788102]]\n",
            "alpha :  0.002718622564567286\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10857463  0.00599796]] \n",
            " bias : \n",
            " [[0.77833358]]\n",
            "\n",
            " Loss : [[0.62171074]]\n",
            "alpha :  0.00267260579064588\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75085693  0.82972132]\n",
            " [-0.03097442  0.7259288 ]] \n",
            " bias : \n",
            " [[0.92599714]\n",
            " [0.78629612]]\n",
            "alpha :  0.002628120893561104\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82504429 0.90177363]\n",
            " [0.85201905 0.37191864]] \n",
            " bias : \n",
            " [[0.95327149]\n",
            " [0.51788009]]\n",
            "//////////// end of iteration\n",
            "epoch : 38 \n",
            " weights : \n",
            "[[0.82504429 0.90177363]\n",
            " [0.85201905 0.37191864]] \n",
            " bias : \n",
            " [[0.95327149]\n",
            " [0.51788009]]\n",
            "alpha :  0.0025839793281653744\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10855238  0.00592159]] \n",
            " bias : \n",
            " [[0.77850446]]\n",
            "\n",
            " Loss : [[0.62169628]]\n",
            "alpha :  0.002541296060991105\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75091605  0.82976533]\n",
            " [-0.03097768  0.72592636]] \n",
            " bias : \n",
            " [[0.9259789 ]\n",
            " [0.78629713]]\n",
            "alpha :  0.0024999999999999996\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82506935 0.9017995 ]\n",
            " [0.85204535 0.37194579]] \n",
            " bias : \n",
            " [[0.95327064]\n",
            " [0.5178792 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 39 \n",
            " weights : \n",
            "[[0.82506935 0.9017995 ]\n",
            " [0.85204535 0.37194579]] \n",
            " bias : \n",
            " [[0.95327064]\n",
            " [0.5178792 ]]\n",
            "alpha :  0.0024590163934426227\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10853102  0.00584912]] \n",
            " bias : \n",
            " [[0.77866711]]\n",
            "\n",
            " Loss : [[0.62168253]]\n",
            "alpha :  0.002419354838709677\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75097231  0.82980721]\n",
            " [-0.03098075  0.72592408]] \n",
            " bias : \n",
            " [[0.92596153]\n",
            " [0.78629808]]\n",
            "alpha :  0.0023809523809523807\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82509322 0.90182414]\n",
            " [0.85207041 0.37197166]] \n",
            " bias : \n",
            " [[0.95326983]\n",
            " [0.51787835]]\n",
            "//////////// end of iteration\n",
            "epoch : 40 \n",
            " weights : \n",
            "[[0.82509322 0.90182414]\n",
            " [0.85207041 0.37197166]] \n",
            " bias : \n",
            " [[0.95326983]\n",
            " [0.51787835]]\n",
            "alpha :  0.0023428348301444747\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1085105   0.00578027]] \n",
            " bias : \n",
            " [[0.77882212]]\n",
            "\n",
            " Loss : [[0.62166945]]\n",
            "alpha :  0.0023059185242121443\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75102592  0.82984711]\n",
            " [-0.03098364  0.72592193]] \n",
            " bias : \n",
            " [[0.92594497]\n",
            " [0.78629897]]\n",
            "alpha :  0.0022701475595913734\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82511596 0.90184763]\n",
            " [0.8520943  0.37199633]] \n",
            " bias : \n",
            " [[0.95326905]\n",
            " [0.51787753]]\n",
            "//////////// end of iteration\n",
            "epoch : 41 \n",
            " weights : \n",
            "[[0.82511596 0.90184763]\n",
            " [0.8520943  0.37199633]] \n",
            " bias : \n",
            " [[0.95326905]\n",
            " [0.51787753]]\n",
            "alpha :  0.00223463687150838\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10849079  0.00571478]] \n",
            " bias : \n",
            " [[0.77897001]]\n",
            "\n",
            " Loss : [[0.621657]]\n",
            "alpha :  0.0022002200220022\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75107705  0.82988517]\n",
            " [-0.03098636  0.7259199 ]] \n",
            " bias : \n",
            " [[0.92592917]\n",
            " [0.78629981]]\n",
            "alpha :  0.002166847237269773\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82513767 0.90187004]\n",
            " [0.85211712 0.37201988]] \n",
            " bias : \n",
            " [[0.95326831]\n",
            " [0.51787675]]\n",
            "//////////// end of iteration\n",
            "epoch : 42 \n",
            " weights : \n",
            "[[0.82513767 0.90187004]\n",
            " [0.85211712 0.37201988]] \n",
            " bias : \n",
            " [[0.95326831]\n",
            " [0.51787675]]\n",
            "alpha :  0.00213371266002845\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10847183  0.00565239]] \n",
            " bias : \n",
            " [[0.77911124]]\n",
            "\n",
            " Loss : [[0.62164512]]\n",
            "alpha :  0.002101576182136603\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75112586  0.82992151]\n",
            " [-0.03098894  0.72591799]] \n",
            " bias : \n",
            " [[0.92591408]\n",
            " [0.7863006 ]]\n",
            "alpha :  0.0020703933747412014\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8251584  0.90189144]\n",
            " [0.85213893 0.3720424 ]] \n",
            " bias : \n",
            " [[0.9532676]\n",
            " [0.517876 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 43 \n",
            " weights : \n",
            "[[0.8251584  0.90189144]\n",
            " [0.85213893 0.3720424 ]] \n",
            " bias : \n",
            " [[0.9532676]\n",
            " [0.517876 ]]\n",
            "alpha :  0.002039428959891231\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1084536  0.0055929]] \n",
            " bias : \n",
            " [[0.77924627]]\n",
            "\n",
            " Loss : [[0.62163378]]\n",
            "alpha :  0.002009377093101139\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75117253  0.82995625]\n",
            " [-0.03099137  0.72591618]] \n",
            " bias : \n",
            " [[0.92589965]\n",
            " [0.78630136]]\n",
            "alpha :  0.0019801980198019802\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82517823 0.90191191]\n",
            " [0.85215979 0.37206394]] \n",
            " bias : \n",
            " [[0.95326692]\n",
            " [0.51787529]]\n",
            "//////////// end of iteration\n",
            "epoch : 44 \n",
            " weights : \n",
            "[[0.82517823 0.90191191]\n",
            " [0.85215979 0.37206394]] \n",
            " bias : \n",
            " [[0.95326692]\n",
            " [0.51787529]]\n",
            "alpha :  0.001951219512195122\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10843605  0.0055361 ]] \n",
            " bias : \n",
            " [[0.77937547]]\n",
            "\n",
            " Loss : [[0.62162294]]\n",
            "alpha :  0.001923076923076923\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75121717  0.82998948]\n",
            " [-0.03099367  0.72591446]] \n",
            " bias : \n",
            " [[0.92588583]\n",
            " [0.78630207]]\n",
            "alpha :  0.0018957345971563982\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8251972  0.90193151]\n",
            " [0.85217977 0.37208457]] \n",
            " bias : \n",
            " [[0.95326626]\n",
            " [0.5178746 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 45 \n",
            " weights : \n",
            "[[0.8251972  0.90193151]\n",
            " [0.85217977 0.37208457]] \n",
            " bias : \n",
            " [[0.95326626]\n",
            " [0.5178746 ]]\n",
            "alpha :  0.0018685767673621925\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10841915  0.00548182]] \n",
            " bias : \n",
            " [[0.77949922]]\n",
            "\n",
            " Loss : [[0.62161258]]\n",
            "alpha :  0.00184218606079214\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75125992  0.83002131]\n",
            " [-0.03099585  0.72591284]] \n",
            " bias : \n",
            " [[0.9258726 ]\n",
            " [0.78630274]]\n",
            "alpha :  0.0018165304268846505\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82521538 0.90195028]\n",
            " [0.85219892 0.37210434]] \n",
            " bias : \n",
            " [[0.95326563]\n",
            " [0.51787393]]\n",
            "//////////// end of iteration\n",
            "epoch : 46 \n",
            " weights : \n",
            "[[0.82521538 0.90195028]\n",
            " [0.85219892 0.37210434]] \n",
            " bias : \n",
            " [[0.95326563]\n",
            " [0.51787393]]\n",
            "alpha :  0.001791044776119403\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10840287  0.00542988]] \n",
            " bias : \n",
            " [[0.77961786]]\n",
            "\n",
            " Loss : [[0.62160265]]\n",
            "alpha :  0.0017662643508978512\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.7513009   0.83005181]\n",
            " [-0.03099792  0.7259113 ]] \n",
            " bias : \n",
            " [[0.92585992]\n",
            " [0.78630339]]\n",
            "alpha :  0.0017421602787456446\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82523281 0.90196828]\n",
            " [0.85221728 0.3721233 ]] \n",
            " bias : \n",
            " [[0.95326502]\n",
            " [0.51787329]]\n",
            "//////////// end of iteration\n",
            "epoch : 47 \n",
            " weights : \n",
            "[[0.82523281 0.90196828]\n",
            " [0.85221728 0.3721233 ]] \n",
            " bias : \n",
            " [[0.95326502]\n",
            " [0.51787329]]\n",
            "alpha :  0.0017182130584192437\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10838717  0.00538015]] \n",
            " bias : \n",
            " [[0.77973169]]\n",
            "\n",
            " Loss : [[0.62159314]]\n",
            "alpha :  0.0016949152542372879\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75134021  0.83008108]\n",
            " [-0.03099989  0.72590983]] \n",
            " bias : \n",
            " [[0.92584775]\n",
            " [0.786304  ]]\n",
            "alpha :  0.001672240802675585\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82524954 0.90198555]\n",
            " [0.85223492 0.37214151]] \n",
            " bias : \n",
            " [[0.95326444]\n",
            " [0.51787268]]\n",
            "//////////// end of iteration\n",
            "epoch : 48 \n",
            " weights : \n",
            "[[0.82524954 0.90198555]\n",
            " [0.85223492 0.37214151]] \n",
            " bias : \n",
            " [[0.95326444]\n",
            " [0.51787268]]\n",
            "alpha :  0.0016497113005224083\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10837204  0.00533249]] \n",
            " bias : \n",
            " [[0.779841]]\n",
            "\n",
            " Loss : [[0.62158402]]\n",
            "alpha :  0.001627780792186652\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75137795  0.83010917]\n",
            " [-0.03100177  0.72590844]] \n",
            " bias : \n",
            " [[0.92583606]\n",
            " [0.78630458]]\n",
            "alpha :  0.0016064257028112448\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82526561 0.90200214]\n",
            " [0.85225186 0.37215901]] \n",
            " bias : \n",
            " [[0.95326388]\n",
            " [0.51787209]]\n",
            "//////////// end of iteration\n",
            "epoch : 49 \n",
            " weights : \n",
            "[[0.82526561 0.90200214]\n",
            " [0.85225186 0.37215901]] \n",
            " bias : \n",
            " [[0.95326388]\n",
            " [0.51787209]]\n",
            "alpha :  0.0015852047556142667\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10835743  0.00528676]] \n",
            " bias : \n",
            " [[0.77994605]]\n",
            "\n",
            " Loss : [[0.62157526]]\n",
            "alpha :  0.0015645371577574965\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75141422  0.83013617]\n",
            " [-0.03100355  0.72590711]] \n",
            " bias : \n",
            " [[0.92582482]\n",
            " [0.78630513]]\n",
            "alpha :  0.0015444015444015442\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82528105 0.90201809]\n",
            " [0.85226816 0.37217584]] \n",
            " bias : \n",
            " [[0.95326334]\n",
            " [0.51787152]]\n",
            "//////////// end of iteration\n",
            "epoch : 50 \n",
            " weights : \n",
            "[[0.82528105 0.90201809]\n",
            " [0.85226816 0.37217584]] \n",
            " bias : \n",
            " [[0.95326334]\n",
            " [0.51787152]]\n",
            "alpha :  0.0015243902439024389\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10834332  0.00524285]] \n",
            " bias : \n",
            " [[0.78004708]]\n",
            "\n",
            " Loss : [[0.62156685]]\n",
            "alpha :  0.0015048908954100827\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.7514491   0.83016214]\n",
            " [-0.03100525  0.72590584]] \n",
            " bias : \n",
            " [[0.92581401]\n",
            " [0.78630566]]\n",
            "alpha :  0.0014858841010401188\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82529591 0.90203343]\n",
            " [0.85228384 0.37219203]] \n",
            " bias : \n",
            " [[0.95326282]\n",
            " [0.51787096]]\n",
            "//////////// end of iteration\n",
            "epoch : 51 \n",
            " weights : \n",
            "[[0.82529591 0.90203343]\n",
            " [0.85228384 0.37219203]] \n",
            " bias : \n",
            " [[0.95326282]\n",
            " [0.51787096]]\n",
            "alpha :  0.001466992665036675\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10832969  0.00520066]] \n",
            " bias : \n",
            " [[0.78014432]]\n",
            "\n",
            " Loss : [[0.62155876]]\n",
            "alpha :  0.0014485755673587638\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75148266  0.83018713]\n",
            " [-0.03100688  0.72590463]] \n",
            " bias : \n",
            " [[0.92580361]\n",
            " [0.78630616]]\n",
            "alpha :  0.0014306151645207437\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82531021 0.90204819]\n",
            " [0.85229894 0.37220762]] \n",
            " bias : \n",
            " [[0.95326231]\n",
            " [0.51787043]]\n",
            "//////////// end of iteration\n",
            "epoch : 52 \n",
            " weights : \n",
            "[[0.82531021 0.90204819]\n",
            " [0.85229894 0.37220762]] \n",
            " bias : \n",
            " [[0.95326231]\n",
            " [0.51787043]]\n",
            "alpha :  0.0014127619496114901\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10831652  0.00516008]] \n",
            " bias : \n",
            " [[0.78023797]]\n",
            "\n",
            " Loss : [[0.62155097]]\n",
            "alpha :  0.001395348837209302\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75151499  0.83021119]\n",
            " [-0.03100843  0.72590348]] \n",
            " bias : \n",
            " [[0.92579359]\n",
            " [0.78630664]]\n",
            "alpha :  0.0013783597518952442\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82532398 0.90206242]\n",
            " [0.85231349 0.37222265]] \n",
            " bias : \n",
            " [[0.95326183]\n",
            " [0.51786992]]\n",
            "//////////// end of iteration\n",
            "epoch : 53 \n",
            " weights : \n",
            "[[0.82532398 0.90206242]\n",
            " [0.85231349 0.37222265]] \n",
            " bias : \n",
            " [[0.95326183]\n",
            " [0.51786992]]\n",
            "alpha :  0.0013614703880190603\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10830379  0.00512103]] \n",
            " bias : \n",
            " [[0.78032823]]\n",
            "\n",
            " Loss : [[0.62154348]]\n",
            "alpha :  0.0013449899125756554\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75154614  0.83023438]\n",
            " [-0.03100991  0.72590237]] \n",
            " bias : \n",
            " [[0.92578393]\n",
            " [0.7863071 ]]\n",
            "alpha :  0.0013289036544850497\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82533726 0.90207613]\n",
            " [0.85232752 0.37223714]] \n",
            " bias : \n",
            " [[0.95326136]\n",
            " [0.51786943]]\n",
            "//////////// end of iteration\n",
            "epoch : 54 \n",
            " weights : \n",
            "[[0.82533726 0.90207613]\n",
            " [0.85232752 0.37223714]] \n",
            " bias : \n",
            " [[0.95326136]\n",
            " [0.51786943]]\n",
            "alpha :  0.001312910284463895\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10829147  0.00508341]] \n",
            " bias : \n",
            " [[0.78041529]]\n",
            "\n",
            " Loss : [[0.62153625]]\n",
            "alpha :  0.0012972972972972972\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75157617  0.83025674]\n",
            " [-0.03101133  0.72590131]] \n",
            " bias : \n",
            " [[0.92577462]\n",
            " [0.78630754]]\n",
            "alpha :  0.0012820512820512818\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82535007 0.90208936]\n",
            " [0.85234106 0.37225112]] \n",
            " bias : \n",
            " [[0.95326091]\n",
            " [0.51786895]]\n",
            "//////////// end of iteration\n",
            "epoch : 55 \n",
            " weights : \n",
            "[[0.82535007 0.90208936]\n",
            " [0.85234106 0.37225112]] \n",
            " bias : \n",
            " [[0.95326091]\n",
            " [0.51786895]]\n",
            "alpha :  0.0012668918918918917\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10827954  0.00504716]] \n",
            " bias : \n",
            " [[0.78049929]]\n",
            "\n",
            " Loss : [[0.62152929]]\n",
            "alpha :  0.0012520868113522535\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75160516  0.83027832]\n",
            " [-0.03101269  0.7259003 ]] \n",
            " bias : \n",
            " [[0.92576563]\n",
            " [0.78630796]]\n",
            "alpha :  0.0012376237623762374\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82536244 0.90210213]\n",
            " [0.85235413 0.37226462]] \n",
            " bias : \n",
            " [[0.95326047]\n",
            " [0.51786848]]\n",
            "//////////// end of iteration\n",
            "epoch : 56 \n",
            " weights : \n",
            "[[0.82536244 0.90210213]\n",
            " [0.85235413 0.37226462]] \n",
            " bias : \n",
            " [[0.95326047]\n",
            " [0.51786848]]\n",
            "alpha :  0.001223241590214067\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10826799  0.0050122 ]] \n",
            " bias : \n",
            " [[0.78058042]]\n",
            "\n",
            " Loss : [[0.62152257]]\n",
            "alpha :  0.00120918984280532\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75163315  0.83029916]\n",
            " [-0.031014    0.72589933]] \n",
            " bias : \n",
            " [[0.92575694]\n",
            " [0.78630837]]\n",
            "alpha :  0.0011954572624028686\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82537438 0.90211446]\n",
            " [0.85236676 0.37227766]] \n",
            " bias : \n",
            " [[0.95326004]\n",
            " [0.51786803]]\n",
            "//////////// end of iteration\n",
            "epoch : 57 \n",
            " weights : \n",
            "[[0.82537438 0.90211446]\n",
            " [0.85236676 0.37227766]] \n",
            " bias : \n",
            " [[0.95326004]\n",
            " [0.51786803]]\n",
            "alpha :  0.0011818002757533973\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1082568   0.00497846]] \n",
            " bias : \n",
            " [[0.7806588]]\n",
            "\n",
            " Loss : [[0.62151608]]\n",
            "alpha :  0.0011684518013631933\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75166019  0.83031929]\n",
            " [-0.03101525  0.7258984 ]] \n",
            " bias : \n",
            " [[0.92574855]\n",
            " [0.78630876]]\n",
            "alpha :  0.0011554015020219523\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82538592 0.90212638]\n",
            " [0.85237897 0.37229027]] \n",
            " bias : \n",
            " [[0.95325963]\n",
            " [0.5178676 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 58 \n",
            " weights : \n",
            "[[0.82538592 0.90212638]\n",
            " [0.85237897 0.37229027]] \n",
            " bias : \n",
            " [[0.95325963]\n",
            " [0.5178676 ]]\n",
            "alpha :  0.0011424219345011423\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10824596  0.00494587]] \n",
            " bias : \n",
            " [[0.78073457]]\n",
            "\n",
            " Loss : [[0.62150981]]\n",
            "alpha :  0.0011297307475051778\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75168633  0.83033875]\n",
            " [-0.03101645  0.7258975 ]] \n",
            " bias : \n",
            " [[0.92574044]\n",
            " [0.78630913]]\n",
            "alpha :  0.0011173184357541896\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82539707 0.9021379 ]\n",
            " [0.85239077 0.37230246]] \n",
            " bias : \n",
            " [[0.95325924]\n",
            " [0.51786718]]\n",
            "//////////// end of iteration\n",
            "epoch : 59 \n",
            " weights : \n",
            "[[0.82539707 0.9021379 ]\n",
            " [0.85239077 0.37230246]] \n",
            " bias : \n",
            " [[0.95325924]\n",
            " [0.51786718]]\n",
            "alpha :  0.0011049723756906074\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10823544  0.00491439]] \n",
            " bias : \n",
            " [[0.78080787]]\n",
            "\n",
            " Loss : [[0.62150375]]\n",
            "alpha :  0.0010928961748633878\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75171161  0.83035757]\n",
            " [-0.03101761  0.72589664]] \n",
            " bias : \n",
            " [[0.92573259]\n",
            " [0.78630949]]\n",
            "alpha :  0.0010810810810810809\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82540787 0.90214905]\n",
            " [0.8524022  0.37231426]] \n",
            " bias : \n",
            " [[0.95325885]\n",
            " [0.51786677]]\n",
            "//////////// end of iteration\n",
            "epoch : 60 \n",
            " weights : \n",
            "[[0.82540787 0.90214905]\n",
            " [0.8524022  0.37231426]] \n",
            " bias : \n",
            " [[0.95325885]\n",
            " [0.51786677]]\n",
            "alpha :  0.0010693281055070393\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10822524  0.00488395]] \n",
            " bias : \n",
            " [[0.78087881]]\n",
            "\n",
            " Loss : [[0.6214979]]\n",
            "alpha :  0.0010578279266572634\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75173608  0.83037579]\n",
            " [-0.03101872  0.72589582]] \n",
            " bias : \n",
            " [[0.925725  ]\n",
            " [0.78630983]]\n",
            "alpha :  0.0010465724751439033\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82541831 0.90215984]\n",
            " [0.85241326 0.37232569]] \n",
            " bias : \n",
            " [[0.95325848]\n",
            " [0.51786638]]\n",
            "//////////// end of iteration\n",
            "epoch : 61 \n",
            " weights : \n",
            "[[0.82541831 0.90215984]\n",
            " [0.85241326 0.37232569]] \n",
            " bias : \n",
            " [[0.95325848]\n",
            " [0.51786638]]\n",
            "alpha :  0.0010353753235547883\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10821534  0.0048545 ]] \n",
            " bias : \n",
            " [[0.7809475]]\n",
            "\n",
            " Loss : [[0.62149223]]\n",
            "alpha :  0.001024415229639747\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75175977  0.83039343]\n",
            " [-0.03101979  0.72589502]] \n",
            " bias : \n",
            " [[0.92571764]\n",
            " [0.78631016]]\n",
            "alpha :  0.001013684744044602\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82542843 0.90217029]\n",
            " [0.85242398 0.37233676]] \n",
            " bias : \n",
            " [[0.95325812]\n",
            " [0.517866  ]]\n",
            "//////////// end of iteration\n",
            "epoch : 62 \n",
            " weights : \n",
            "[[0.82542843 0.90217029]\n",
            " [0.85242398 0.37233676]] \n",
            " bias : \n",
            " [[0.95325812]\n",
            " [0.517866  ]]\n",
            "alpha :  0.0010030090270812435\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10820573  0.004826  ]] \n",
            " bias : \n",
            " [[0.78101405]]\n",
            "\n",
            " Loss : [[0.62148674]]\n",
            "alpha :  0.0009925558312655087\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75178272  0.83041051]\n",
            " [-0.03102082  0.72589425]] \n",
            " bias : \n",
            " [[0.92571052]\n",
            " [0.78631048]]\n",
            "alpha :  0.000982318271119843\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82543824 0.90218041]\n",
            " [0.85243436 0.37234748]] \n",
            " bias : \n",
            " [[0.95325777]\n",
            " [0.51786562]]\n",
            "//////////// end of iteration\n",
            "epoch : 63 \n",
            " weights : \n",
            "[[0.82543824 0.90218041]\n",
            " [0.85243436 0.37234748]] \n",
            " bias : \n",
            " [[0.95325777]\n",
            " [0.51786562]]\n",
            "alpha :  0.0009721322099805574\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1081964  0.0047984]] \n",
            " bias : \n",
            " [[0.78107855]]\n",
            "\n",
            " Loss : [[0.62148142]]\n",
            "alpha :  0.0009621552277100705\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75180497  0.83042707]\n",
            " [-0.03102181  0.72589351]] \n",
            " bias : \n",
            " [[0.92570361]\n",
            " [0.78631079]]\n",
            "alpha :  0.0009523809523809524\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82544774 0.90219023]\n",
            " [0.85244443 0.37235788]] \n",
            " bias : \n",
            " [[0.95325743]\n",
            " [0.51786526]]\n",
            "//////////// end of iteration\n",
            "epoch : 64 \n",
            " weights : \n",
            "[[0.82544774 0.90219023]\n",
            " [0.85244443 0.37235788]] \n",
            " bias : \n",
            " [[0.95325743]\n",
            " [0.51786526]]\n",
            "alpha :  0.0009426551453260016\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10818733  0.00477166]] \n",
            " bias : \n",
            " [[0.7811411]]\n",
            "\n",
            " Loss : [[0.62147627]]\n",
            "alpha :  0.0009331259720062208\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75182654  0.83044313]\n",
            " [-0.03102277  0.7258928 ]] \n",
            " bias : \n",
            " [[0.92569691]\n",
            " [0.78631109]]\n",
            "alpha :  0.0009237875288683603\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82545696 0.90219975]\n",
            " [0.8524542  0.37236797]] \n",
            " bias : \n",
            " [[0.95325709]\n",
            " [0.51786491]]\n",
            "//////////// end of iteration\n",
            "epoch : 65 \n",
            " weights : \n",
            "[[0.82545696 0.90219975]\n",
            " [0.8524542  0.37236797]] \n",
            " bias : \n",
            " [[0.95325709]\n",
            " [0.51786491]]\n",
            "alpha :  0.0009144947416552353\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10817851  0.00474573]] \n",
            " bias : \n",
            " [[0.78120179]]\n",
            "\n",
            " Loss : [[0.62147127]]\n",
            "alpha :  0.0009053870529651424\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75184746  0.83045871]\n",
            " [-0.03102369  0.72589211]] \n",
            " bias : \n",
            " [[0.92569041]\n",
            " [0.78631138]]\n",
            "alpha :  0.0008964589870013444\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8254659  0.90220899]\n",
            " [0.85246369 0.37237777]] \n",
            " bias : \n",
            " [[0.95325677]\n",
            " [0.51786457]]\n",
            "//////////// end of iteration\n",
            "epoch : 66 \n",
            " weights : \n",
            "[[0.8254659  0.90220899]\n",
            " [0.85246369 0.37237777]] \n",
            " bias : \n",
            " [[0.95325677]\n",
            " [0.51786457]]\n",
            "alpha :  0.000887573964497041\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10816994  0.00472059]] \n",
            " bias : \n",
            " [[0.78126069]]\n",
            "\n",
            " Loss : [[0.62146642]]\n",
            "alpha :  0.0008788633367511348\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75186777  0.83047383]\n",
            " [-0.03102458  0.72589145]] \n",
            " bias : \n",
            " [[0.9256841 ]\n",
            " [0.78631165]]\n",
            "alpha :  0.000870322019147084\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82547459 0.90221796]\n",
            " [0.85247289 0.37238727]] \n",
            " bias : \n",
            " [[0.95325646]\n",
            " [0.51786424]]\n",
            "//////////// end of iteration\n",
            "epoch : 67 \n",
            " weights : \n",
            "[[0.82547459 0.90221796]\n",
            " [0.85247289 0.37238727]] \n",
            " bias : \n",
            " [[0.95325646]\n",
            " [0.51786424]]\n",
            "alpha :  0.0008618213157138748\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1081616  0.0046962]] \n",
            " bias : \n",
            " [[0.78131789]]\n",
            "\n",
            " Loss : [[0.62146172]]\n",
            "alpha :  0.0008534850640113792\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75188749  0.83048851]\n",
            " [-0.03102544  0.72589081]] \n",
            " bias : \n",
            " [[0.92567797]\n",
            " [0.78631192]]\n",
            "alpha :  0.0008453085376162293\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82548302 0.90222667]\n",
            " [0.85248183 0.37239651]] \n",
            " bias : \n",
            " [[0.95325616]\n",
            " [0.51786392]]\n",
            "//////////// end of iteration\n",
            "epoch : 68 \n",
            " weights : \n",
            "[[0.82548302 0.90222667]\n",
            " [0.85248183 0.37239651]] \n",
            " bias : \n",
            " [[0.95325616]\n",
            " [0.51786392]]\n",
            "alpha :  0.0008371703641691078\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10815349  0.00467252]] \n",
            " bias : \n",
            " [[0.78137346]]\n",
            "\n",
            " Loss : [[0.62145715]]\n",
            "alpha :  0.0008291873963515747\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75190665  0.83050278]\n",
            " [-0.03102627  0.72589019]] \n",
            " bias : \n",
            " [[0.92567202]\n",
            " [0.78631218]]\n",
            "alpha :  0.0008213552361396296\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82549121 0.90223513]\n",
            " [0.85249052 0.37240549]] \n",
            " bias : \n",
            " [[0.95325586]\n",
            " [0.51786361]]\n",
            "//////////// end of iteration\n",
            "epoch : 69 \n",
            " weights : \n",
            "[[0.82549121 0.90223513]\n",
            " [0.85249052 0.37240549]] \n",
            " bias : \n",
            " [[0.95325586]\n",
            " [0.51786361]]\n",
            "alpha :  0.0008135593220338976\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10814559  0.00464952]] \n",
            " bias : \n",
            " [[0.78142746]]\n",
            "\n",
            " Loss : [[0.62145272]]\n",
            "alpha :  0.000805910006715916\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75192527  0.83051664]\n",
            " [-0.03102708  0.72588959]] \n",
            " bias : \n",
            " [[0.92566623]\n",
            " [0.78631243]]\n",
            "alpha :  0.0007984031936127738\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82549917 0.90224335]\n",
            " [0.85249897 0.37241421]] \n",
            " bias : \n",
            " [[0.95325558]\n",
            " [0.5178633 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 70 \n",
            " weights : \n",
            "[[0.82549917 0.90224335]\n",
            " [0.85249897 0.37241421]] \n",
            " bias : \n",
            " [[0.95325558]\n",
            " [0.5178633 ]]\n",
            "alpha :  0.0007909306617453196\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.1081379   0.00462718]] \n",
            " bias : \n",
            " [[0.78147996]]\n",
            "\n",
            " Loss : [[0.62144841]]\n",
            "alpha :  0.0007835967088938219\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75194337  0.83053011]\n",
            " [-0.03102785  0.72588901]] \n",
            " bias : \n",
            " [[0.92566061]\n",
            " [0.78631267]]\n",
            "alpha :  0.0007763975155279496\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82550692 0.90225135]\n",
            " [0.85250719 0.3724227 ]] \n",
            " bias : \n",
            " [[0.9532553 ]\n",
            " [0.51786301]]\n",
            "//////////// end of iteration\n",
            "epoch : 71 \n",
            " weights : \n",
            "[[0.82550692 0.90225135]\n",
            " [0.85250719 0.3724227 ]] \n",
            " bias : \n",
            " [[0.9532553 ]\n",
            " [0.51786301]]\n",
            "alpha :  0.0007692307692307685\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10813041  0.00460546]] \n",
            " bias : \n",
            " [[0.78153102]]\n",
            "\n",
            " Loss : [[0.62144422]]\n",
            "alpha :  0.0007621951219512188\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75196097  0.83054322]\n",
            " [-0.03102861  0.72588845]] \n",
            " bias : \n",
            " [[0.92565514]\n",
            " [0.7863129 ]]\n",
            "alpha :  0.0007552870090634435\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82551445 0.90225913]\n",
            " [0.85251518 0.37243095]] \n",
            " bias : \n",
            " [[0.95325502]\n",
            " [0.51786272]]\n",
            "//////////// end of iteration\n",
            "epoch : 72 \n",
            " weights : \n",
            "[[0.82551445 0.90225913]\n",
            " [0.85251518 0.37243095]] \n",
            " bias : \n",
            " [[0.95325502]\n",
            " [0.51786272]]\n",
            "alpha :  0.0007484096295372327\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10812311  0.00458435]] \n",
            " bias : \n",
            " [[0.7815807]]\n",
            "\n",
            " Loss : [[0.62144014]]\n",
            "alpha :  0.0007416563658838065\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.7519781   0.83055597]\n",
            " [-0.03102934  0.72588791]] \n",
            " bias : \n",
            " [[0.92564981]\n",
            " [0.78631313]]\n",
            "alpha :  0.0007350238882763683\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82552178 0.9022667 ]\n",
            " [0.85252296 0.37243899]] \n",
            " bias : \n",
            " [[0.95325476]\n",
            " [0.51786244]]\n",
            "//////////// end of iteration\n",
            "epoch : 73 \n",
            " weights : \n",
            "[[0.82552178 0.9022667 ]\n",
            " [0.85252296 0.37243899]] \n",
            " bias : \n",
            " [[0.95325476]\n",
            " [0.51786244]]\n",
            "alpha :  0.0007284205414592684\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10811599  0.00456381]] \n",
            " bias : \n",
            " [[0.78162906]]\n",
            "\n",
            " Loss : [[0.62143617]]\n",
            "alpha :  0.0007219347852244007\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75199476  0.83056838]\n",
            " [-0.03103004  0.72588738]] \n",
            " bias : \n",
            " [[0.92564463]\n",
            " [0.78631335]]\n",
            "alpha :  0.0007155635062611801\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82552891 0.90227407]\n",
            " [0.85253054 0.37244681]] \n",
            " bias : \n",
            " [[0.9532545 ]\n",
            " [0.51786216]]\n",
            "//////////// end of iteration\n",
            "epoch : 74 \n",
            " weights : \n",
            "[[0.82552891 0.90227407]\n",
            " [0.85253054 0.37244681]] \n",
            " bias : \n",
            " [[0.9532545 ]\n",
            " [0.51786216]]\n",
            "alpha :  0.0007092198581560279\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10810905  0.00454382]] \n",
            " bias : \n",
            " [[0.78167615]]\n",
            "\n",
            " Loss : [[0.62143232]]\n",
            "alpha :  0.0007029876977152894\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75201099  0.83058046]\n",
            " [-0.03103073  0.72588687]] \n",
            " bias : \n",
            " [[0.92563958]\n",
            " [0.78631356]]\n",
            "alpha :  0.0006968641114982572\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82553586 0.90228124]\n",
            " [0.85253791 0.37245443]] \n",
            " bias : \n",
            " [[0.95325425]\n",
            " [0.51786189]]\n",
            "//////////// end of iteration\n",
            "epoch : 75 \n",
            " weights : \n",
            "[[0.82553586 0.90228124]\n",
            " [0.85253791 0.37245443]] \n",
            " bias : \n",
            " [[0.95325425]\n",
            " [0.51786189]]\n",
            "alpha :  0.0006907667510937134\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10810229  0.00452437]] \n",
            " bias : \n",
            " [[0.78172201]]\n",
            "\n",
            " Loss : [[0.62142856]]\n",
            "alpha :  0.000684775165487331\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.7520268   0.83059223]\n",
            " [-0.03103139  0.72588638]] \n",
            " bias : \n",
            " [[0.92563467]\n",
            " [0.78631377]]\n",
            "alpha :  0.0006788866259334684\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82554263 0.90228823]\n",
            " [0.8525451  0.37246186]] \n",
            " bias : \n",
            " [[0.953254  ]\n",
            " [0.51786163]]\n",
            "//////////// end of iteration\n",
            "epoch : 76 \n",
            " weights : \n",
            "[[0.82554263 0.90228823]\n",
            " [0.8525451  0.37246186]] \n",
            " bias : \n",
            " [[0.953254  ]\n",
            " [0.51786163]]\n",
            "alpha :  0.0006730229949523268\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10809569  0.00450542]] \n",
            " bias : \n",
            " [[0.7817667]]\n",
            "\n",
            " Loss : [[0.6214249]]\n",
            "alpha :  0.0006672597864768676\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.7520422   0.8306037 ]\n",
            " [-0.03103204  0.7258859 ]] \n",
            " bias : \n",
            " [[0.92562988]\n",
            " [0.78631397]]\n",
            "alpha :  0.0006615944426066813\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82554922 0.90229505]\n",
            " [0.85255211 0.37246909]] \n",
            " bias : \n",
            " [[0.95325377]\n",
            " [0.51786138]]\n",
            "//////////// end of iteration\n",
            "epoch : 77 \n",
            " weights : \n",
            "[[0.82554922 0.90229505]\n",
            " [0.85255211 0.37246909]] \n",
            " bias : \n",
            " [[0.95325377]\n",
            " [0.51786138]]\n",
            "alpha :  0.0006559527714004584\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10808925  0.00448696]] \n",
            " bias : \n",
            " [[0.78181025]]\n",
            "\n",
            " Loss : [[0.62142133]]\n",
            "alpha :  0.0006504065040650399\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75205722  0.83061488]\n",
            " [-0.03103266  0.72588543]] \n",
            " bias : \n",
            " [[0.92562521]\n",
            " [0.78631417]]\n",
            "alpha :  0.0006449532408900347\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82555565 0.90230169]\n",
            " [0.85255893 0.37247615]] \n",
            " bias : \n",
            " [[0.95325353]\n",
            " [0.51786113]]\n",
            "//////////// end of iteration\n",
            "epoch : 78 \n",
            " weights : \n",
            "[[0.82555565 0.90230169]\n",
            " [0.85255893 0.37247615]] \n",
            " bias : \n",
            " [[0.95325353]\n",
            " [0.51786113]]\n",
            "alpha :  0.0006395224898742265\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10808296  0.00446898]] \n",
            " bias : \n",
            " [[0.78185272]]\n",
            "\n",
            " Loss : [[0.62141786]]\n",
            "alpha :  0.0006341824331466011\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75207185  0.83062577]\n",
            " [-0.03103327  0.72588498]] \n",
            " bias : \n",
            " [[0.92562066]\n",
            " [0.78631435]]\n",
            "alpha :  0.0006289308176100622\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82556192 0.90230816]\n",
            " [0.85256559 0.37248303]] \n",
            " bias : \n",
            " [[0.9532533 ]\n",
            " [0.51786089]]\n",
            "//////////// end of iteration\n",
            "epoch : 79 \n",
            " weights : \n",
            "[[0.82556192 0.90230816]\n",
            " [0.85256559 0.37248303]] \n",
            " bias : \n",
            " [[0.9532533 ]\n",
            " [0.51786089]]\n",
            "alpha :  0.0006237006237006231\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10807682  0.00445145]] \n",
            " bias : \n",
            " [[0.78189413]]\n",
            "\n",
            " Loss : [[0.62141447]]\n",
            "alpha :  0.0006185567010309272\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75208613  0.8306364 ]\n",
            " [-0.03103386  0.72588454]] \n",
            " bias : \n",
            " [[0.92561622]\n",
            " [0.78631454]]\n",
            "alpha :  0.0006134969325153368\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82556803 0.90231448]\n",
            " [0.85257209 0.37248974]] \n",
            " bias : \n",
            " [[0.95325308]\n",
            " [0.51786065]]\n",
            "//////////// end of iteration\n",
            "epoch : 80 \n",
            " weights : \n",
            "[[0.82556803 0.90231448]\n",
            " [0.85257209 0.37248974]] \n",
            " bias : \n",
            " [[0.95325308]\n",
            " [0.51786065]]\n",
            "alpha :  0.0006084575600851834\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10807083  0.00443435]] \n",
            " bias : \n",
            " [[0.78193454]]\n",
            "\n",
            " Loss : [[0.62141117]]\n",
            "alpha :  0.0006035003017501502\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75210005  0.83064677]\n",
            " [-0.03103444  0.72588411]] \n",
            " bias : \n",
            " [[0.92561189]\n",
            " [0.78631472]]\n",
            "alpha :  0.0005986231667165513\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.825574   0.90232064]\n",
            " [0.85257843 0.37249629]] \n",
            " bias : \n",
            " [[0.95325287]\n",
            " [0.51786042]]\n",
            "//////////// end of iteration\n",
            "epoch : 81 \n",
            " weights : \n",
            "[[0.825574   0.90232064]\n",
            " [0.85257843 0.37249629]] \n",
            " bias : \n",
            " [[0.95325287]\n",
            " [0.51786042]]\n",
            "alpha :  0.0005937654626422557\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10806497  0.00441768]] \n",
            " bias : \n",
            " [[0.78197397]]\n",
            "\n",
            " Loss : [[0.62140795]]\n",
            "alpha :  0.0005889859625012264\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75211364  0.83065688]\n",
            " [-0.03103499  0.7258837 ]] \n",
            " bias : \n",
            " [[0.92560766]\n",
            " [0.78631489]]\n",
            "alpha :  0.0005842827928717493\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82557982 0.90232665]\n",
            " [0.85258462 0.37250268]] \n",
            " bias : \n",
            " [[0.95325265]\n",
            " [0.5178602 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 82 \n",
            " weights : \n",
            "[[0.82557982 0.90232665]\n",
            " [0.85258462 0.37250268]] \n",
            " bias : \n",
            " [[0.95325265]\n",
            " [0.5178602 ]]\n",
            "alpha :  0.0005795981452859344\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10805925  0.00440141]] \n",
            " bias : \n",
            " [[0.78201246]]\n",
            "\n",
            " Loss : [[0.6214048]]\n",
            "alpha :  0.0005749880210828935\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.7521269   0.83066676]\n",
            " [-0.03103554  0.7258833 ]] \n",
            " bias : \n",
            " [[0.92560354]\n",
            " [0.78631506]]\n",
            "alpha :  0.0005704506560182537\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8255855  0.90233252]\n",
            " [0.85259066 0.37250892]] \n",
            " bias : \n",
            " [[0.95325245]\n",
            " [0.51785998]]\n",
            "//////////// end of iteration\n",
            "epoch : 83 \n",
            " weights : \n",
            "[[0.8255855  0.90233252]\n",
            " [0.85259066 0.37250892]] \n",
            " bias : \n",
            " [[0.95325245]\n",
            " [0.51785998]]\n",
            "alpha :  0.0005659309564233156\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10805366  0.00438553]] \n",
            " bias : \n",
            " [[0.78205005]]\n",
            "\n",
            " Loss : [[0.62140173]]\n",
            "alpha :  0.0005614823133071301\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75213986  0.8306764 ]\n",
            " [-0.03103606  0.7258829 ]] \n",
            " bias : \n",
            " [[0.92559951]\n",
            " [0.78631522]]\n",
            "alpha :  0.0005571030640668516\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82559105 0.90233826]\n",
            " [0.85259657 0.37251502]] \n",
            " bias : \n",
            " [[0.95325224]\n",
            " [0.51785976]]\n",
            "//////////// end of iteration\n",
            "epoch : 84 \n",
            " weights : \n",
            "[[0.82559105 0.90233826]\n",
            " [0.85259657 0.37251502]] \n",
            " bias : \n",
            " [[0.95325224]\n",
            " [0.51785976]]\n",
            "alpha :  0.0005527406725011508\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10804819  0.00437002]] \n",
            " bias : \n",
            " [[0.78208676]]\n",
            "\n",
            " Loss : [[0.62139874]]\n",
            "alpha :  0.0005484460694698348\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75215251  0.83068582]\n",
            " [-0.03103658  0.72588252]] \n",
            " bias : \n",
            " [[0.92559557]\n",
            " [0.78631538]]\n",
            "alpha :  0.0005442176870748293\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82559647 0.90234386]\n",
            " [0.85260233 0.37252098]] \n",
            " bias : \n",
            " [[0.95325205]\n",
            " [0.51785955]]\n",
            "//////////// end of iteration\n",
            "epoch : 85 \n",
            " weights : \n",
            "[[0.82559647 0.90234386]\n",
            " [0.85260233 0.37252098]] \n",
            " bias : \n",
            " [[0.95325205]\n",
            " [0.51785955]]\n",
            "alpha :  0.0005400054000539999\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10804284  0.00435489]] \n",
            " bias : \n",
            " [[0.78212262]]\n",
            "\n",
            " Loss : [[0.62139581]]\n",
            "alpha :  0.0005358578190586757\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75216487  0.83069502]\n",
            " [-0.03103708  0.72588215]] \n",
            " bias : \n",
            " [[0.92559173]\n",
            " [0.78631554]]\n",
            "alpha :  0.0005317734645041205\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82560177 0.90234933]\n",
            " [0.85260797 0.3725268 ]] \n",
            " bias : \n",
            " [[0.95325185]\n",
            " [0.51785935]]\n",
            "//////////// end of iteration\n",
            "epoch : 86 \n",
            " weights : \n",
            "[[0.82560177 0.90234933]\n",
            " [0.85260797 0.3725268 ]] \n",
            " bias : \n",
            " [[0.95325185]\n",
            " [0.51785935]]\n",
            "alpha :  0.000527704485488126\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10803761  0.0043401 ]] \n",
            " bias : \n",
            " [[0.78215767]]\n",
            "\n",
            " Loss : [[0.62139295]]\n",
            "alpha :  0.0005236973029588891\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75217694  0.83070401]\n",
            " [-0.03103756  0.72588179]] \n",
            " bias : \n",
            " [[0.92558797]\n",
            " [0.78631569]]\n",
            "alpha :  0.0005197505197505191\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82560695 0.90235468]\n",
            " [0.85261347 0.37253248]] \n",
            " bias : \n",
            " [[0.95325167]\n",
            " [0.51785915]]\n",
            "//////////// end of iteration\n",
            "epoch : 87 \n",
            " weights : \n",
            "[[0.82560695 0.90235468]\n",
            " [0.85261347 0.37253248]] \n",
            " bias : \n",
            " [[0.95325167]\n",
            " [0.51785915]]\n",
            "alpha :  0.0005158184319119663\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10803249  0.00432565]] \n",
            " bias : \n",
            " [[0.78219193]]\n",
            "\n",
            " Loss : [[0.62139016]]\n",
            "alpha :  0.0005119453924914669\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75218875  0.8307128 ]\n",
            " [-0.03103804  0.72588143]] \n",
            " bias : \n",
            " [[0.92558429]\n",
            " [0.78631584]]\n",
            "alpha :  0.0005081300813008123\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82561201 0.9023599 ]\n",
            " [0.85261886 0.37253805]] \n",
            " bias : \n",
            " [[0.95325148]\n",
            " [0.51785895]]\n",
            "//////////// end of iteration\n",
            "epoch : 88 \n",
            " weights : \n",
            "[[0.82561201 0.9023599 ]\n",
            " [0.85261886 0.37253805]] \n",
            " bias : \n",
            " [[0.95325148]\n",
            " [0.51785895]]\n",
            "alpha :  0.000504328822392199\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10802748  0.00431152]] \n",
            " bias : \n",
            " [[0.78222543]]\n",
            "\n",
            " Loss : [[0.62138742]]\n",
            "alpha :  0.0005005840146837971\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75220029  0.8307214 ]\n",
            " [-0.0310385   0.72588109]] \n",
            " bias : \n",
            " [[0.9255807 ]\n",
            " [0.78631598]]\n",
            "alpha :  0.0004968944099378876\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82561696 0.90236502]\n",
            " [0.85262412 0.37254349]] \n",
            " bias : \n",
            " [[0.9532513 ]\n",
            " [0.51785876]]\n",
            "//////////// end of iteration\n",
            "epoch : 89 \n",
            " weights : \n",
            "[[0.82561696 0.90236502]\n",
            " [0.85262412 0.37254349]] \n",
            " bias : \n",
            " [[0.9532513 ]\n",
            " [0.51785876]]\n",
            "alpha :  0.0004932182490752152\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10802258  0.00429772]] \n",
            " bias : \n",
            " [[0.78225819]]\n",
            "\n",
            " Loss : [[0.62138475]]\n",
            "alpha :  0.0004895960832313336\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75221158  0.8307298 ]\n",
            " [-0.03103895  0.72588075]] \n",
            " bias : \n",
            " [[0.92557719]\n",
            " [0.78631612]]\n",
            "alpha :  0.0004860267314702304\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8256218  0.90237002]\n",
            " [0.85262927 0.37254881]] \n",
            " bias : \n",
            " [[0.95325112]\n",
            " [0.51785857]]\n",
            "//////////// end of iteration\n",
            "epoch : 90 \n",
            " weights : \n",
            "[[0.8256218  0.90237002]\n",
            " [0.85262927 0.37254881]] \n",
            " bias : \n",
            " [[0.95325112]\n",
            " [0.51785857]]\n",
            "alpha :  0.00048247024766806003\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10801778  0.00428422]] \n",
            " bias : \n",
            " [[0.78229024]]\n",
            "\n",
            " Loss : [[0.62138214]]\n",
            "alpha :  0.00047896543466113156\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75222262  0.83073802]\n",
            " [-0.03103939  0.72588043]] \n",
            " bias : \n",
            " [[0.92557375]\n",
            " [0.78631626]]\n",
            "alpha :  0.0004755111745126006\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82562653 0.90237491]\n",
            " [0.85263431 0.37255401]] \n",
            " bias : \n",
            " [[0.95325095]\n",
            " [0.51785839]]\n",
            "//////////// end of iteration\n",
            "epoch : 91 \n",
            " weights : \n",
            "[[0.82562653 0.90237491]\n",
            " [0.85263431 0.37255401]] \n",
            " bias : \n",
            " [[0.95325095]\n",
            " [0.51785839]]\n",
            "alpha :  0.00047206923682140004\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10801308  0.00427101]] \n",
            " bias : \n",
            " [[0.7823216]]\n",
            "\n",
            " Loss : [[0.62137959]]\n",
            "alpha :  0.0004686767692548035\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75223343  0.83074607]\n",
            " [-0.03103982  0.72588011]] \n",
            " bias : \n",
            " [[0.92557039]\n",
            " [0.78631639]]\n",
            "alpha :  0.00046533271288971573\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82563117 0.9023797 ]\n",
            " [0.85263925 0.37255911]] \n",
            " bias : \n",
            " [[0.95325078]\n",
            " [0.51785821]]\n",
            "//////////// end of iteration\n",
            "epoch : 92 \n",
            " weights : \n",
            "[[0.82563117 0.9023797 ]\n",
            " [0.85263925 0.37255911]] \n",
            " bias : \n",
            " [[0.95325078]\n",
            " [0.51785821]]\n",
            "alpha :  0.0004620004620004616\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10800848  0.00425809]] \n",
            " bias : \n",
            " [[0.78235229]]\n",
            "\n",
            " Loss : [[0.62137709]]\n",
            "alpha :  0.0004587155963302749\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.752244    0.83075394]\n",
            " [-0.03104024  0.7258798 ]] \n",
            " bias : \n",
            " [[0.9255671 ]\n",
            " [0.78631652]]\n",
            "alpha :  0.0004554771122751078\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.8256357  0.90238438]\n",
            " [0.85264407 0.3725641 ]] \n",
            " bias : \n",
            " [[0.95325061]\n",
            " [0.51785803]]\n",
            "//////////// end of iteration\n",
            "epoch : 93 \n",
            " weights : \n",
            "[[0.8256357  0.90238438]\n",
            " [0.85264407 0.3725641 ]] \n",
            " bias : \n",
            " [[0.95325061]\n",
            " [0.51785803]]\n",
            "alpha :  0.0004522499434687567\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10800397  0.00424545]] \n",
            " bias : \n",
            " [[0.78238233]]\n",
            "\n",
            " Loss : [[0.62137464]]\n",
            "alpha :  0.0004490681835191973\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75225435  0.83076165]\n",
            " [-0.03104064  0.72587949]] \n",
            " bias : \n",
            " [[0.92556387]\n",
            " [0.78631665]]\n",
            "alpha :  0.000445930880713489\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82564014 0.90238897]\n",
            " [0.8526488  0.37256898]] \n",
            " bias : \n",
            " [[0.95325045]\n",
            " [0.51785786]]\n",
            "//////////// end of iteration\n",
            "epoch : 94 \n",
            " weights : \n",
            "[[0.82564014 0.90238897]\n",
            " [0.8526488  0.37256898]] \n",
            " bias : \n",
            " [[0.95325045]\n",
            " [0.51785786]]\n",
            "alpha :  0.00044280442804428007\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10799955  0.00423307]] \n",
            " bias : \n",
            " [[0.78241175]]\n",
            "\n",
            " Loss : [[0.62137225]]\n",
            "alpha :  0.0004397215097105163\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75226449  0.8307692 ]\n",
            " [-0.03104104  0.72587919]] \n",
            " bias : \n",
            " [[0.92556072]\n",
            " [0.78631677]]\n",
            "alpha :  0.00043668122270742327\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82564449 0.90239346]\n",
            " [0.85265343 0.37257376]] \n",
            " bias : \n",
            " [[0.95325029]\n",
            " [0.51785769]]\n",
            "//////////// end of iteration\n",
            "epoch : 95 \n",
            " weights : \n",
            "[[0.82564449 0.90239346]\n",
            " [0.85265343 0.37257376]] \n",
            " bias : \n",
            " [[0.95325029]\n",
            " [0.51785769]]\n",
            "alpha :  0.00043365134431916705\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10799522  0.00422096]] \n",
            " bias : \n",
            " [[0.78244056]]\n",
            "\n",
            " Loss : [[0.62136991]]\n",
            "alpha :  0.00043066322136089545\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75227441  0.83077659]\n",
            " [-0.03104143  0.72587891]] \n",
            " bias : \n",
            " [[0.92555763]\n",
            " [0.78631689]]\n",
            "alpha :  0.0004277159965782717\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82564875 0.90239786]\n",
            " [0.85265796 0.37257844]] \n",
            " bias : \n",
            " [[0.95325014]\n",
            " [0.51785752]]\n",
            "//////////// end of iteration\n",
            "epoch : 96 \n",
            " weights : \n",
            "[[0.82564875 0.90239786]\n",
            " [0.85265796 0.37257844]] \n",
            " bias : \n",
            " [[0.95325014]\n",
            " [0.51785752]]\n",
            "alpha :  0.0004247787610619466\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10799097  0.00420909]] \n",
            " bias : \n",
            " [[0.78246878]]\n",
            "\n",
            " Loss : [[0.62136761]]\n",
            "alpha :  0.0004218815918998731\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75228414  0.83078382]\n",
            " [-0.03104181  0.72587862]] \n",
            " bias : \n",
            " [[0.9255546 ]\n",
            " [0.78631701]]\n",
            "alpha :  0.00041902367483762803\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82565292 0.90240217]\n",
            " [0.85266241 0.37258303]] \n",
            " bias : \n",
            " [[0.95324998]\n",
            " [0.51785736]]\n",
            "//////////// end of iteration\n",
            "epoch : 97 \n",
            " weights : \n",
            "[[0.82565292 0.90240217]\n",
            " [0.85266241 0.37258303]] \n",
            " bias : \n",
            " [[0.95324998]\n",
            " [0.51785736]]\n",
            "alpha :  0.0004161753485468541\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10798681  0.00419747]] \n",
            " bias : \n",
            " [[0.78249643]]\n",
            "\n",
            " Loss : [[0.62136536]]\n",
            "alpha :  0.00041336548398208717\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75229366  0.83079092]\n",
            " [-0.03104218  0.72587835]] \n",
            " bias : \n",
            " [[0.92555164]\n",
            " [0.78631713]]\n",
            "alpha :  0.0004105933073290902\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82565701 0.90240639]\n",
            " [0.85266676 0.37258753]] \n",
            " bias : \n",
            " [[0.95324983]\n",
            " [0.5178572 ]]\n",
            "//////////// end of iteration\n",
            "epoch : 98 \n",
            " weights : \n",
            "[[0.82565701 0.90240639]\n",
            " [0.85266676 0.37258753]] \n",
            " bias : \n",
            " [[0.95324983]\n",
            " [0.5178572 ]]\n",
            "alpha :  0.0004078303425774874\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10798273  0.00418609]] \n",
            " bias : \n",
            " [[0.78252353]]\n",
            "\n",
            " Loss : [[0.62136316]]\n",
            "alpha :  0.0004051043143609476\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.752303    0.83079787]\n",
            " [-0.03104255  0.72587808]] \n",
            " bias : \n",
            " [[0.92554873]\n",
            " [0.78631724]]\n",
            "alpha :  0.00040241448692152884\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82566102 0.90241053]\n",
            " [0.85267103 0.37259194]] \n",
            " bias : \n",
            " [[0.95324969]\n",
            " [0.51785704]]\n",
            "//////////// end of iteration\n",
            "epoch : 99 \n",
            " weights : \n",
            "[[0.82566102 0.90241053]\n",
            " [0.85267103 0.37259194]] \n",
            " bias : \n",
            " [[0.95324969]\n",
            " [0.51785704]]\n",
            "alpha :  0.00039973351099267123\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[-0.10797873  0.00417494]] \n",
            " bias : \n",
            " [[0.78255009]]\n",
            "\n",
            " Loss : [[0.621361]]\n",
            "alpha :  0.0003970880211780275\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[ 0.75231215  0.83080468]\n",
            " [-0.0310429   0.72587781]] \n",
            " bias : \n",
            " [[0.92554588]\n",
            " [0.78631735]]\n",
            "alpha :  0.00039447731755424035\n",
            "iterations : 1 \n",
            " weights : \n",
            "[[0.82566494 0.90241458]\n",
            " [0.85267521 0.37259626]] \n",
            " bias : \n",
            " [[0.95324954]\n",
            " [0.51785689]]\n",
            "//////////// end of iteration\n",
            "epoch : 100 \n",
            " weights : \n",
            "[[0.82566494 0.90241458]\n",
            " [0.85267521 0.37259626]] \n",
            " bias : \n",
            " [[0.95324954]\n",
            " [0.51785689]]\n",
            "Y_Hat : [[0.68589364 0.52807889 0.59881496 0.31663967 0.31663967 0.31663967]]\n",
            " Loss : [[0.59742807]]\n",
            "opa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoue9odL190J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}